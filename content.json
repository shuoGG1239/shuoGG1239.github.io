{"posts":[{"title":"2020年的绘画之路","text":"绘画之路 今年年初买了正版CSP, 开始了正式的练画之路 完整过了遍美术基础的视频, 从透视到色彩理论, 但感觉没啥卵用, 画画这事还是得靠堆练习量, 从小到大涂涂画画, 咱没科班基础, 但手感还有的 今年涂涂画画, 没画出什么成品, 草稿一堆…糊糊涂涂一年就过去了 总结 虽然完全不及原计划, 但今年还是花了时间去画的了. 明年尝试画点作品, 总不能一直画草稿吧","link":"/2020/12/20/2020%E5%B9%B4%E7%9A%84%E7%BB%98%E7%94%BB%E4%B9%8B%E8%B7%AF/"},{"title":"2021年我都画了些什么鬼?","text":"赶在2021结束前画了只苏芳 今年画的最满意的一只, 我是尽力还原原作的画风了, 堆了30多个图层, 算是大工程了 甚至录下了绘画过程: https://www.bilibili.com/video/BV1TT4y1m7zj 一些杂杂的涂鸦 今年的练习量 今年练的比较勤快, 留下了些杂七杂八的草稿和涂鸦 总结 今年终于是画了些成品作品, 但感觉还是少了, 就那么几幅, 希望明年能多画些作品","link":"/2021/12/29/2021%E5%B9%B4%E6%88%91%E9%83%BD%E7%94%BB%E4%BA%86%E4%BA%9B%E4%BB%80%E4%B9%88%E9%AC%BC/"},{"title":"2022年我都画了些什么鬼","text":"设计了只广工酱 红白配色, 头饰为校花紫荆花, 设计元素比较简约 还蛮受欢迎的, 做了梗图 附初稿纪念下 今年的练习量 今年摸鱼了, 这悲惨的练习量…","link":"/2022/12/22/2022%E5%B9%B4%E6%88%91%E9%83%BD%E7%94%BB%E4%BA%86%E4%BA%9B%E4%BB%80%E4%B9%88%E9%AC%BC/"},{"title":"BA逆向资源与解包思路","text":"前言 BA最新的游戏资源是在日服, 所以通常想获取需要: 安装安卓日服BA, 注册日服账号, 进入游戏, 才会动态拉取游戏所有资源, 总之很笨重繁琐 我需要一个轻量的方法来获取最新的游戏美术资源: 直接从服务器按需获取资源 流程 获取最新资源服务器地址, 这一步是难点, 放在本文最后一节 当前2025年5月份日服最新版本的资源服务器地址为: https://prod-clientpatch.bluearchiveyostar.com/r79_swwin27e1u6czsvrxshi_3 直接浏览器访问服务器地址+Android/bundleDownloadInfo.json即可获取到所有BundleAssets的资源信息列表, 此时我们可以从里面按需获取资源ID, 例如我想要小春(koharu)的资源, 就直接搜koharu, 如果只要3D资源搜koharu_original, 资源信息如下(其中Name字段便是资源ID): 完整地址: https://prod-clientpatch.bluearchiveyostar.com/r79_swwin27e1u6czsvrxshi_3/Android/bundleDownloadInfo.json 1234567891011121314151617181920212223242526272829303132333435363738394041424344[ { &quot;Name&quot;: &quot;assets-_mx-characters-koharu_original-_mxdependency_anim_assets_all_3786658315.bundle&quot;, &quot;Size&quot;: 5208436, &quot;IsPrologue&quot;: false, &quot;Crc&quot;: 3786658315, &quot;IsSplitDownload&quot;: false }, { &quot;Name&quot;: &quot;assets-_mx-characters-koharu_original-_mxdependency_assets_all_3546548379.bundle&quot;, &quot;Size&quot;: 536439, &quot;IsPrologue&quot;: false, &quot;Crc&quot;: 3546548379, &quot;IsSplitDownload&quot;: false }, { &quot;Name&quot;: &quot;assets-_mx-characters-koharu_original-_mxdependency_mat_assets_all_3814452055.bundle&quot;, &quot;Size&quot;: 4809, &quot;IsPrologue&quot;: false, &quot;Crc&quot;: 3814452055, &quot;IsSplitDownload&quot;: false }, { &quot;Name&quot;: &quot;assets-_mx-characters-koharu_original-_mxdependency_prefab_assets_all_3453201862.bundle&quot;, &quot;Size&quot;: 69441, &quot;IsPrologue&quot;: false, &quot;Crc&quot;: 3453201862, &quot;IsSplitDownload&quot;: false }, { &quot;Name&quot;: &quot;assets-_mx-characters-koharu_original-_mxdependency_psd_assets_all_478833476.bundle&quot;, &quot;Size&quot;: 346879, &quot;IsPrologue&quot;: false, &quot;Crc&quot;: 478833476, &quot;IsSplitDownload&quot;: false }, { &quot;Name&quot;: &quot;character-koharu_original-_mxload-2024-05-30_assets_all_629783588.bundle&quot;, &quot;Size&quot;: 90217, &quot;IsPrologue&quot;: false, &quot;Crc&quot;: 629783588, &quot;IsSplitDownload&quot;: false },] 直接访问服务地址+ /Android/+ 资源ID即可下载对应的资源文件 例如: https://prod-clientpatch.bluearchiveyostar.com/r79_swwin27e1u6czsvrxshi_3/Android/assets-_mx-characters-koharu_original-_mxdependency_assets_all_3546548379.bundle 到这一步其实游戏的资源文件就已经拿到了, 剩下AssetBundle解包流程就简单了, 直接选好所有下载好的资源文件, 拖到AssetStudio(AssetStudio的版本必须用最新不然会解析错误) AssetStudio下载地址: https://github.com/Perfare/AssetStudio/releases 然后从Asset List找需要的资源即可, 例如想要3D模型则直接导出Koharu_Original_Mesh, 如图所示: 最后把导出的fbx文件导入到blender测试下, 记得FBX Unit的单位要改为m, (默认值为cm) 效果如下, 完工 获取最新资源服务器地址流程 访问: https://prod-noticeindex.bluearchiveyostar.com/prod/index.json, 搜索LatestClientVersion, 看到对应的值为1.56, 这是最新的客户端版本 访问地址获取1.56版本的游戏客户端: https://d.apkpure.com/b/XAPK/com.YostarJP.BlueArchive?nc=arm64-v8a&amp;sv=24&amp;versionCode=56 解压apk, 到资源路径./assets/bin/Data下执行脚本, 脚本会打印服务器地址, 原理是通过UnityTool扫该目录下的所有AssetBundle来解析 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182# 打印资源服务器地址import timeimport base64import jsonfrom base64 import b64decodeimport osimport UnityPyfrom UnityPy.files.File import ObjectReaderfrom Crypto.Util.strxor import strxorfrom xxhash import xxh32_intdigestdef calculate_hash(name: bytes | str) -&gt; int: &quot;&quot;&quot;Calculate a 32-bit hash using xxhash with UTF-8 encoding if needed.&quot;&quot;&quot; if isinstance(name, str): name = name.encode(&quot;utf8&quot;) return xxh32_intdigest(name)def create_key(name: str, size: int = 8) -&gt; bytes: &quot;&quot;&quot;Create a random key based on a hashed name and a specific size.&quot;&quot;&quot; seed = calculate_hash(name) return MersenneTwister(seed).next_bytes(size)def xor(value: bytes, key: bytes) -&gt; bytes: &quot;&quot;&quot;XOR operation between two byte arrays.&quot;&quot;&quot; if len(value) == len(key): return strxor(value, key) if len(value) &lt; len(key): return strxor(value, key[: len(value)]) # Handle the case where the value is longer than the key return b&quot;&quot;.join( strxor(value[i: i + len(key)], key) for i in range(0, len(value) - len(key) + 1, len(key)) ) + strxor( value[len(value) - len(value) % len(key):], key[: len(value) % len(key)] )def convert_string(value: bytes | str, key: bytes = b&quot;&quot;) -&gt; str: &quot;&quot;&quot;Decrypt or decode a base64 string or raw bytes, depending on the input.&quot;&quot;&quot; if not value: return &quot;&quot; try: raw = b64decode(value) if decoded := xor(raw, key).decode(&quot;utf16&quot;): return decoded raise UnicodeError except: if isinstance(value, bytes): return value.decode(&quot;utf8&quot;) return &quot;&quot;class MersenneTwister: # Constants for the Mersenne Twister algorithm N = 624 M = 397 MATRIX_A = 0x9908B0DF # Constant vector a UPPER_MASK = 0x80000000 # Most significant w-r bits LOWER_MASK = 0x7FFFFFFF # Least significant r bits def __init__(self, seed: int | None = None) -&gt; None: if seed is None: seed = int(time.time() * 1000) # Use current time in milliseconds as seed self.mt = [0] * self.N # Create an array to store the state self.mti = self.N + 1 # Initial value for mti self.init_genrand(seed) def init_genrand(self, seed: int) -&gt; None: &quot;&quot;&quot;Initializes the generator with a seed.&quot;&quot;&quot; self.mt[0] = seed &amp; 0xFFFFFFFF # Seed is limited to 32 bits for i in range(1, self.N): self.mt[i] = ( 1812433253 * (self.mt[i - 1] ^ (self.mt[i - 1] &gt;&gt; 30)) + i ) &amp; 0xFFFFFFFF self.mti = self.N def _generate_numbers(self) -&gt; None: &quot;&quot;&quot;Generates N words at a time.&quot;&quot;&quot; for i in range(self.N - self.M): y = (self.mt[i] &amp; self.UPPER_MASK) | (self.mt[i + 1] &amp; self.LOWER_MASK) self.mt[i] = ( self.mt[i + self.M] ^ (y &gt;&gt; 1) ^ (self.MATRIX_A if y % 2 else 0) ) for i in range(self.N - self.M, self.N - 1): y = (self.mt[i] &amp; self.UPPER_MASK) | (self.mt[i + 1] &amp; self.LOWER_MASK) self.mt[i] = ( self.mt[i + (self.M - self.N)] ^ (y &gt;&gt; 1) ^ (self.MATRIX_A if y % 2 else 0) ) y = (self.mt[self.N - 1] &amp; self.UPPER_MASK) | (self.mt[0] &amp; self.LOWER_MASK) self.mt[self.N - 1] = ( self.mt[self.M - 1] ^ (y &gt;&gt; 1) ^ (self.MATRIX_A if y % 2 else 0) ) self.mti = 0 def genrand_int32(self) -&gt; int: &quot;&quot;&quot;Generates a random number on [0, 0xFFFFFFFF]-interval.&quot;&quot;&quot; if self.mti &gt;= self.N: self._generate_numbers() y = self.mt[self.mti] self.mti += 1 # Tempering transformation y ^= y &gt;&gt; 11 y ^= (y &lt;&lt; 7) &amp; 0x9D2C5680 y ^= (y &lt;&lt; 15) &amp; 0xEFC60000 y ^= y &gt;&gt; 18 return y &amp; 0xFFFFFFFF # Return 32-bit unsigned integer def genrand_int31(self) -&gt; int: &quot;&quot;&quot;Generates a random number on [0, 0x7FFFFFFF]-interval.&quot;&quot;&quot; return self.genrand_int32() &gt;&gt; 1 def next_bytes(self, length: int) -&gt; bytes: &quot;&quot;&quot;Generates random bytes.&quot;&quot;&quot; return b&quot;&quot;.join( self.genrand_int31().to_bytes(4, &quot;little&quot;, signed=False) for _ in range(0, length, 4) )[:length]class UnityUtils: @staticmethod def search_unity_pack( pack_path: str, data_type: list | None = None, data_name: list | None = None, condition_connect: bool = False, read_obj_anyway: bool = False, ) -&gt; list[ObjectReader] | None: data_list: list[ObjectReader] = [] type_passed = False try: env = UnityPy.load(pack_path) for obj in env.objects: if data_type and obj.type.name in data_type: if condition_connect: type_passed = True else: data_list.append(obj) if read_obj_anyway or type_passed: data = obj.read() if data_name and data.m_Name in data_name: if not (condition_connect or type_passed): continue data_list.append(obj) except: pass return data_listdef decode_server_url(data: bytes) -&gt; str: ciphers = { &quot;ServerInfoDataUrl&quot;: &quot;X04YXBFqd3ZpTg9cKmpvdmpOElwnamB2eE4cXDZqc3ZgTg==&quot;, &quot;DefaultConnectionGroup&quot;: &quot;tSrfb7xhQRKEKtZvrmFjEp4q1G+0YUUSkirOb7NhTxKfKv1vqGFPEoQqym8=&quot;, &quot;SkipTutorial&quot;: &quot;8AOaQvLC5wj3A4RC78L4CNEDmEL6wvsI&quot;, &quot;Language&quot;: &quot;wL4EWsDv8QX5vgRaye/zBQ==&quot;, } b64_data = base64.b64encode(data).decode() json_str = convert_string(b64_data, create_key(&quot;GameMainConfig&quot;)) obj = json.loads(json_str) encrypted_url = obj[ciphers[&quot;ServerInfoDataUrl&quot;]] url = convert_string(encrypted_url, create_key(&quot;ServerInfoDataUrl&quot;)) return urlif __name__ == &quot;__main__&quot;: for f in os.listdir(os.getcwd()): if url_obj := UnityUtils.search_unity_pack(f, [&quot;TextAsset&quot;], [&quot;GameMainConfig&quot;], True): url = decode_server_url(url_obj[0].read().m_Script.encode(&quot;utf-8&quot;, &quot;surrogateescape&quot;)) print(url) break 脚本执行后打印: https://yostar-serverinfo.bluearchiveyostar.com/r79_56_swwin27e1u6czsvrxshi.json 访问上一步打印的地址得到json如下, 其中1.56下的AddressablesCatalogUrlRoot对应的值便是最新的资源服务器的地址https://prod-clientpatch.bluearchiveyostar.com/r79_zqy5uxhd13gi68vaatbd 1234567891011121314151617181920212223242526{ &quot;ConnectionGroups&quot;: [ { &quot;Name&quot;: &quot;Prod-Audit&quot;, &quot;ManagementDataUrl&quot;: &quot;https://prod-noticeindex.bluearchiveyostar.com/prod/index.json&quot;, &quot;IsProductionAddressables&quot;: true, &quot;ApiUrl&quot;: &quot;https://prod-game.bluearchiveyostar.com:5000/api/&quot;, &quot;GatewayUrl&quot;: &quot;https://prod-gateway.bluearchiveyostar.com:5100/api/&quot;, &quot;KibanaLogUrl&quot;: &quot;https://prod-logcollector.bluearchiveyostar.com:5300&quot;, &quot;ProhibitedWordBlackListUri&quot;: &quot;https://prod-notice.bluearchiveyostar.com/prod/ProhibitedWord/blacklist.csv&quot;, &quot;ProhibitedWordWhiteListUri&quot;: &quot;https://prod-notice.bluearchiveyostar.com/prod/ProhibitedWord/whitelist.csv&quot;, &quot;CustomerServiceUrl&quot;: &quot;https://bluearchive.jp/contact-1-hint&quot;, &quot;OverrideConnectionGroups&quot;: [ { &quot;Name&quot;: &quot;1.0&quot;, &quot;AddressablesCatalogUrlRoot&quot;: &quot;https://prod-clientpatch.bluearchiveyostar.com/m28_1_0_1_mashiro3&quot; }, { &quot;Name&quot;: &quot;1.56&quot;, &quot;AddressablesCatalogUrlRoot&quot;: &quot;https://prod-clientpatch.bluearchiveyostar.com/r79_zqy5uxhd13gi68vaatbd&quot; } ], &quot;BundleVersion&quot;: &quot;li3pmyogha&quot; } ]} 参考 https://github.com/ZM-Kimu/Blue-Archive-Asset-Downloader https://github.com/Deathemonic/BA-AD","link":"/2025/05/01/BA%E9%80%86%E5%90%91%E8%B5%84%E6%BA%90%E4%B8%8E%E8%A7%A3%E5%8C%85%E6%80%9D%E8%B7%AF/"},{"title":"QQ机器人qqbot把玩","text":"关于qqbot的官方sdk 都2024年7月了, 有些sdk的最新更新时间还停留在去年, 最新的也就python版本, 这里我用的是botpy https://github.com/tencent-connect/botpy QQ群发图的问题 botpy目前这个版本还没支持QQ群发base64图的功能, 这意味着必须先把图送到图床才行, 麻烦! 翻阅接口文档我发现其实接口上已经是支持了,但是所有语言的sdk没有一个支持就离谱 这时候需要魔改下botpy源码, 很简单, 找到botpy/api.py, 改下post_group_file这个方法, 加一个file_data的参数即可 123456789101112131415161718192021async def post_group_file( self, group_openid: str, file_type: int, url: str, file_data: str, # 新增该参数即可 srv_send_msg: bool = False,) -&gt; message.Media: &quot;&quot;&quot; 上传/发送群聊图片 Args: group_openid (str): 您要将消息发送到的群的 ID file_type (int): 媒体类型：1 图片png/jpg，2 视频mp4，3 语音silk，4 文件（暂不开放） url (str): 需要发送媒体资源的url srv_send_msg (bool): 设置 true 会直接发送消息到目标端，且会占用主动消息频次 &quot;&quot;&quot; payload = locals() payload.pop(&quot;self&quot;, None) route = Route(&quot;POST&quot;, &quot;/v2/groups/{group_openid}/files&quot;, group_openid=group_openid) return await self._http.request(route, json=payload) 吐槽下QQBot 咱开发这机器人无非就是要和QQ群里面的小伙伴们一起耍, 结果个人开发者开发的机器人只能在沙箱群里玩, 沙箱群最多就20人, 那还玩个蛋? 看官方文档和SDK的更新情况, 感觉这个项目大概是要凉了 希望有朝一日QQBot的产品能把它盘活了, 目前这玩意, 我是不想继续折腾了, 88 最后贴个我的Demo供参考1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586import botpyfrom botpy import logging, Intentsfrom botpy.message import GroupMessageclass Bot(botpy.Client): img_gen_running = False app_id: int = 0 app_secret: str = '' def __init__(self, intents: Intents): super().__init__(intents) self.app_id, self.app_secret = load_qqbot_cfg() tc_app_id, tc_app_secret = load_tecentcloud_cfg() tran = lang_translate.LanguageTranslater(tc_app_id, tc_app_secret) if tc_app_id != '' else None self.qq_msg_parser = qq_msg_parser.QQMsgParser(tran) self.ai_chat = ai_chat.AiChat(tc_app_id, tc_app_secret) async def on_group_at_message_create(self, message: GroupMessage): print(message.content) prompt_type, prompt = self.qq_msg_parser.msg_to_prompt(message.content) msg_req = 0 if prompt_type == qq_msg_parser.PROMPT_TYPE_IMG: await self.resolve_img_gen(message, msg_req, prompt) else: # PROMPT_TYPE_TEXT case await self.resolve_chat(message, msg_req, prompt) async def resolve_img_gen(self, message: GroupMessage, msg_req: int, img_prompt: str): if self.img_gen_running: return self.group_reply_txt(message, msg_req, &quot;aris手里的画没画完呐~等画完再发一遍给aris喵~&quot;) msg_req += 1 await self.group_reply_txt(message, msg_req, &quot;aris画得比较慢,要等半分钟喵~&quot;) msg_req += 1 self.img_gen_running = True gen_code, file_or_msg = await img_gen.generate_img(img_prompt) self.img_gen_running = False _log.info(f'generate_img(&quot;{img_prompt}&quot;): {gen_code} {file_or_msg}') if gen_code == 200: jpg_data = await img_gen.get_jpg_from_png(file_or_msg) jpg_data_b64 = base64.standard_b64encode(jpg_data).decode() await self.group_reply_image_data(message, msg_req, jpg_data_b64) else: await self.group_reply_txt(message, msg_req, &quot;aris这张不想画了,换别的吧 T_T&quot;) async def resolve_chat(self, message: GroupMessage, msg_req: int, prompt: str): reply_txt = self.ai_chat.chat(prompt) await self.group_reply_txt(message, msg_req, reply_txt) async def group_reply_txt(self, message: GroupMessage, msg_req: int, txt: str): await self.api.post_group_message( group_openid=message.group_openid, msg_type=0, msg_id=message.id, msg_seq=msg_req, content=txt) async def group_reply_image_data(self, message: GroupMessage, msg_req: int, img_b64: str): upload_media = await self.api.post_group_file( group_openid=message.group_openid, file_type=1, url='', file_data=img_b64, ) await self.api.post_group_message( group_openid=message.group_openid, msg_type=7, msg_id=message.id, msg_seq=msg_req, media=upload_media, ) async def group_reply_image_url(self, message: GroupMessage, msg_req: int, file_url: str): upload_media = await self.api.post_group_file( group_openid=message.group_openid, file_type=1, url=file_url, file_data='', ) await self.api.post_group_message( group_openid=message.group_openid, msg_type=7, msg_id=message.id, msg_seq=msg_req, media=upload_media, )","link":"/2024/07/30/QQ%E6%9C%BA%E5%99%A8%E4%BA%BAqqbot%E6%8A%8A%E7%8E%A9/"},{"title":"ai图手脚崩坏如何修复","text":"先看看修复效果 这是原ai图, 是用sd的一个微调模型生成的: 这是修复后的图: 怎么修复? 重绘? 用sd的inpaint局部重绘? 然后加上controlNet? 各种教程的都教人这么去搞, 然后效果就是一坨! 首先重绘出一只完美的手就要换时间不停重试,好不容易roll出一只好手, 重绘区域却和整体图片有违和感, 对于违和感是0容忍的, 对于一幅插画来说, 这比手脚崩坏严重多了; 在无数次重试,我发现几个小时就过了… 总结, 重绘就是陷阱, 不要陷进去, 至少目前是这样的, 未来不好说 半小时人工修好还费那劲在那roll inpaint? 我的评价是: 直接动笔, 半小时的事情, 效果是完美的","link":"/2023/12/06/ai%E5%9B%BE%E6%89%8B%E8%84%9A%E5%B4%A9%E5%9D%8F%E5%A6%82%E4%BD%95%E4%BF%AE%E5%A4%8D/"},{"title":"astrbot源码","text":"前言 记录下, 防遗忘 关于各阶段的handler 关键代码: star_handlers_registry.get_handlers_by_event_type 可以根据EventType找各个阶段的代码 123456789101112131415# astrbot/core/star/star_handler.pyclass EventType(enum.Enum): &quot;&quot;&quot;表示一个 AstrBot 内部事件的类型。如适配器消息事件、LLM 请求事件、发送消息前的事件等 用于对 Handler 的职能分组。 &quot;&quot;&quot; OnAstrBotLoadedEvent = enum.auto() # AstrBot 加载完成 AdapterMessageEvent = enum.auto() # 收到适配器发来的消息 OnLLMRequestEvent = enum.auto() # 收到 LLM 请求（可以是用户也可以是插件） OnLLMResponseEvent = enum.auto() # LLM 响应后 OnDecoratingResultEvent = enum.auto() # 发送消息前 OnCallingFuncToolEvent = enum.auto() # 调用函数工具 OnAfterMessageSentEvent = enum.auto() # 发送消息后 llm_request的装饰器handlers astrbot/core/pipeline/process_stage/method/llm_request.py 1234567891011# 执行请求 LLM 前事件钩子。# 装饰 system_prompt 等功能handlers = star_handlers_registry.get_handlers_by_event_type( EventType.OnLLMRequestEvent)for handler in handlers: try: logger.debug( f&quot;hook(on_llm_request) -&gt; {star_map[handler.handler_module_path].name} - {handler.handler_name}&quot; ) await handler.handler(event, req) # 执行handler 完整调用链 astrbot/core/pipeline/scheduler.py: await self._process_stages(event) astrbot/core/pipeline/scheduler.py: async for _ in coro astrbot/core/pipeline/process_stage/stage.py: async for _ in self.llm_request_sub_stage.process(event) astrbot/core/pipeline/process_stage/method/llm_request.py: for handler in handlers","link":"/2025/04/18/astrbot%E6%BA%90%E7%A0%81/"},{"title":"axios的ES module (esm)","text":"背景 刚好遇到某个场景需要用到es module, axios用习惯了, 不过axios官方没有esm版本 https://github.com/axios/axios/issues/1879 解决 可以用第三方: https://github.com/bundled-es-modules/axios 使用起来很简单, 直接用里面的axios.js即可12345678910111213141516171819&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;ESM-test&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;script type=&quot;module&quot;&gt; import axios from './axios.js' axios.get('http://127.0.0.1:8888/shuogg').then(resp =&gt; { console.log(resp.data) }).catch(e =&gt; { console.log(e) })&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;","link":"/2020/06/05/axio_esm/"},{"title":"bender-kurt教程学习笔记","text":"前言 本文是学习Kurt-blender教程时的学习笔记, 主要记了些重点, 方便未来翻看回顾 blender版本为4.3 0. 资料 Blender官方手册 1. 基础操作 左边的工具可以长按出现子工具选项 视角: 中键拖动: 自由视角转换 Alt+中键拖动: 正视角转换 (Num1-8平替) shift+中键拖动: 平移视角转换 Alt+Z: 透视模式 /: 进入物体的放大视图 N: 右边的插件栏是否显示 F12: 渲染预览 游标(3D游标): Shift+右键: 设置游标到当前鼠标位置 Shift+S: 弹出游标轮盘 Shift+C: 游标恢复至世界中心 原点: 原点是物体的根基, 1个原点就是1个物体; 如物体模式下复制, 原点数会+1, 编辑模式下复制, 原点数不变 编辑原点: 轴心点: 变换: G(grab): 进入平移状态, 按XYZ固定轴方向, 左键确定右键取消 R(rotate): 进入旋转状态, 按XYZ固定轴方向, 左键确定右键取消 (期间填角度可以指定角度) S(scale): 进入缩放状态, 按XYZ固定轴方向, 左键确定右键取消 Alt+G/R/S: 重置G,R,S状态, 也就是右上角的变换归0或归1 Ctrl+A: 应用(缩放); 应用后坐标参数会矫正, 所以物体模式下一定要记得ctrl+A! 物体操作 X: 弹出删除菜单 Shift+A: 新增模型或其他东西 Shift+H: 将选中物体外的东西隐藏 Shift+D: 复制选中物体 Alt+D: 关联复制选中物体(改一个同步给全部) Ctrl+J: 合并选中的多个物体 Ctrl+L: 选中2个以上时, 按下弹出关联菜单(如关联材质等) Ctrl+C,Ctrl+V: 复制粘贴物 Ctrl按住: 临时吸附原点 Ctrl+2: 添加细分修改器 父子: 绑父级: 选子物件(可多个)-&gt; shift选父物件 -&gt; Ctrl+P -&gt; 物体: 绑定父子 解父级: Alt+P 或 右键菜单父级, 有时根据情况选清空父级保持变换, 否则会飘 导航栏 M(选中多个物体后): 移动到某个集合内, 当物体项距离集合太远时可用 .(句号): 导航栏快速定位到选中物体 父子级的选择, 可以手动shift把父子一个个点上; 或者在父级右键点选择层级: 摄像机 将当前视图设置给摄像机 1.1 总结 课程1.2一图流 课程1.3一图流 2. 编辑模式 Tab: 切换编辑模式或物体模式 编辑基础 1,2,3: 点,线,面 A: 全选 (取消全选是Alt+A) L: 全选连接在一起的线 J: 连接顶点 (选择两个点后按下, 会连成一条边, 在两点之间存在面时使用) F: 连接顶点 (选择两个点后按下, 会连成一条边, 在两点之间不存在面时使用) E: 挤出; 记住在按下E后, 想取消不能按Esc, 而是要Ctrl+Z, 因为按下E时新的点线面就已提交! M: 合并所选(如合并2个点成1点) 例: 选2个点-&gt; M -&gt; 到末选节点: 合并2点 P: 分离 例: 树桩从树皮shift+D然后按P分离出苔藓, 此时树桩和苔藓为2个独立物体 Y: 拆分(不产生新物体,相对P) V: 断开(点或边) Ctrl+B(选中线时按): 在线条出细分出倒角, 滚轮控制细分数 Ctrl+E: 桥接循环边 Ctrl+X: 融并 (相当于安全的X, 干掉点或面时不会把面也干掉了) 例: 选边-&gt; X -&gt; 融并边: 去掉多余边 (Ctrl+X) Alt+选边: 选中周围的循环边(如多边环) U: uv菜单 GG: 使点贴着物体线位移 Shift+鼠标移动操作: 精准缓慢 Ctrl+鼠标移动与操作: 吸附网格 实用操作流 旋转90°: R-&gt;S-&gt;90 水平对齐选中点: S-&gt;Z-&gt;0 快速应用所有修改器: 右键-&gt; 转换为 -&gt; 网格 (物体模式下): 快速应用所有修改器 视图着色方式修改, 为了方便区分可以改为随机 对于多个点重合一起的情况可以: 网格-&gt;清理-&gt;按间距合并 2.1修改器 曲线修改器 创建流程: 新建曲线(路径曲线)-&gt; 编辑曲线 -&gt; 物体添加曲线修改器 -&gt; 吸曲线 Alt+S: 修改半径 通过曲线制作尾巴: 新建路径曲线-&gt; 集合数据 -&gt; 倒角 -&gt; 深度拉大 -&gt; Alt+S调各点的半径 蒙皮修改器 创建流程: 创建平面-&gt; 编辑 -&gt; 全选点 -&gt; M合并点 -&gt; 创蒙皮修改器 -&gt; 编辑E挤出点 -&gt; 选点Ctrl+A调整蒙皮宽度 Ctrl+A: 修改半径 置换修改器 石头示例: 立方体-&gt; 细分修改器 -&gt; 置换修改器 -&gt; 纹理, 沃罗诺伊图 -&gt; 调整参数 2.2 总结 课程2.1一图流 课程2.2一图流 3. 着色器 着色器基础操作 Ctrl+右键划动: 切断材质连线 Ctrl+J (框选节点后): 给选中节点们组合成一个组 NodeWrangler插件 Ctrl+T: 补全前置节点 Ctrl+Shift+左键: 快速把一个节点连接到输出预览 Ctrl+Shift+T (选择BSDF节点后): 选择材质4样, 自动补齐置换 (记得改材质置换模式为: 置换与凹凸) 4样: color, displacement, normal, roughness Ctrl+Shift+右键拉到另外一个节点: 为该2个节点创建一个混合BSDF节点 Alt+S (选混合节点后): 切换混合节点上下顺序 UV绘制: 进入纹理绘制模式可以给UV上色 智能切UV: 编辑模式下-&gt; A -&gt; U -&gt; 展开 -&gt; 智能UV投射 手动切UV: 编辑模式下-&gt; 线模式下选好切割线(如Alt+线)-&gt; U -&gt; 标记缝合边-&gt; A-&gt; U-&gt; 展开 编辑模式下选好要遮罩的面后进入纹理绘制: 3.1 总结 4. 粒子 节点组: 当只希望物体的一部分受影响, 可以用节点组, 有些修改器可指定节点组 * 变换跟时间轴绑定: 先创建一个圆环, 编辑模式下, F填充成圆盘, 然后物体选中圆盘后创建粒子系统 5. 场景灯光 导入 关联: 无法修改, 但省内存 (需要去源文件修改,再重新加载) 追加: 可以修改, 但消耗资源 摄像机 景深和透视比较常用 6.动画 关键帧 插入关键帧: 选择物体后按i, 或者右键菜单中插入关键帧; 各种参数的右键菜单都有插入关键帧, 包括修改器里面的参数啥的都行 选择物体后按k会弹出关键帧菜单, 相当于3.6版本的i的功能 例如在缩放右键插入关键帧就仅在缩放下插帧 形态键 用于记录物体的某几个状态的形变, 例如下图的蝴蝶翅膀上下扇动 曲线动画 添加修改器: 常用的有内建函数, 噪波, 循环 骨骼 创建骨架: Shift+A -&gt; 骨架 编辑骨架: Tab进入编辑模式, 编辑方式和以前那些物体编辑基本一致; 挤出子骨骼用E, 右键细分可以分成n条小骨骼 绑定骨架: 物体模式 -&gt; 选物体 -&gt; 选骨骼 -&gt; Ctrl+P -&gt; 附带自动权重 (如下图) 绑骨骼前, 记得将先将物体清除父级, 不然容易出奇怪的bug 骨骼带动物体: 进入姿态模式, 此时试试移动骨骼(G), 物体也会跟着动, 所以打关键帧也在姿态模式下打 姿态模式下只允许操作骨骼, 属于骨骼的独占专属模式 若骨骼在物体内部被挡住无法操作, 则可以在姿态模式下, 视图显示 -&gt; 在前面 标准追踪 追踪轴用的是局部轴, 如图狐狸头跟随蝴蝶的移动而转动 7. 合成与输出 合成器 合成器用于后期处理美化之类的, 相当于把Ae的部分功能搬进来, 属于纯2D的处理 输出 主要关注如图几个点, 分辨率, 输出文件夹, 保存格式等; 建议保存为图片序列, 主要可以防止渲染一半崩了 进行渲染输出文件","link":"/2024/12/09/blender-kurt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"bender-MMD学习笔记","text":"MMD mmd主要定义了一套规范, 如骨骼命名规范, 有标准就可以使组件通用化, 如动作可以通用 mmd文件 .pmx: mmd模型文件 .vmd: mmd动作(运动)文件 .vpd: mmd姿态文件 MMD导入Blender 在MMD插件中: 模型导入-&gt; 导入pmx文件-&gt; 选择模型 -&gt; 转换给Blender 若想单独编辑组件, 可按材质将各部件拆开, 如下图 人物一般不建议做拆分, 会出现奇奇怪怪的问题 模型描边: 点边缘预览可为模型描边 三渲二 方式一: 直接用MiaoBox的三渲二插件 效果如图: 动画 动作文件导入 vmd文件可以包含表情动作,肢体动作,镜头动作, 也可以分开包含 假设vmd文件同时包含了以上3种动作: 选中人物, 只能导入表情动作 选中骨架, 只能导入肢体动作 权限人物+骨架, 能同时导入表情+肢体动作 选中摄像机, 只能导入镜头动作 (一般镜头动作是单独vmd文件) 导入动作前记得把所有ik切换关掉, 不然有时会出现脚动不了的情况 动作导入示例 全选模型 -&gt; 运动/导入 -&gt; 导入vmd文件, 边距改30(有多个文件就重复几次)-&gt; 按空格看看动画效果 导入动画后, 时间线不会显示关键帧的, 在选择骨骼后按i插入关键帧后就显示了 摄像机导入 选中摄像机再导入 调整摄像机参数或手动K帧, 一般也是只调整这个摄像机 表情动画 表情动画一般是用形态键实现, 所以在形态键栏中调整或K帧 物理 物理烘培 开启物理-&gt; 更新世界 -&gt; 烘焙 -&gt; 等待物理烘培结束(图示例是烘到39帧)-&gt; 空格看看动画效果 刚体 物理模拟的原理就是靠刚体模拟实现 点击刚体图标显示刚体 若要修改刚体: 删除烘焙 -&gt; 关闭物理 -&gt; 再去修改刚体 换头手术 姿态模式下选头部骨骼, 切断, 头部删掉 导入另一个mmd模型, 姿态模式下选头部骨骼, 切断, 身体删掉 头部安放到合适位置 同时选中头和身的骨架, 进入姿态模式, 选择头部骨骼, 再选颈部骨骼, 合并","link":"/2024/03/01/blender-MMD%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"blender-从恋活导入模型","text":"1. 插件下载 KKBP提供了恋活导出插件(KKBP_Exporter)和blender导入插件(KKBP_Importer) KKBP: 仓库: https://github.com/FlailingFog/KK-Blender-Porter-Pack release: https://github.com/FlailingFog/KK-Blender-Porter-Pack/releases wiki: https://kkbpwiki.github.io/ 选哪个版本可以参照下图: 本次教程使用blender4.3, 所以用了7.2.2版本的KKBP 表格来自kkbp-FQ: https://flailingfog.github.io/faq.html 2. 插件安装 KKBP_Importer是安装给blender的, 就走正常的本地插件安装流程就行 KKBP_Exporter是安装给恋活的, 将里面的KKBP_Exporter.dll文件放在恋活目录中的BepInEx/plugins中 3. 模型导出 进入角色创建界面, 你会发现顶部多出的ui就是KKBP插件 选好要导出的角色, 勾选Export Variations和Export Single Outfit, 点Export Model for KKBP 等待一段时间后, 会弹出导出的模型文件夹, 里面有个model.pmx待会用于导入到blender 4. 模型导入 打开blender的KKBP插件, 点导入模型, 选上一步导出模型文件夹里的model.pmx 导入模型需要花费数分钟, 最终效果如图","link":"/2025/03/08/blender-%E4%BB%8E%E6%81%8B%E6%B4%BB%E5%AF%BC%E5%85%A5%E6%A8%A1%E5%9E%8B/"},{"title":"bender-恋活改模笔记","text":"1. zipmod解包 zipmod文件改后缀解压, 找到里面的.unity3d文件 用SB3Utility来解开.unity3d文件 例如下图, 将hyacine_shoes.unity3d拖到SB3Utility, 找到对应的MeshRenderer后Export即可 导出后.unity3d文件同目录下会导出对应的.fbx文件 2. 导入Blender改模 直接导入生成的.fbx文件 导入后一般太小了, 为了方便修改, 放大100倍 (s-&gt;100) 此时你可以随意修改模型了 修改模型后, 导出为.fbx, 导出时物体类型为骨架和网络, 缩放为0.01, 因为上一步放大了100倍 3. 重新打包zipmod 再次用SB3Utility打开最开始待修改的那个.unity3d文件 将修改好的fbx拖入左下窗 -&gt; 将模型拖到MeshRenderer的上一级 -&gt; Rest/Bind -&gt; 关闭fbx编辑 最后Ctrl+s, 保存.unity3d文件 重新打包成zipmod, 打包时记得压包根目录必须是abdata和manifest.xml","link":"/2025/03/07/blender-%E6%81%8B%E6%B4%BB%E6%94%B9%E6%A8%A1%E7%AC%94%E8%AE%B0/"},{"title":"Jetbrains Clion官方支持了Stm32的项目搭建, 说下感想","text":"背景 得知Clion 2019.1之后的版本官方直接支持Stm32项目的创建, 遂怀揣激动之心准备一试… 吐槽 照着别人的教程, 一顿操作猛如虎, 一会捣鼓OpenOCD, 一会捣鼓arm-none-eabi-gcc… …说实话, 过程挺麻烦的, 会遇到一些坑 手头上只有一块老stm32的核心板还有一个Jlink, 烧写调试也只能靠Jlink. 结果捣鼓了老半天, Jlink这块没办法打通, 即没办法用Jlink愉快地Debug, 遂放弃 结论 现阶段还不完善, 该用keil的还是得用keil (当然也有可能只是我的搭建姿势有问题, 望指教) 期待未来某一天Clion能够拳打Keil脚踩IAR 参考教程 Clion下开发STM32 用clion自带的嵌入式开发功能和stm32cubeMX开发stm32!!!","link":"/2020/05/05/clion_stm32/"},{"title":"bender雕刻学习笔记","text":"前言 blender版本为4.3 常用操作一图流 4.3之前的笔刷 4.3之后的笔刷 模型切割 快速布尔: 选被切物体 -&gt; 选形状物体 -&gt; Ctrl+Shift+- 插件Carver: Ctrl+Shift+X: 唤起插件 不选物体唤起是创建模式, 选物体唤起是切割模式 空格: 切换工具或确定切割 雕刻基础 笔刷 弹出笔刷菜单: Shift+空格 调整笔刷大小: F或者[, ] 调整笔刷强度: Shift+F (默认强度0.5太低了建议直接改成1.0) 按Ctrl绘制: 可实现反向操作, 凸变凹, 凹变凸 按Shift绘制: 可实现平滑 常用几个笔刷: 遮罩笔刷(M): Ctrl: 按住进行绘制去除遮罩 Ctrl+i: 遮罩反向 Alt+M: 取消全部遮罩 动态拓扑 自动细分, 雕到哪细分到哪 缺点: 由于不受控制, 所以可能导致面数过多 重构网格 可以理解为雕刻模式下的细分, 不同细分下的雕刻效果不一样, 所以经常按需调整 Ctrl+R: 重构网格 R: 快速调整网格细分, R调整完再按Ctrl+R提交进行重构生效 Quad Remesher插件 一键拓扑: 对所有面智能四边化处理 使用前须关掉动态拓扑","link":"/2024/12/29/blender%E9%9B%95%E5%88%BB%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"Py小玩具-简易取色器","text":"简单的拾色器 最近遇到几次取屏幕某处颜色的场景, 用ps去取色又觉得有点麻烦(步骤太多我懒), 索性自己做一个简单的拾色器 功能极简单就是取屏幕某处的色号, 按下空格把颜色记录下来… 效果 思路 定时截取屏幕然后取下鼠标位置的像素颜色 1234567891011121314def catch(self): x = QCursor.pos().x() y = QCursor.pos().y() pixmap = QGuiApplication.primaryScreen().grabWindow(QApplication.desktop().winId(), x, y, 1, 1) if not pixmap.isNull(): image = pixmap.toImage() if not image.isNull(): if (image.valid(0, 0)): color = QColor(image.pixel(0, 0)) r, g, b, _ = color.getRgb() self.nowColor = color self.ui.lineEditMove.setText('(%d, %d, %d) %s' % (r, g, b, color.name().upper())) self.ui.lineEditMove.setStyleSheet('QLineEdit{border:2px solid %s;}' % (color.name())) 依赖 PyQt5 代码 https://github.com/shuoGG1239/ColorCatcher","link":"/2019/06/09/color_catcher/"},{"title":"csp插画模式转动画模式","text":"CSP的插画与动画 新建插画和新建动画是分在2个类别中, 但其实它们本质上还是一个东西(保存格式也相同) 插画模式下的图层, 可以通过一些弱绑定就可以轻松转为动画模式的胶片, 这个弱绑定的核心就是动画文件夹, 你甚至可以简单地认为图层放进动画文件夹, 就成了动画 转换步骤 动画-&gt; 动画所用新图层-&gt; 动画文件夹 将已有的图层手动拖到动画文件夹下 打开时间轴, 然后新建时间轴 展开-&gt; 轨道标签-&gt;轨道编辑-&gt;批量指定胶片 选从现有的动画胶片名称进行指定后确定; 最后就如下图, 图层已转为动画胶片","link":"/2025/01/13/csp%E6%8F%92%E7%94%BB%E6%A8%A1%E5%BC%8F%E8%BD%AC%E5%8A%A8%E7%94%BB%E6%A8%A1%E5%BC%8F/"},{"title":"csp手绘动画笔记","text":"创建动画 创建动画后确认下有没有时间轴组件, 若没有则在窗口--&gt;时间轴开启 概念 设计理念: 时间轴上的帧和胶片做绑定, 就是动画; 时间和胶片是解耦的, 仅仅是通过编辑绑定关系, 完成动画 胶片: 就是1个图层或图层组; 1帧只能绑1个胶片, 1个胶片可被多个帧绑定, 例如1, 3, 5帧绑定了胶片1, 修改胶片1后1,3,5帧的动画会同时改动 推荐胶片直接用图层组, 不然会丧失很多图层编辑能力, 所以初始动画的胶片1我们起手就是ctrl+G先转图层组再说 动画文件夹: 可理解为时间线, 主要用于解耦的. 例如眨眼动画, 一条时间线负责眼睛, 另一条负责眉毛, 当然也完全可以全放一条时间线来完成 动画时间轴界面 时间轴常用的5个操作如下图红框, 从左到右: 新建动画文件夹: 就是新建1条时间线, 例如下图有”slime”和”纸张”这2条时间线 新建动画胶片: 在当前帧上创建1张空白胶片; 本质是2个动作: 新建空胶片, 将其绑到当前帧 指定胶片: 在当前帧上绑定1张已存在的胶片; 例如下图可以有1,2两张胶片可以选 删除胶片指定: 在当前帧上解绑胶片; 仅仅是做了解绑, 胶片(图层)本身还在 启用洋葱皮: 开启后可以看到上一帧的样子, 用于参考 按住Alt拖动时间轴上的胶片可以复制绑定到其他帧的功能(图层并不会复制) 按住空格 + ctrl拖动时间轴进行缩放帧间隔 参考csp官方动画胶片教学","link":"/2024/06/06/csp%E6%89%8B%E7%BB%98%E5%8A%A8%E7%94%BB%E7%AC%94%E8%AE%B0/"},{"title":"danbooru爬图","text":"简介 最近ai炼丹嫌找炼丹素材麻烦, 就写了个按danbooru tag爬图的脚本, 没什么第三方依赖, 想用直接copy去跑就行 使用方法 把脚本里面的your_username和your_password替换成你的danbooru账号密码(账号在https://danbooru.donmai.us注册) main里面, 在tag填上要爬取的tag, save_dir为爬取的图片的保存路径 如果需要通过代理爬取, 把use_proxy置为True, 然后改下proxies变量的代理地址即可 脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120# -*- coding: utf-8 -*-import osimport urllib.parseimport requestsfrom requests.auth import HTTPBasicAuthuse_proxy = Trueheaders = { 'User-Agent': 'db/v1.0.0', 'Content-Type': 'application/json; charset=utf-8',}proxies = {&quot;http&quot;: &quot;socks5://127.0.0.1:1080&quot;, 'https': 'socks5://127.0.0.1:1080'}auth = HTTPBasicAuth('your_username', 'your_password')session = requests.session()def save_file(file_url, path): response = request_get(file_url) with open(path, 'wb') as f: f.write(response.content) f.flush()def request_get(url): if use_proxy: return session.get(url, headers=headers, proxies=proxies, auth=auth) else: return session.get(url, headers=headers, auth=auth)def get_all_danbooru_items(tag_list): &quot;&quot;&quot; :param tag_list: :return: list of danbooru item &quot;&quot;&quot; items = [] cur_page = 1 while True: page_items = get_danbooru_items(tag_list, cur_page) if len(page_items) == 0: break items.extend(page_items) cur_page += 1 return itemsdef get_danbooru_items(tag_list, page=1, limit=100): &quot;&quot;&quot; API文档 https://danbooru.donmai.us/wiki_pages/api%3Aposts :param tag_list: :param page: 从1开始 :param limit: :return: list of danbooru item &quot;&quot;&quot; clean_tag_list = list(map(lambda x: x.replace(' ', '_'), tag_list)) query = { 'tags': ' '.join(clean_tag_list), 'page': page, 'limit': limit, } posts_url = 'https://danbooru.donmai.us/posts.json?%s' % (urllib.parse.urlencode(query)) print(posts_url) resp = request_get(posts_url) return resp.json()def count_danbooru_items(tag_list): &quot;&quot;&quot; :param tag_list: :return: int &quot;&quot;&quot; clean_tag_list = list(map(lambda x: x.replace(' ', '_'), tag_list)) query = { 'tags': ' '.join(clean_tag_list), } posts_url = 'https://danbooru.donmai.us/counts/posts.json?%s' % (urllib.parse.urlencode(query)) print(posts_url) resp = request_get(posts_url) return resp.json()['counts']['posts']def download_imgs_by_tags(tags, save_dir): items = get_all_danbooru_items(tags) sub_folder_name = '_'.join(tags) folder_path = os.path.join(save_dir, sub_folder_name) if not os.path.exists(folder_path): os.mkdir(folder_path) total = len(items) cnt = 0 print(&quot;downloading&quot;, sub_folder_name, 'total:', total) for item in items: img_id, img_url = item['id'], item.get('file_url') if img_url is None: print('emtpy file_url:', item) continue img_suffix = img_url[img_url.rindex('.'):] img_file_name = '%d%s' % (img_id, img_suffix) img_file_path = os.path.join(folder_path, img_file_name) if os.path.exists(img_file_path): print(img_file_name, 'exists! pass...') continue save_file(img_url, img_file_path) cnt += 1 print('(%d/%d)%s download ok!' % (cnt, total, img_file_name)) print('all done!')# https://danbooru.donmai.us/if __name__ == '__main__': use_proxy = False save_dir = './danbooru_imgs' tag = 'mari_(blue_archive)' cnt = count_danbooru_items([tag]) print(cnt) if cnt &gt; 0: download_imgs_by_tags([tag], save_dir)","link":"/2023/08/13/danbooru%E7%88%AC%E5%9B%BE/"},{"title":"Py小玩具-简易截图","text":"简介 有时没开微信或QQ的时候想立即截个图啥的挺蛋疼的, 故自己捣鼓一个 简单干净快速, 无界面, 运行即截图 使用方式 运行easyshot.py直接开启区域截图, 截完图自动保存到桌面, 然后退出进程 截图的时候框选完区域后可以双击或Enter完成截图, 中途可以按Esc放弃截图 环境 python3 pyQt5 代码 https://github.com/shuoGG1239/EasyScreenShot","link":"/2020/05/10/easyscreenshot/"},{"title":"gh-ost源码分析","text":"简述 之前用到了gh-ost做大表改表工具, 回过来看看源码, 本篇为阅读源码的笔记 源码信息 源码版本: 源码仓库: https://github.com/github/gh-ost gh-ost原理 gh-ost 首先连接到主库上，根据 alter 语句创建幽灵表，然后作为一个”备库”连接到其中一个真正的备库上(默认设置,想连到master也行) 一边在主库上拷贝已有的数据到幽灵表，一边从备库上拉取增量数据的 binlog，然后不断的把 binlog 应用回主库 图中 cut-over 是最后一步，锁住主库的源表，等待 binlog 应用完毕，然后替换 gh-ost 表为源表 gh-ost 在执行中，会在原本的 binlog event 里面增加以下 hint 和心跳包，用来控制整个流程的进度，检测状态等 gh-ost的改表流程 检查有没有外键和触发器。 检查表的主键信息。 检查是否主库或从库，是否开启log_slave_updates，以及binlog信息 检查gho和del结尾的临时表是否存在 创建ghc结尾的表，存数据迁移的信息，以及binlog信息等 初始化stream的连接,添加binlog的监听 创建gho结尾的临时表，执行DDL在gho结尾的临时表上 开启事务，按照主键id把源表数据写入到gho结尾的表上，再提交，以及binlog apply。 lock源表，rename 表：rename 源表 to 源_del表，gho表 to 源表。(这个过程叫cut-over) 清理ghc表。 关于v1.1.6修复的时区问题 在_gho表执行sql的session和binlog读取时指定的时区不一致导致 从binlogEvent读取的时间结构体是带了时区的, 该时区是由BinlogParser.timestampStringLocation指定, 在转换成query时会用timestamp结合时区生成时间String 强调: 不管是mysql底层还是binlog中, timestamp是不带时区的, 就是4个bytes; github.com/go-mysql-org/go-mysql在时区强制指定utc, 新版本变成可配置并默认为系统时区, 所以是go-mysql没考虑兼容性导致 源码结构 /cmd包: 入口 /cmd/gh-ost/cmd.go: 入口 /base包: 相当于config, 处理配置信息和日志工具 /base/context.go: MigrationContext的定义和各种Get/Set方法, 不重要 /base/default_logger.go: 标准输出logger封装, 不重要 /base/load_map.go: 解析k1=v1,k2=v2到map, 不重要 /base/utils.go: 标准工具包, 不重要 /sql包: 相当于sql_parser, 处理sql解析的工具包 /sql/builder.go: 构建带/* gh-ost xxx.tbl */的sql /sql/encoding.go: charset定义, 不重要 /sql/parser.go: AlterTable特供parser (gh-ost没有引用其他sqlparser包, 很干净但也仅支持了alter table) /sql/types.go: Column相关结构的封装, 不重要 /mysql包: 相当于mysql相关的util包 /mysql/binlog.go: BinlogCoordinates结构(logfile,logPos), 不重要 /mysql/connection.go: mysql的ConnectionConfig结构, 不重要 /mysql/instance_key.go: InstanceKey结构(host,port), 不重要 /mysql/instance_key_map.go: 给上面的InstanceKey套了层map, 不重要 /mysql/utils.go: 不重要 /binlog包: 仅仅是对replication.BinlogSyncer的封装, 最后将replication.RowsEvent封装成BinlogEntry塞到EventsStreamer.eventsChannel里面 /binlog/binlog_dml_event.go: BinlogDMLEvent结构, 不重要 /binlog/binlog_entry.go: BinlogEntry结构, 不重要 /binlog/binlog_reader.go: BinlogReader接口定义, 不重要 /binlog/gomysql_reader.go: 基于go-mysql/replication封装了自己的binlogReader /logic包: 核心流程都在这个包 /logic/server.go: 提供接口, 用于动态设置一些运行参数和查看任务状态 (不重要) /logic/hooks.go: hook执行器. 按规定的执行程序名字, 将执行程序(如sh脚本)放入指定目录, 后面会根据事件执行这些执行程序. (不重要) /logic/streamer.go: 在上面binlog包的基础上再封装一层listener, listener处理上面提到的EventsStreamer.eventsChannel接收的BinlogEntry /logic/inspect.go: 连接slave, 获取实例的基础信息如表结构, 表大小等, 检查改表是否符合迁移条件 /logic/throttler.go: 限流器, 调用throttle()实现限流 (符合限流条件时该函数会卡住否则不卡) 根据多种条件（如HTTP,freno状态、复制延迟、系统负载等）判断是否需要进行限流 /logic/applier.go gho和ghc的处理包括cutOver, 提供实现. 调用都在Migrator ApplyDMLEventQueries(dmlEvents ): 将binlogEvent转为query, 然后在_gho表执行 /logic/migrator.go: 主流程. 上述各个模块提供的方法会在migrator中使用, 完成整个改表流程 改表流程源码 改表流程直接从/logic/migrator.go的func (this *Migrator) Migrate()开始看, 核心逻辑如下1234567891011121314151617181920212223242526272829303132333435363738394041424344func (this *Migrator) Migrate() (err error) { // 初始化binlogReader, 用于读取binlog if err := this.initiateStreaming(); err != nil { return err } // 初始化Applier, 影子表的操作基本都在applier中进行 if err := this.initiateApplier(); err != nil { return err } // 若支持instant改表则直接用instant改表完成大表改表操作 if this.migrationContext.AttemptInstantDDL { this.migrationContext.Log.Infof(&quot;Attempting to execute alter with ALGORITHM=INSTANT&quot;) if err := this.applier.AttemptInstantDDL(); err == nil { this.migrationContext.Log.Infof(&quot;Success! table %s.%s migrated instantly&quot;, sql.EscapeName(this.migrationContext.DatabaseName), sql.EscapeName(this.migrationContext.OriginalTableName)) return nil } else { this.migrationContext.Log.Infof(&quot;ALGORITHM=INSTANT not supported for this operation, proceeding with original algorithm: %s&quot;, err) } } // 抓binlogEvent, 最终在this.executeWriteFuncs消费 if err := this.addDMLEventsListener(); err != nil { return err } // 确定row copy的边界值, 其实就是通过&quot;select uk order by uk limit 1 desc/asc&quot;来获取 if err := this.applier.ReadMigrationRangeValues(); err != nil { return err } go this.executeWriteFuncs() // 消费来自this.iterateChunks的chunkCopy任务和this.addDMLEventsListener的binlogEvent go this.iterateChunks() // 生产chunk copy任务, 在self.executeWriteFuncs消费 this.consumeRowCopyComplete() // 等待row copy完成, 信号来自this.iterateChunks // cutOver: rename gho表 var retrier func(func() error, ...bool) error if err := retrier(this.cutOver); err != nil { return err } // 清理阶段: drop ghc表 if err := this.finalCleanup(); err != nil { return nil } return nil}","link":"/2024/05/22/gh-ost%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"go module笔记与源码分析","text":"简介 零零散散的关于go module的笔记, 通过源码来理解这些点 go mod源码位置 仓库位置: https://github.com/golang/go/tree/go1.16.6/src/cmd/go/internal/modcmd 相对位置: cmd/go/internal/modcmd cmd/go/internal/modfetch cmd/go/internal/modget cmd/go/internal/modload 关于版本选择 同一个大版本取最大版本号 main依赖了(A1.1.0, B1.2.0), B1.2.0依赖了(A1.0.0), 则最终构建阶段大家都用A1.1.0编译 版本从信息从/@v/list获取, 如果为空则取走@latest获取最新版本号, 在拿最新版本号取拉包 官方版本规则 核心逻辑 1234567891011121314151617181920func (p *proxyRepo) Versions(prefix string) ([]string, error) { data, err := p.getBytes(&quot;@v/list&quot;) // 获取list文件内容 if err != nil { return nil, p.versionError(&quot;&quot;, err) } var list []string for _, line := range strings.Split(string(data), &quot;\\n&quot;) { f := strings.Fields(line) if len(f) &gt;= 1 &amp;&amp; semver.IsValid(f[0]) &amp;&amp; strings.HasPrefix(f[0], prefix) &amp;&amp; !IsPseudoVersion(f[0]) { list = append(list, f[0]) } } SortVersions(list) // 对list里面的版本进行排序 return list, nil}// IsPseudoVersion reports whether v is a pseudo-version.func IsPseudoVersion(v string) bool { return strings.Count(v, &quot;-&quot;) &gt;= 2 &amp;&amp; semver.IsValid(v) &amp;&amp; pseudoVersionRE.MatchString(v)} go private private时不会走proxy和checksumDB1234567// go/internal/modfetch/sumdb.gofunc useSumDB(mod module.Version) bool { return cfg.GOSUMDB != &quot;off&quot; &amp;&amp; !module.MatchPrefixPatterns(cfg.GONOSUMDB, mod.Path) // cfg.GONOSUMDB里面包含了GOPRIVATE}// cmd/go/internal/cfg/cfg.goGONOSUMDB = envOr(&quot;GONOSUMDB&quot;, GOPRIVATE) @latest v0.0.5 &gt; v0.0.5-alpha &gt; v0.0.4123456789101112131415161718192021222324// 版本比较的源码: src/cmd/vendor/golang.org/x/mod/semver/semver.gofunc Compare(v, w string) int { pv, ok1 := parse(v) pw, ok2 := parse(w) if !ok1 &amp;&amp; !ok2 { return 0 } if !ok1 { return -1 } if !ok2 { return +1 } if c := compareInt(pv.major, pw.major); c != 0 { return c } if c := compareInt(pv.minor, pw.minor); c != 0 { return c } if c := compareInt(pv.patch, pw.patch); c != 0 { return c } return comparePrerelease(pv.prerelease, pw.prerelease)} indirect main依赖了A, 但是A依赖了B但go.mod里没有require B, 则A的go.mod会自动加上B indirect 此时main的go.mod强行require上B, 则B indirect将消失 exclude 跳过某个版本 (之后一般gomod会自动使用比跳过版本更高的版本) 例如: “require github.com/google/uuid v1.1.0”, 最后tidy后require里自动变成”github.com/google/uuid v1.1.1” 跟replace一样, 仅main module时生效 不大实用, 一般直接用replace即可 url GET $base/$module/@v/list https://goproxy.io/github.com/gin-gonic/gin/@v/v1.4.0.mod https://goproxy.io/github.com/gin-gonic/gin/@v/ https://goproxy.io/github.com/gin-gonic/gin/@v/list //latest是根据这个list拉取最大的版本 https://goproxy.io/github.com/gin-gonic/gin/@latest go.sum https://sum.golang.org/lookup/golang.org/x/sync@v0.0.0-20181221193216-37e7f081c4d4 checksum源码: go/src搜索 checkModSum(mod, hash) checksumDB源码: go/src搜索 checkSumDB(mod, h) commit version go get github.com/pingcap/parser@659821e go get github.com/pingcap/parser@latest go get github.com/pingcap/parser@feature-lstest","link":"/2021/06/09/go%20module%E7%AC%94%E8%AE%B0%E4%B8%8E%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"golang&#x2F;net包与epoll","text":"net包与epoll linux下go的网络包底层如tcp也是采用epoll来实现, 你可以从Accept方法一路追下去, 追到尽头你会看到internal/poll/fd_poll_runtime.go里面这些在runtime实现的方法:123456789func runtime_pollServerInit()func runtime_pollOpen(fd uintptr) (uintptr, int)func runtime_pollClose(ctx uintptr)func runtime_pollWait(ctx uintptr, mode int) intfunc runtime_pollWaitCanceled(ctx uintptr, mode int) intfunc runtime_pollReset(ctx uintptr, mode int) intfunc runtime_pollSetDeadline(ctx uintptr, d int64, mode int)func runtime_pollUnblock(ctx uintptr)func runtime_isPollServerDescriptor(fd uintptr) bool 此时到src/runtime/netpoll.go就能看到上述这些方法的实现, 再往下追下去就可以看到各个平台的具体实现了, 如netpoll_epoll.go netpoll_kqueue.go netpoll_windows.go, 看到netpoll_epoll.go里面的epollcreate, epollctl, epollwait了吧, 多么熟悉的几个函数! goroutine与epoll 虽然net包底层用epoll实现了, 但是实际我们在用tcp还是开goroutine来serve net包就是推荐我们用goroutine来玩tcp, 应对大部分场景妥妥的 面对比较变态的场景并发量贼高时, goroutine尽管只有消耗2k~8k的栈空间, 连接一多还是耗不起, 此时就只能用一些黑魔法来使用epoll了 具体怎么玩可以参照 https://github.com/mailru/easygo","link":"/2020/06/07/go_and_epoll/"},{"title":"go源码阅读:database&#x2F;sql包","text":"简介 database/sql最主要还是实现了连接池逻辑 go源码版本: v1.16 源码仓库: https://github.com/golang/go/tree/go1.16.6/src/database/sql sql.DB的一些关键逻辑 Open会返回DB对象并开启一条connectionOpener线程 connectionOpener主要处理下面提到的”当前连接数大于maxOpen会陷入等待”的连接资源请求 DB的核心方法: conn(ctx context.Context, strategy connReuseStrategy) (*driverConn, error) 优先返回连接池里的连接 当前连接数大于maxOpen会陷入等待, 等待取决于ctx, 也即由调用方控制 其余情况则返回一个新连接 DB的连接池: freeConn []*driverConn DB的核心方法: putConnDBLocked(conn, err) bool 如果当前连接数大于maxOpen则直接返回false, 上层看到false则直接关闭该连接conn 优先满足正在等待连接资源请求的(connRequests是一个map,可以看出请求连接资源并无优先级的说法) 如果MaxIdleConns &lt; len(freeConn), 即连接池满了, 则直接返回false, 上层看到false则直接关闭该连接conn 否则丢到连接池freeConn中 清理线程(connectionCleaner): SetConnMaxLifetime,SetConnMaxIdleTime时才会去起唯一的一条清理线程 清理线程定期清理连接池freeConn的连接, 根据maxLifetime和createAt清理, 也根据maxIdleTime和returnedAt清理 有趣的是清理线程并不理会MaxOpen和MaxIdleConns是多少, 只关注MaxLifetime和MaxIdleTime, 反正过期了就清理 sql执行方法如Query,Exec,Ping等, 都会先去调conn获取连接, 再用其连接执行sql, 最后将putConnDBLocked(conn), (query是等rows全部scan完close再putConnDBLocked(conn)) 关于resetSession最终的去处, 总的来说就是reset了个寂寞, 最终居然只是conn.SetReadDeadline(time.Time{})? 123456789101112131415161718192021222324252627282930313233343536373839// go-sql-driver/mysql/connection.go里面的// Write packet buffer 'data'func (mc *mysqlConn) writePacket(data []byte) error { pktLen := len(data) - 4 if pktLen &gt; mc.maxAllowedPacket { return ErrPktTooLarge } // Perform a stale connection check. We only perform this check for // the first query on a connection that has been checked out of the // connection pool: a fresh connection from the pool is more likely // to be stale, and it has not performed any previous writes that // could cause data corruption, so it's safe to return ErrBadConn // if the check fails. if mc.reset { mc.reset = false conn := mc.netConn if mc.rawConn != nil { conn = mc.rawConn } var err error // If this connection has a ReadTimeout which we've been setting on // reads, reset it to its default value before we attempt a non-blocking // read, otherwise the scheduler will just time us out before we can read if mc.cfg.ReadTimeout != 0 { err = conn.SetReadDeadline(time.Time{}) } if err == nil &amp;&amp; mc.cfg.CheckConnLiveness { err = connCheck(conn) } if err != nil { errLog.Print(&quot;closing bad idle connection: &quot;, err) mc.Close() return driver.ErrBadConn } } ... ...} 关于statement 关于query带?的sql的逻辑: func (db *DB) queryDC: 对于带了args的query, 且InterpolateParams=false, 则driver会返回driver.ErrSkip, 此时会走到si, err = ctxDriverPrepare(ctx, dc.ci, query), 做完prepare与ctxDriverStmtQuery, 将si放到Rows里面, Rows读完Close后si会跟着Close","link":"/2022/03/27/go%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB_database-sql%E5%8C%85/"},{"title":"godot学习笔记-01 FoxyVsSlime","text":"简介 本篇是制作FoxyVsSlime这个demo的学习笔记 FoxyVsSlime的godot工程: https://github.com/shuoGG1239/godot_play/tree/main/foxy_vs_slime 基础界面及操作 官方Manual: 2D界面 场景与节点 下图1和图2都是给main节点添加子节点 2D场景的对象编辑 如图, QWES: 选择,移动,旋转,缩放 文件系统(资源管理) 资源直接从外面拖进来就行 检查器 下图是从检查器查看和编辑main节点的属性 脚本 脚本是绑在节点上的, 节点实例化后会执行脚本上的各种handler如_ready(),_process(float)等等 @export可以将变量暴露到节点的检查器进行编辑, 例如绑定其他场景类或节点实例或资源等等 脚本可以直接使用被绑节点实例的field, 不需要加this或self之类的, 查看修改都行, 例如main节点是Node2D类型, 有position属性, 可以直接position=xxx直接修改main节点的位置 脚本对应节点上的子节点可以直接$节点id获取其节点 看下另外一个节点enemy, 是Area2D节点所以有碰撞信号如_area_entered, 红是信号, 绿是信号接受函数, 类似Qt的信号与槽 调试, 按F5运行游戏调试 运行期间可以在场景/远程时实查看运行时节点 关于position position变量是相对父节的位置, 全局位置则是global_position 节点默认的初始position就是(0,0), 你可以看下Tranform的position或者在onready打印下看看 例如game和player是父子关系, player一开始放置在game的(111,222)位置, 此时如果player的position从(0,0)变为(100,300), 他则在game的位置就变成(211,522)了 FoxyVsSlime工程用到的类 官方Class Manual: Node2d 主场景: Node2D 相机: Camera2D 文字容器: CanvasLayer 文字: Label 背景: Node2D (Node2D可以当组来使用) 背景图: Sprite2D 边界: StaticBody2D 物理碰撞区: CollisionShape2D 定时器: Timer BGM: AudioStreamPlayer 玩家foxy: CharacterBody2D (相比Sprite2D,Node2D多了velocity系列属性, 方便控制移动) foxy动画雪碧图: AnimatedSprite2D foxy物理碰撞区: CollisionShape2D foxy声音: AudioStreamPlayer 定时器: Timer 敌人slime: Area2D (能检测其他带物理碰撞区的节点的碰撞信号area_entered,body_entered) slime动画雪碧图: AnimatedSprite2D slime物理碰撞区: CollisionShape2D slime声音: AudioStreamPlayer 玩家输入 Input: 单例 velocity = Input.get_vector(“left”, “right”, “up”, “down”) 其他常用类或函数 PackedScene: 可以认为是Scene类的容器, 用instantiate()实例化 get_tree(): 返回包含该节点的 SceneTree, 是Node的方法 get_tree().current_scene: 主场景节点(即root的子节点main) await get_tree().create_timer(1).timeout: 同步等待1s queue_free: 删除本节点, 是Node的方法","link":"/2025/02/22/godot%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-01%20FoxyVsSlime/"},{"title":"grpc的goAway和keepalive","text":"简介 虽是Http2的东西, 但也可以通过grpc的源码来侧面加深下理解 GoAway 告诉客户端, 服务端准备关闭了, 本连接不要发新请求过来了 (发一半的请求还是会处理完的) 当client收到这个包之后就会主动关闭连接。下次需要发送数据时，就会重新建立连接 流程: client收到Goaway -&gt; client主动关闭http2连接 -&gt; channel变为IDLE -&gt; 用户发起新请求 -&gt; 创建新连接 -&gt; channel变为CONNECTING 另外GoAway是实现优雅关闭的基石, 因为是client主动关闭(不同于服务端关闭), 可以避免很多无效的请求 源码: google.golang.org/grpc/clientconn.go: errConnDrain (drain是接收到goaway后的连接状态) google.golang.org/grpc/internal/transport/http2_client.go: func (t *http2Client) Close(err error) google.golang.org/grpc/internal/transport/http2_client.go: func (t *http2Client) handleGoAway(f *http2.GoAwayFrame) 里面的 t.onClose(t.goAwayReason)的onClose在”grpc/clientconn.go/addrConn createTransport”里面定义的: 123456789101112131415161718192021222324252627282930313233343536373839func (ac *addrConn) createTransport(ctx context.Context, addr resolver.Address, copts transport.ConnectOptions, connectDeadline time.Time) error { addr.ServerName = ac.cc.getServerName(addr) hctx, hcancel := context.WithCancel(ctx) // hctx会深入到http2Client,见newHTTP2Client的信号&quot;&lt;-newClientCtx.Done()&quot; // 客户端收到goAway的反馈: 关闭连接 + state变IDLE onClose := func(r transport.GoAwayReason) { ac.mu.Lock() defer ac.mu.Unlock() // adjust params based on GoAwayReason ac.adjustParams(r) if ctx.Err() != nil { // Already shut down or connection attempt canceled. tearDown() or // updateAddrs() already cleared the transport and canceled hctx // via ac.ctx, and we expected this connection to be closed, so do // nothing here. return } hcancel() // 关闭http2连接! if ac.transport == nil { // We're still connecting to this address, which could error. Do // not update the connectivity state or resolve; these will happen // at the end of the tryAllAddrs connection loop in the event of an // error. return } ac.transport = nil // Refresh the name resolver on any connection loss. ac.cc.resolveNow(resolver.ResolveNowOptions{}) // Always go idle and wait for the LB policy to initiate a new // connection attempt. ac.updateConnectivityState(connectivity.Idle, nil) } connectCtx, cancel := context.WithDeadline(ctx, connectDeadline) defer cancel() copts.ChannelzParentID = ac.channelzID newTr, err := transport.NewClientTransport(connectCtx, ac.cc.ctx, addr, copts, onClose) ... ...} 关于keepalive keepalive在server端是默认开启的, client端默认关闭 keepalive.ServerParameters.MaxConnectionIdle: 如果一个client空闲超过15s, 发送一个 GOAWAY grpc-keepalive-guide RPC客户端长连接机制实现及keepalive分析 源码: 结构: google.golang.org/grpc/internal/transport/http2_server.go: http2Server.kp 结构: google.golang.org/grpc/internal/transport/http2_client.go: http2Client.kp 实现: google.golang.org/grpc/internal/transport/http2_server.go: func (t *http2Server) keepalive() 实现: google.golang.org/grpc/internal/transport/http2_client.go: func (t *http2Client) keepalive()","link":"/2023/08/02/grpc%E7%9A%84goAway%E5%92%8Ckeepalive/"},{"title":"go源码阅读:net&#x2F;http的Transport","text":"简介 http.Transport这样的高频使用模块, 源码肯定得看看 go源码版本: v1.16 源码仓库: https://github.com/golang/go/blob/go1.16.6/src/net/http/transport.go http.Transport的关键逻辑 Transport是RoundTripper接口的实现: func RoundTrip(req *Request) (*Response, error) Transport对外只提供方法: func RoundTrip(req *Request) (*Response, error) Transport的内部对象idleLRU connLRU写得不错, 简单实现了LRU http.Client就是在Tranport上简单封装一层 Transport就是一个连接池, 池子里面放着persistConn连接对象(idleConn map[connectMethodKey][]*persistConn) queueForIdleConn: 根据请求的connectMethodKey从t.idleConn获取一个[]*persistConn切片， 并从切片中，根据算法获取一个有效的空闲连接。如果未获取到空闲连接，则将wantConn结构体放入t.idleConnWait[w.key]等待队列 连接释放逻辑在 (t *Transport) tryPutIdleConn(pconn *persistConn) 哪些情况才回去调 tryPutIdleConn: 大部分的异常情况 responseBody read完: 代码详细见 case bodyEOF := &lt;-waitForBodyRead dialConnFor: 会调用t.dialConn获取一个真正的*persistConn。并将这个连接传递给w, 如果w已经获取到了连接，则会传递失败，此时调用t.putOrCloseIdleConn将连接放回空闲连接池。 dialConn: 调用t.dial(ctx, “tcp”, cm.addr())创建TCP连接并将其赋予刚new的persistConn 如果是https的请求，则对请求建立安全的tls传输通道 为persistConn创建读写buffer，如果用户没有自定义读写buffer的大小，读写bufffer的大小默认为4096 执行go pconn.readLoop()和go pconn.writeLoop()开启读写循环然后返回连接 dialConn里面这段代码是开启http2的核心 12345678910111213// 当client和server都支持http2时，s.NegotiatedProtocol的值为&quot;h2&quot;且s.NegotiatedProtocolIsMutual的值为true// pconn.tlsState是在pconn.addTLS中附加的// 所以是否支持http2是在tls握手时得知的, 因此http2时强制要求httpsif s := pconn.tlsState; s != nil &amp;&amp; s.NegotiatedProtocolIsMutual &amp;&amp; s.NegotiatedProtocol != &quot;&quot; { if next, ok := t.TLSNextProto[s.NegotiatedProtocol]; ok { alt := next(cm.targetAddr, pconn.conn.(*tls.Conn)) if e, ok := alt.(erringRoundTripper); ok { // pconn.conn was closed by next (http2configureTransports.upgradeFn). return nil, e.RoundTripErr() } return &amp;persistConn{t: t, cacheKey: pconn.cacheKey, alt: alt}, nil }} 关于persistConn persistConn是在给”conn net.Conn”包一层 readLoop: for循环, 不停等待新的requestAndChan(由roundTrip发起), response塞回requestAndChan(rc.ch &lt;- responseAndError{res: resp}); 确认读完之后调tryPutIdleConn放回Transport的连接池 只有当调用方完整的读取了响应，该连接才能够被复用。 因此在http1.1中，1个连接上的请求，只有等前一个请求处理完之后才能继续下一个请求。 如果前面的请求处理较慢， 则后面的请求必须等待， 这就是http1.1中的线头阻塞 所以就算你不关心response的body, 也必须把body读完以保持连接的复用, 可以如下处理 io.CopyN(ioutil.Discard, resp.Body, 2 &lt;&lt; 10) resp.Body.Close() writeLoop: for循环, 不停等待新的writeRequest, 写完发信号给pc.writeErrCh和wr.ch, 出错了会关闭该persistConn并结束writeLoop的循环, 否则继续等待新的writeRequest roundTrip: 在for循环里面等待本次roundTrip的各种信号, 如来自writeLoop的写完成信号, pcClosed, cancelChan, response结果信号等, 收到response或者出错则结束循环. 只有在出错的时候才会pc.close; roundTrip里面没有处理连接池的逻辑 关于http.Response http/response.go: 核心函数 func ReadResponse(r *bufio.Reader, req *Request) (*Response, error) 关于HeaderTimeout, 源码可看出是读完所有header才算header读结束了(blank line), HeaderTimeout是header读结束的timeout response.wroteHeader: writeHeader里面会将wroteHeader置为true func (cw *chunkWriter) writeHeader(p []byte)的最后一行是: w.conn.bufw.Write(crlf) response的flush本质就是writeHeader(nil), 也就是最后也会w.conn.bufw.Write(crlf) 关于http.DefaultTransport123456789101112var DefaultTransport RoundTripper = &amp;Transport{ Proxy: ProxyFromEnvironment, // &quot;HTTP_PROXY&quot;,&quot;http_proxy&quot;,&quot;HTTPS_PROXY&quot;,&quot;https_proxy&quot;,&quot;NO_PROXY&quot;,&quot;no_proxy&quot; DialContext: (&amp;net.Dialer{ Timeout: 30 * time.Second, KeepAlive: 30 * time.Second, }).DialContext, ForceAttemptHTTP2: true, MaxIdleConns: 100, IdleConnTimeout: 90 * time.Second, TLSHandshakeTimeout: 10 * time.Second, ExpectContinueTimeout: 1 * time.Second,}","link":"/2022/03/20/go%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB_net-http-transport/"},{"title":"Py小玩具-简单好用的OCR","text":"效果如下 截图识别 图片识别 代码https://github.com/shuoGG1239/Image2Text 介绍 本来一开始是用谷歌的tesseract, 也搞来了据说比较靠谱的trainedData, 但实际识别准确率实在不行, 于是放弃了, 不过这种好处就是可以离线识图, 只要能搞到靠谱好用的trainedData肯定是比在线识图要好啦 这个小工具最终是用了百度AI的OCR接口, 识别率不错, 特别是中文 百度AI的普通文字识别的接口一天最多只能免费调用500次/账号, 也不保证并发量, 想变强就充钱吧 识图的核心代码在上面代码仓库的ocr_util.py, 要注意的是API_KEY和SECRET_KEY的这两个变量要填上自己的key, 这俩key获取直接得到百度AI去拿, 直接登陆控制台–&gt;鼠标移到右上角头像上–&gt;安全认证–&gt; AccessKey, 当然也可以直接用我的Key, 我都直接丢代码里, 但尽量用自己的吧, 说不定某天我不小心把AccessKey删了呢 :P Gui用的是PyQt5, 只支持python3, 所以python2.7的同学可以无视Gui部分…","link":"/2018/07/21/image2text/"},{"title":"go源码阅读:TLS handshake","text":"tls handshake tls/handshake_server.go: serverHandshakeState tls/common.go: Conn.PeerCertificates tls/handshake_client.go: doFullHandshake: handshake读取到的certificateMsg最终会解析后赋值给peerCertificates rfc5246-Handshake Protocol tls/handshake_client.go: clientHandshake makeClientHello loadSession : 会生成sessionID writeRecord : 将ClientHello发送给server readHandshake: 等server回复 tls/handshake_server.go: serverHandshake readClientHello processClientHello pickCipherSuite doFullHandshake establishKeys readFinished sendSessionTicket sendFinished tls.Conn: handlePostHandshakeMessage/handleKeyUpdate: KeyUpdate指的就是tls最后的那个对称密钥(变量名叫trafficSecret) tls/conn.go tls.Conn实现了net.Conn接口, 在Write和Read包裹了一层handShake, 后面的读写也是带了加密的(readRecordOrCCS) net/conn.go12345678910type Conn interface { Read(b []byte) (n int, err error) Write(b []byte) (n int, err error) Close() error LocalAddr() Addr RemoteAddr() Addr SetDeadline(t time.Time) error SetReadDeadline(t time.Time) error SetWriteDeadline(t time.Time) error}","link":"/2023/04/25/go%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB_tls-handshake/"},{"title":"Py小玩具-罗马转假名","text":"罗马音转日文假名 罗马音转假名(平假片假), 简单好用… 属于个人需求, 偶尔要敲一段假名, (日文输入法太笨重污染桌面干净的右下角) 算是用的比较频繁的一个自制玩具 效果 使用 无需联网 除了长音符用了yy, 其余输入规则和主流的日文输入法差不多 例子1234567ka かwa わi いlo ぉ (小お)le ぇ (小え)nn んyy ー 实现 纯PyQt5开发 代码 https://github.com/shuoGG1239/JapInput","link":"/2019/06/09/japinput/"},{"title":"live2d学习笔记","text":"官方文档 手册: https://docs.live2d.com/zh-CHS/cubism-editor-manual/top/ 关键字: (有忘记的功能就在手册搜关键字查看吧) 辅助线: 其实就是参考线 live2d通用参数 部件维护 若有需求变更, 如原画增加部件或修改部件, 上述的变动图层均要以新图层处理 (copy and write), 然后新psd直接拖live2d进行替换即可, 新图层会被自动置顶, 然后当作新部件进行替换或新增工作 布点(网格) 分为手动布点和自动布点, 点击如图工具进入布点模式 退出布点模式后, 若拖动网点会带动底下的部件形变, 以下工具可以不同方式拖动网点引起形变 蒙版 被蒙版部件在剪贴ID填入蒙版部件id即可 关键点(关键帧) 部件和关键点是多对多的关系, 所以调整部件动画状态的时候, 记得要先创建关键点! 如果有自信的可以多选所有所需部件然后创建关键点 呼吸参数是唯一一个自循环的参数 参数速调(偷懒) 针对部件绑反或者绑错参数情况, 提供了解决方法如图红框里的反转,调整 ; 记得先选中部件才能进行反转 调整 ! 复制并反转 对称的部件可以用动作反转实现复制并反转, 先选中被复制的参数点位, 然后再点动作反转 对称轴为变形器的中轴 软骨骼(路径工具) 软骨骼主要用于快速对条形部件进行变形, 因为单个单个网点变形实在太慢了! 可以理解为柔性的骨骼(普通骨骼为一段一段的, 软骨骼是条曲线) 软骨骼不是变形器, 所以不会出现在左下角的变形器列表中 先点选部件再进行软骨骼编辑! 如果要删除整个软骨则选中软骨后点左边工具细节栏的删除按钮 软骨骼不属于变形器, 所以不会显示到界面左下角的变形器中 路径蒙皮(软骨骼蒙皮) 实现: 软骨骼创建好后–&gt;建模–&gt;蒙皮–&gt;变形路径进行蒙皮 本质: 根据路径创建对应的多个骨骼(旋转变形器)并进行蒙皮, 并自动创建好对应的参数; 所以本质就是一个快捷操作, 你可以通过创建多段骨骼+蒙皮+新建参数+绑定参数来完成同样的效果 用途: 适合配合物理摆锤快速实现条状部件的物理效果如长发摆动, 丝带飘动, 尾巴翘动 等等 实例: 下图是实现长发物理摆动的例子, 是路径蒙皮+多段物理的经典配合 旋转变形器(骨骼) 简介: 本质就是骨骼, 基本是用来控制部件位移和旋转的, 虽然它也有缩放和透明度的能力, 但一般不用 (而是由弯曲变形器来完成) 骨骼快捷编辑: 按住ctrl拖动骨骼旋心或尖端实现平移和旋转; 按住alt拖动骨骼尖端实现骨骼长度拉伸 骨骼最常使用的区块如图的红框所示: 骨骼蒙皮 简介: 骨骼蒙皮不常使用, 它的大部分工作被弯曲变形器取代了 作用: 由于创建骨骼后, 仅仅是部件与骨骼关联起来, 部件网格与骨骼并没有关联起来, 蒙皮就是用来关联 创建: 按住ctrl后选择1个部件及2个以上骨骼, 然后建模-蒙皮-蒙皮 表现: 创建蒙皮后会自动新增对应的蒙皮部件, 它们每个布点产生了权重参数, 即和骨骼产生了关联 弯曲变形器 简介: 用于控制部件的变形, 透明度, 缩放, 工程上不同的部件属性由不同的弯曲变形器独立控制 快捷编辑: 按住ctrl拖动弯曲变形器实现平移 对于对称部件外层的弯曲变形器, 一定要记得保证变形器的对称! (为了方便复制反转) 弯曲变形器的常用区块如图所似: 实际工程上旋转变形器和弯曲变形器经常嵌套使用 物理模拟 物理模拟本质也是新增一种A到B的绑定, 但主界面上看不到, 需要进物理模拟界面才能查看和管理该绑定 新建: 无需先选中什么, 直接建模-&gt;打开物理/场景混合设定进入物理模拟界面, 然后追加一个组 物理模拟界面不要误按空格, 会disable掉物理模拟, 若遇到了再按一次空格恢复 我们以头部左右摇摆带动头发摇摆为例子来展示物理模拟: 例子会用到的参数如下图所示, 简单讲就是角度Z控制头摆, 摇动 前发单独控制前发摆 期望的工作链路为: 输入参数(角度Z) --&gt; 输出参数(摇动前发) --&gt; 弯曲变形器hairM --&gt; 前发 关于输入 在输入设定进行编辑 头部左右摇摆为参数角度Z , 所以在输入设定里面, 留一个角度Z的输入即可, 如果没有则追加一个角度Z的输入, 因为输入参数只有1个, 所以影响度设为100 关于输出 在输出设定进行编辑 由于是头摇摆来带动头发运动, 我们把输出参数设置为摇动 前发 最大输出力控制在150~200为优? 存疑 果冻眼 实现原理: XY双弯曲变形器嵌套+2个参数xy+2段物理摆锤(其实1段也能实现但效果稍逊), 这2个弯曲变形器, 1个负责x轴的拉伸收缩且绑在参数x, 1个负责y轴的拉伸收缩且绑在参数y, 他们的嵌套顺序没所谓 实例: 如下图 瞳孔游离(跟踪) 用2个参数XY+2个弯曲变形(仅控制位移)即可实现 九轴头部 九轴一般指角度X和角度Y2个参数分别和各大部件的变形器交织而成 (每个变形器绑好9个状态) 如图例子为脸做九轴, 变形器face_9d绑在角度X和角度Y参数上, 在5个状态上做好透视形变调整 5个状态做好后记得四角形合成, 在参数栏的右上角菜单里 四角形合成本质是软件帮忙计算其他关键点的状态(4个状态), 所以9轴是5+4也是3x3 四角形合成后的那4个状态还是需要手动调整, 自动生成的效果一般不大行 需做九轴的部件很多, 对应需要很多变形器, 如脸9d变形器,眼睛9d变形器, 前发9d变形器,后发9d变形器,鼻子9d变形器, 腮红9d变形器, 嘴巴9d变形器 等等, 变形器x9就是九轴的工作总量 按键表情 由按键触发而非动捕触发的表情, 其实有点像动画 一种特殊表情一般由1个自定义参数控制 控制脚本: set_special_pose_param myGirl ‘Param123’ 0 1 1 口型 本质就是做好3x2种状态帧, 即开闭和喜平悲的排列组合6种状态 (变形参也可以自行加关键点例如喜怒平悲) 嘴变形和嘴张开和闭合是会进行自动四角合成的, 是属于系统级参数了 嘴巴各参数状态参考: (可以仅关注红框的6状态) 动画制作 动画的一些工作其实可以直接由参数直接实现, 那什么场景适合动画? 无需复原的变化. 参数是变完后须复原, 动画可以实现一去不复返 动画和面捕是互斥的, 也就是播放动画时, 面捕参数的参数变动是失效的 制作步骤: 切换到Animation模式 创建新场景(左下角4小图标的第1个) 将模型拖入空白场景界面中(模型在左上角的项目那里) 展开live2d参数, 给需要动的参数打初始帧(00:00处) 初始帧确认打齐之后, 可以把其他不需要的参数隐藏, 不然参数找死你 (隐藏按钮在参数框内的循环和速度右边的下拉菜单的”隐藏未选择的属性”) 拉到某个时间点, 调整所需live2d参数, 会自动打帧. 如果需要手动打针, 就在时间线中右键选插入关键帧即可 动画最后最好所有参数都打一个结束帧, 参数和初始帧一样(这步其实可以在第4步一起先做了) 所有动画做好后, 如果模型带物理, 则要进行物理烘焙: 动画 -&gt; 轨 -&gt; 物理烘焙生成动画, 此时物理参数会自动生成关键帧, 你可以调整它们但一般没必要 做好动画, 文件-保存, 格式为.can3 做好动画, 文件-导出运作档, 导出格式为.motion3.json, 如果是循环动画, 命名为IDLE.motion3.json 控制脚本: set_special_action_anime 模型名 ‘动画名’ 控制id 循环动画 所谓循环动画的概念只是来自面捕软件, 对于Live2d只是一个普通动画 循环动画可以用于一些场景道具, 例如光环循环旋转之类 导出动画文件时, 文件名必须为IDLE.motion3.json 为了方便制作循环动画, 绑参数时可以做成循环参数, 如图:","link":"/2024/11/28/live2d%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"llOnebot实现QQ机器人","text":"QQ机器人的近乎完美方案 之前捣鼓qqbot结果让我非常失望, 各种功能限制, onebot这玩意就靠谱多了 onebot缺点仅仅是平台限定windows 部署 安装QQNT: 安装包地址 在安装目录下找到resources\\app\\app_launcher, 到app_launcher目录下创建文件llob.js, 然后写入一句require(String.raw`./LiteLoaderQQNT`) 在安装目录下找到resources\\app\\app_launcher\\package.json, 将json里面的main对应的值改为./app_launcher/llob.js 强调: 上面个resources文件不是和QQ.exe同目录下那个, 而是versions的子文件夹 下载LiteLoaderQQNT.zip: 下载地址 将解压出来的整个文件夹LiteLoaderQQNT复制到第1步的llob.js相同目录下 在LiteLoaderQQNT文件夹内创建一个plugins文件夹 下载LLOneBot.zip: 下载地址 解压后将llonebot的文件夹放在上面创建的plugins文件夹里 下载dbghelp_x64.dll: 下载地址 下载完后重命名为dbghelp.dll然后放到和QQ.exe同目录(就是第1步安装的那个QQ) 此时打开第1步装的QQ, 上号, 在设置里面能看到LLOneBot就说明部署ok了 机器人发消息 上面部署完之后就可以测试下了, 发消息的测试脚本如下: 1234567891011121314151617181920212223242526272829303132333435363738import jsonimport requestsheaders = { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36', 'Accept': 'application/json, text/plain, */*', 'Upgrade-Insecure-Requests': '1', 'Content-type': 'application/json', 'Sec-Ch-Ua': '&quot;Not_A Brand&quot;;v=&quot;8&quot;, &quot;Chromium&quot;;v=&quot;120&quot;, &quot;Google Chrome&quot;;v=&quot;120&quot;', 'Sec-Ch-Ua-Mobile': '?0', 'Sec-Ch-Ua-Platform': 'Windows',}class OneBotApi(object): def __init__(self): self.addr = 'http://127.0.0.1:3000' def send_text_to_group(self, group_id: int, text: str): req = { &quot;group_id&quot;: group_id, &quot;message_type&quot;: &quot;private&quot;, &quot;message&quot;: [ { &quot;type&quot;: &quot;text&quot;, &quot;data&quot;: { &quot;text&quot;: text } } ] } payload = json.dumps(req) resp = requests.post('%s/send_group_msg' % self.addr, data=payload, headers=headers) print(resp.text)cli = OneBotApi()your_group_id = 1145144444 # 这里填测试用的QQ群号cli.send_text_to_group(your_group_id, 'hello') 其他功能 直接看LLOneBot的官方文档即可, 非常全: LLOneBot 参考资料 LLOnebot教程","link":"/2024/10/24/llOnebot%E5%AE%9E%E7%8E%B0QQ%E6%9C%BA%E5%99%A8%E4%BA%BA/"},{"title":"markdown锚点跳转的坑","text":"背景 写markdown有这样的需求: 点击某个词跳转到markdown文章的某个位置(某个锚点), 但是写完发现有些点了跳不过去 原因就是跳转锚点的格式没写对, 格式见下面 锚点title需要注意的格式 必须全小写 空格用’-‘代替 ‘_’ ‘()’需要去掉 错误例子123[点我跳转1](/shuogg/article.html#如何取一个好的ID) [点我跳转2](/shuogg/article.html#game system搭建)[点我跳转3](/shuogg/article.html#game_system搭建) 正确例子123[点我跳转1](/shuogg/article.html#如何取一个好的id) [点我跳转2](/shuogg/article.html#game-system搭建)[点我跳转3](/shuogg/article.html#gamesystem搭建)","link":"/2019/11/13/markdown_note/"},{"title":"markdown数学公式","text":"一. Markdown公式基础关键字 $ 单行公式 $ $$ 多行公式 $$ \\\\ 公式内换行符 \\! 跟随 \\, 小空格 \\; 中空格 \\ 大空格(约1字符) \\quad 巨大空格(约2字符) \\qquad 超巨大空格(约4字符) _ 下标 ^上标 二. 基础符号 预览$$f(x) \\x \\pm y \\x \\times y \\x \\div y \\x \\cdot y \\x^y \\x_i \\x_{i+1} \\x^i_j \\\\dfrac{x}{y} \\\\sqrt{x} \\x \\gt y \\x \\lt y \\x \\ge y \\x \\le y \\\\cdots \\\\infty \\\\sin \\\\cos \\\\tan \\\\cot \\\\vec{x} \\\\sum_{x}^{y} \\\\prod_{x}^{y} \\\\lim_{x} \\$$ 对应的markdown123456789101112131415161718192021222324252627$$f(x) \\\\x \\pm y \\\\x \\times y \\\\x \\div y \\\\x \\cdot y \\\\x^y \\\\x_i \\\\x_{i+1} \\\\x^i_j \\\\\\dfrac{x}{y} \\\\\\sqrt{x} \\\\x \\gt y \\\\x \\lt y \\\\x \\ge y \\\\x \\le y \\\\\\cdots \\\\\\infty \\\\\\sin \\\\\\cos \\\\\\tan \\\\\\cot \\\\\\vec{x} \\\\\\sum_{x}^{y} \\\\\\prod_{x}^{y} \\\\\\lim_{x} \\\\$$ 三. 希腊字符 预览$$\\alpha \\beta \\gamma \\delta \\epsilon \\varepsilon \\eta \\theta \\kappa \\iota \\zeta \\lambda \\pi \\rho \\xi \\nu \\upsilon \\varphi \\chi \\psi \\omega \\Omega \\Gamma \\Delta \\mu \\Phi \\nabla $$ 对应的markdown1234567891011121314151617181920212223242526272829$$\\alpha \\\\beta \\\\gamma \\\\delta \\\\epsilon \\\\varepsilon \\\\eta \\\\theta \\\\kappa \\\\iota \\\\zeta \\\\lambda \\\\pi \\\\rho \\\\xi \\\\nu \\\\upsilon \\\\varphi \\\\chi \\\\psi \\\\omega \\\\Omega \\\\Gamma \\\\Delta \\\\mu \\\\Phi \\\\nabla \\$$ 四. 矩阵 预览$$ \\left[ \\begin{matrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \\ 7 &amp; 8 &amp; 9 \\\\end{matrix}\\right]\\tag{这是注释}$$ 对应的markdown12345678910$$ \\left[ \\begin{matrix} 1 &amp; 2 &amp; 3 \\\\ 4 &amp; 5 &amp; 6 \\\\ 7 &amp; 8 &amp; 9 \\\\ \\end{matrix} \\right] \\tag{这是注释}$$ 五. 表达式 预览$$\\begin{cases}x + y + z \\2x - 2y + 4z \\-3x + 4y +5z\\end{cases}$$ 对应的markdown1234567$$\\begin{cases}x + y + z \\\\2x - 2y + 4z \\\\-3x + 4y +5z\\end{cases}$$ 经典示例 麦克斯威方程$$\\begin{array}{lll}\\nabla\\times E &amp;=&amp; -;\\frac{\\partial{B}}{\\partial{t}} \\nabla\\times H &amp;=&amp; \\frac{\\partial{D}}{\\partial{t}}+J \\nabla\\cdot D &amp;=&amp; \\rho \\nabla\\cdot B &amp;=&amp; 0 \\end{array} $$","link":"/2022/11/03/markdown%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/"},{"title":"mongodb官方备份工具, MongoDump源码分析","text":"简介 最近用到了该模块, 期间看了源码, 这里顺便做下笔记 本文前几小节讲MongoDump的运转流程, 后几小节讲代码方面的技术细节 源码版本: 100.6.1 源码仓库: https://github.com/mongodb/mongo-tools/blob/100.6.1/mongodump 0. 备份总览: MongoDump.Dump 备份逻辑就在MongoDump的Dump方法 (mongodump/mongodump.go/MongoDump.Dump) Dump主要分4步: 各种初始化工作 备份metaData, index, users, roles, version 等基础数据 备份collections 备份oplog 后面会经常提到Intent, 这是MongoDump自己的一个抽象概念, 可以简单理解为备份任务单元, 例如一个collection的备份对应一个Intent, oplog的备份对应一个Intent等等; 在阅读源码时你可以将Intent在脑海里替换成Task. 关于Intent详见本文后面章节 核心逻辑见以下源码及注释(为了方便阅读, 这里我删减了些不关键的逻辑): 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258// Dump是MongoDump的一个方法type MongoDump struct { ToolOptions *options.ToolOptions InputOptions *InputOptions OutputOptions *OutputOptions SkipUsersAndRoles bool ProgressManager progress.Manager SessionProvider *db.SessionProvider // 就是mongoClient manager *intents.Manager // 备份单元管理, 核心组件 query bson.D oplogCollection string oplogStart primitive.Timestamp oplogEnd primitive.Timestamp isMongos bool storageEngine storageEngineType authVersion int archive *archive.Writer // InputOptions.Output非&quot;-&quot;时往这里写入 shutdownIntentsNotifier *notifier OutputWriter io.Writer // InputOptions.Output为&quot;-&quot;时往这里写入 Logger *log.ToolLogger}// OutputOptions出现频繁所以贴一下type OutputOptions struct { Out string `long:&quot;out&quot; value-name:&quot;&lt;directory-path&gt;&quot; short:&quot;o&quot; description:&quot;output directory, or '-' for stdout (default: 'dump')&quot;` Gzip bool `long:&quot;gzip&quot; description:&quot;compress archive or collection output with Gzip&quot;` Oplog bool `long:&quot;oplog&quot; description:&quot;use oplog for taking a point-in-time snapshot&quot;` Archive string `long:&quot;archive&quot; value-name:&quot;&lt;file-path&gt;&quot; optional:&quot;true&quot; optional-value:&quot;-&quot; description:&quot;dump as an archive to the specified path. If flag is specified without a value, archive is written to stdout&quot;` DumpDBUsersAndRoles bool `long:&quot;dumpDbUsersAndRoles&quot; description:&quot;dump user and role definitions for the specified database&quot;` ExcludedCollections []string `long:&quot;excludeCollection&quot; value-name:&quot;&lt;collection-name&gt;&quot; description:&quot;collection to exclude from the dump (may be specified multiple times to exclude additional collections)&quot;` ExcludedCollectionPrefixes []string `long:&quot;excludeCollectionsWithPrefix&quot; value-name:&quot;&lt;collection-prefix&gt;&quot; description:&quot;exclude all collections from the dump that have the given prefix (may be specified multiple times to exclude additional prefixes)&quot;` NumParallelCollections int `long:&quot;numParallelCollections&quot; short:&quot;j&quot; description:&quot;number of collections to dump in parallel&quot; default:&quot;4&quot; default-mask:&quot;-&quot;` ViewsAsCollections bool `long:&quot;viewsAsCollections&quot; description:&quot;dump views as normal collections with their produced data, omitting standard collections&quot;`}func (dump *MongoDump) Dump() (err error) { defer dump.SessionProvider.Close() /* 1. 阶段1: 各种初始化工作 */ // 检查下dump.ToolOptions.Namespace.DB和dump.ToolOptions.Namespace.Collection是否存在 exists, err := dump.verifyCollectionExists() if err != nil { return fmt.Errorf(&quot;error verifying collection info: %v&quot;, err) } if !exists { return nil } // 初始化shutdownIntentsNotifier; 本质就是一个shutdown chan dump.shutdownIntentsNotifier = newNotifier() // 初始化dump.query; 是针对指定了过滤条件的情况, 一般不会用到 if dump.InputOptions.HasQuery() { content, err := dump.InputOptions.GetQuery() if err != nil { return err } var query bson.D err = bson.UnmarshalExtJSON(content, false, &amp;query) if err != nil { return fmt.Errorf(&quot;error parsing query as Extended JSON: %v&quot;, err) } dump.query = query } // 连源MongoDB获取authSchemaVersion, 版本小于3则不支持备份用户和角色, 直接返回错误 if !dump.SkipUsersAndRoles &amp;&amp; dump.OutputOptions.DumpDBUsersAndRoles { // dump.SessionProvider就是mongoClient dump.authVersion, err = auth.GetAuthVersion(dump.SessionProvider) if err == nil { err = auth.VerifySystemAuthVersion(dump.SessionProvider) } if err != nil { return fmt.Errorf(&quot;error getting auth schema version for dumpDbUsersAndRoles: %v&quot;, err) } if dump.authVersion &lt; 3 { return fmt.Errorf(&quot;backing up users and roles is only supported for &quot;+ &quot;deployments with auth schema versions &gt;= 3, found: %v&quot;, dump.authVersion) } } // 初始化dump.archive, dump.archive是个高度封装的Writer if dump.OutputOptions.Archive != &quot;&quot; { var archiveOut io.WriteCloser // 根据dump.OutputOptions.Archive获取对应输出文件的ioWriter, 当值为&quot;-&quot;时输出将到OutputWriter而不是文件 archiveOut, err = dump.getArchiveOut() if err != nil { return err } dump.archive = &amp;archive.Writer{ Out: archiveOut, Mux: archive.NewMultiplexer(archiveOut, dump.shutdownIntentsNotifier), } go dump.archive.Mux.Run() // 备份结束后的一些释放工作 defer func() { // The Mux runs until its Control is closed close(dump.archive.Mux.Control) muxErr := &lt;-dump.archive.Mux.Completed archiveOut.Close() if muxErr != nil { if err != nil { err = fmt.Errorf(&quot;archive writer: %v / %v&quot;, err, muxErr) } else { err = fmt.Errorf(&quot;archive writer: %v&quot;, muxErr) } dump.Logger.Logvf(log.DebugLow, &quot;%v&quot;, err) } else { dump.Logger.Logvf(log.DebugLow, &quot;mux completed successfully&quot;) } }() } // 源Mongodb连通性检测 session, err := dump.SessionProvider.GetSession() if err != nil { return fmt.Errorf(&quot;error getting a client session: %v&quot;, err) } err = session.Ping(context.Background(), nil) if err != nil { return fmt.Errorf(&quot;error connecting to host: %v&quot;, err) } // 创建备份Intents switch { case dump.ToolOptions.DB == &quot;&quot; &amp;&amp; dump.ToolOptions.Collection == &quot;&quot;: err = dump.CreateAllIntents() case dump.ToolOptions.DB != &quot;&quot; &amp;&amp; dump.ToolOptions.Collection == &quot;&quot;: err = dump.CreateIntentsForDatabase(dump.ToolOptions.DB) case dump.ToolOptions.DB != &quot;&quot; &amp;&amp; dump.ToolOptions.Collection != &quot;&quot;: err = dump.CreateCollectionIntent(dump.ToolOptions.DB, dump.ToolOptions.Collection) } if err != nil { return fmt.Errorf(&quot;error creating intents to dump: %v&quot;, err) } // 如果需要备份Oplog, 则创建备份Oplog的Intents if dump.OutputOptions.Oplog { err = dump.CreateOplogIntents() if err != nil { return err } } // 如果需要备份Users和Roles, 则创建备份Users和Role的Intents if !dump.SkipUsersAndRoles &amp;&amp; dump.OutputOptions.DumpDBUsersAndRoles &amp;&amp; dump.ToolOptions.DB != &quot;admin&quot; { err = dump.CreateUsersRolesVersionIntentsForDB(dump.ToolOptions.DB) if err != nil { return err } } /* 2. 阶段2: 备份metaData, index, users, roles, version 等基础数据 */ err = dump.DumpMetadata() // intent.MetadataFile.Write(json.Marshal(metadata)) if err != nil { return fmt.Errorf(&quot;error dumping metadata: %v&quot;, err) } if dump.OutputOptions.Archive != &quot;&quot; { serverVersion, err := dump.SessionProvider.ServerVersion() if err != nil { dump.Logger.Logvf(log.Always, &quot;warning, couldn't get version information from server: %v&quot;, err) serverVersion = &quot;unknown&quot; } dump.archive.Prelude, err = archive.NewPrelude(dump.manager, dump.OutputOptions.NumParallelCollections, serverVersion, dump.ToolOptions.VersionStr) if err != nil { return fmt.Errorf(&quot;creating archive prelude: %v&quot;, err) } err = dump.archive.Prelude.Write(dump.archive.Out) if err != nil { return fmt.Errorf(&quot;error writing metadata into archive: %v&quot;, err) } } // 备份users, roles if !dump.SkipUsersAndRoles { if dump.ToolOptions.DB == &quot;admin&quot; || dump.ToolOptions.DB == &quot;&quot; { err = dump.DumpUsersAndRoles() if err != nil { return fmt.Errorf(&quot;error dumping users and roles: %v&quot;, err) } } if dump.OutputOptions.DumpDBUsersAndRoles { dump.Logger.Logvf(log.Always, &quot;dumping users and roles for %v&quot;, dump.ToolOptions.DB) if dump.ToolOptions.DB == &quot;admin&quot; { dump.Logger.Logvf(log.Always, &quot;skipping users/roles dump, already dumped admin database&quot;) } else { err = dump.DumpUsersAndRolesForDB(dump.ToolOptions.DB) if err != nil { return fmt.Errorf(&quot;error dumping users and roles: %v&quot;, err) } } } } // 设置dump.oplogStart 和 dump.oplogCollection if dump.OutputOptions.Oplog { // set dump.oplogCollection, &quot;oplog.rs&quot;或&quot;oplog.$main&quot; err := dump.determineOplogCollectionName() if err != nil { return fmt.Errorf(&quot;error finding oplog: %v&quot;, err) } dump.Logger.Logvf(log.Info, &quot;getting most recent oplog timestamp&quot;) dump.oplogStart, err = dump.getOplogCopyStartTime() if err != nil { return fmt.Errorf(&quot;error getting oplog start: %v&quot;, err) } } /* 3. 阶段3: 备份collections */ if err := dump.DumpIntents(); err != nil { return err } /* 4. 阶段4: 备份oplog */ if dump.OutputOptions.Oplog { dump.oplogEnd, err = dump.getCurrentOplogTime() if err != nil { return fmt.Errorf(&quot;error getting oplog end: %v&quot;, err) } // 确认oplog文件是否发生了翻转(Roll over), oplog本身是个环形队列 exists, err := dump.checkOplogTimestampExists(dump.oplogStart) if !exists { return fmt.Errorf( &quot;oplog overflow: mongodump was unable to capture all new oplog entries during execution&quot;) } if err != nil { return fmt.Errorf(&quot;unable to check oplog for overflow: %v&quot;, err) } dump.Logger.Logvf(log.Always, &quot;writing captured oplog to %v&quot;, dump.manager.Oplog().Location) // 备份oplog err = dump.DumpOplogBetweenTimestamps(dump.oplogStart, dump.oplogEnd) if err != nil { return fmt.Errorf(&quot;error dumping oplog: %v&quot;, err) } // 再次确认oplog文件是否发生了翻转 dump.Logger.Logvf(log.DebugLow, &quot;checking again if oplog entry %v still exists&quot;, dump.oplogStart) exists, err = dump.checkOplogTimestampExists(dump.oplogStart) if !exists { return fmt.Errorf( &quot;oplog overflow: mongodump was unable to capture all new oplog entries during execution&quot;) } if err != nil { return fmt.Errorf(&quot;unable to check oplog for overflow: %v&quot;, err) } } // 备份完成 dump.Logger.Logvf(log.DebugLow, &quot;finishing dump&quot;) return err} 1. 备份metadata 备份metadata的逻辑比较简单, 就是将Metadata jsonMarshal后写入intent.MetadataFile (io) 源码逻辑如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192type Metadata struct { Options bson.M `bson:&quot;options,omitempty&quot;` Indexes []bson.D `bson:&quot;indexes&quot;` UUID string `bson:&quot;uuid,omitempty&quot;` CollectionName string `bson:&quot;collectionName&quot;` Type string `bson:&quot;type,omitempty&quot;`}func (dump *MongoDump) dumpMetadata(intent *intents.Intent, buffer resettableOutputBuffer) (err error) { // 1. 填充Metadata, 值取自入参`intent` meta := Metadata{ Indexes: []bson.D{}, } meta.Options = intent.Options meta.UUID = intent.UUID meta.CollectionName = intent.C if intent.Type != &quot;&quot; { meta.Type = intent.Type } session, err := dump.SessionProvider.GetSession() if err != nil { return err } // 获取源端的index并set进meta.Indexes if dump.OutputOptions.ViewsAsCollections || intent.IsView() { dump.Logger.Logvf(log.DebugLow, &quot;not dumping indexes metadata for '%v' because it is a view&quot;, intent.Namespace()) } else { // get the indexes indexesIter, err := db.GetIndexes(session.Database(intent.DB).Collection(intent.C)) if err != nil { return err } if indexesIter == nil { dump.Logger.Logvf(log.Always, &quot;the collection %v appears to have been dropped after the dump started&quot;, intent.Namespace()) return nil } defer indexesIter.Close(context.Background()) ctx := context.Background() for indexesIter.Next(ctx) { indexOpts := &amp;bson.D{} err := indexesIter.Decode(indexOpts) if err != nil { return fmt.Errorf(&quot;error converting index: %v&quot;, err) } meta.Indexes = append(meta.Indexes, *indexOpts) } if err := indexesIter.Err(); err != nil { return fmt.Errorf(&quot;error getting indexes for collection `%v`: %v&quot;, intent.Namespace(), err) } } // 2. 把Metadata写入intent.MetadataFile /* 后面就是将meta jsonMarshal后写入intent.MetadataFile 而已*/ jsonBytes, err := bson.MarshalExtJSON(meta, true, false) if err != nil { return fmt.Errorf(&quot;error marshalling metadata json for collection `%v`: %v&quot;, intent.Namespace(), err) } err = intent.MetadataFile.Open() if err != nil { return err } defer func() { closeErr := intent.MetadataFile.Close() if err == nil &amp;&amp; closeErr != nil { err = fmt.Errorf(&quot;error writing metadata for collection `%v` to disk: %v&quot;, intent.Namespace(), closeErr) } }() var f io.Writer f = intent.MetadataFile if buffer != nil { buffer.Reset(f) f = buffer defer func() { closeErr := buffer.Close() if err == nil &amp;&amp; closeErr != nil { err = fmt.Errorf(&quot;error writing metadata for collection `%v` to disk: %v&quot;, intent.Namespace(), closeErr) } }() } _, err = f.Write(jsonBytes) if err != nil { err = fmt.Errorf(&quot;error writing metadata for collection `%v` to disk: %v&quot;, intent.Namespace(), err) } return} 2. 备份collections 源码如下, 就是从intent的manager中不断取intent分配给n条线程进行备份 一个intent对应一个collection的备份任务 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// 并发备份collections, NumParallelCollections条线程func (dump *MongoDump) DumpIntents() error { resultChan := make(chan error) // 线程数 = jobs = dump.OutputOptions.NumParallelCollections jobs := dump.OutputOptions.NumParallelCollections if numIntents := len(dump.manager.Intents()); jobs &gt; numIntents { jobs = numIntents } // 设置intents的Pop顺序策略 if jobs &gt; 1 { dump.manager.Finalize(intents.LongestTaskFirst) } else { dump.manager.Finalize(intents.Legacy) } // 多线程从dump.manager中Pop出Intent, 进行dump for i := 0; i &lt; jobs; i++ { go func(id int) { buffer := dump.getResettableOutputBuffer() dump.Logger.Logvf(log.DebugHigh, &quot;starting dump routine with id=%v&quot;, id) for { intent := dump.manager.Pop() if intent == nil { dump.Logger.Logvf(log.DebugHigh, &quot;ending dump routine with id=%v, no more work to do&quot;, id) resultChan &lt;- nil return } if intent.BSONFile != nil { err := dump.DumpIntent(intent, buffer) if err != nil { resultChan &lt;- err return } } dump.manager.Finish(intent) } }(i) } // 等待所有intents dump完 for i := 0; i &lt; jobs; i++ { if err := &lt;-resultChan; err != nil { return err } } return nil} 3. 备份oplog 备份oplog的逻辑比较简单, 将查询oplog的结果写入oplog对应的intent.BSONFile 如果对oplog不熟悉可以看下官方文档: https://www.mongodb.com/zh-cn/docs/manual/core/replica-set-oplog/ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980// 查询start与end之间的oplog, 写入 dump.manager.Oplog().BSONFilefunc (dump *MongoDump) DumpOplogBetweenTimestamps(start, end primitive.Timestamp) error { session, err := dump.SessionProvider.GetSession() if err != nil { return err } queryObj := bson.M{&quot;$and&quot;: []bson.M{ {&quot;ts&quot;: bson.M{&quot;$gte&quot;: start}}, {&quot;ts&quot;: bson.M{&quot;$lte&quot;: end}}, }} oplogQuery := &amp;db.DeferredQuery{ // &quot;local.oplog.rs&quot;(replset)或&quot;local.oplog.$main&quot;(m/s) Coll: session.Database(&quot;local&quot;).Collection(dump.oplogCollection), Filter: queryObj, LogReplay: true, } // 执行上面的`oplogQuery`, 将结果写入`dump.manager.Oplog().BSONFile` (dump.manager.Oplog()是oplog的intent) oplogCount, err := dump.dumpValidatedQueryToIntent(oplogQuery, dump.manager.Oplog(), dump.getResettableOutputBuffer(), oplogDocumentValidator) if err == nil { dump.Logger.Logvf(log.Always, &quot;\\tdumped %v oplog %v&quot;, oplogCount, util.Pluralize(int(oplogCount), &quot;entry&quot;, &quot;entries&quot;)) } return err}// 把`query`的查询结果写入`intent.BSONFile` (这是一个公共函数, 上边引用到了就顺便贴下, 不关键)func (dump *MongoDump) dumpValidatedQueryToIntent( query *db.DeferredQuery, intent *intents.Intent, buffer resettableOutputBuffer, validator documentValidator) (dumpCount int64, err error) { err = intent.BSONFile.Open() if err != nil { return 0, err } defer func() { closeErr := intent.BSONFile.Close() if err == nil &amp;&amp; closeErr != nil { err = fmt.Errorf(&quot;error writing data for collection `%v` to disk: %v&quot;, intent.Namespace(), closeErr) } }() // don't dump any data for views being dumped as views if intent.IsView() &amp;&amp; !dump.OutputOptions.ViewsAsCollections { return 0, nil } total, err := dump.getCount(query, intent) if err != nil { return 0, err } dumpProgressor := progress.NewCounter(total) if dump.ProgressManager != nil { dump.ProgressManager.Attach(intent.Namespace(), dumpProgressor) defer dump.ProgressManager.Detach(intent.Namespace()) } var f io.Writer f = intent.BSONFile if buffer != nil { buffer.Reset(f) f = buffer defer func() { closeErr := buffer.Close() if err == nil &amp;&amp; closeErr != nil { err = fmt.Errorf(&quot;error writing data for collection `%v` to disk: %v&quot;, intent.Namespace(), closeErr) } }() } cursor, err := query.Iter() if err != nil { return } // 将cursor查询结果写入f err = dump.dumpValidatedIterToWriter(cursor, f, dumpProgressor, validator) dumpCount, _ = dumpProgressor.Progress() if err != nil { err = fmt.Errorf(&quot;error writing data for collection `%v` to disk: %v&quot;, intent.Namespace(), err) } return} 备份单元: Intent 备份任务单元, 可以简单理解1个collection的备份任务就叫intent, 拆分是为了多线程执行 Intent相关的结构和关键方法: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177type Intent struct { // Destination namespace info DB string C string // collection // File locations as absolute paths BSONFile file BSONSize int64 MetadataFile file // Indicates where the intent will be read from or written to Location string MetadataLocation string // Collection options Options bson.M // UUID (for MongoDB 3.6+) as a big-endian hex string UUID string // File/collection size, for some prioritizer implementations. // Units don't matter as long as they are consistent for a given use case. Size int64 // Either view or timeseries. Empty string &quot;&quot; is a regular collection. Type string}// 查询collection(intent.C) 的数据, 写入intent.BSONFile, 仅此而已func (dump *MongoDump) DumpIntent(intent *intents.Intent, buffer resettableOutputBuffer) error { session, err := dump.SessionProvider.GetSession() if err != nil { return err } intendedDB := session.Database(intent.DB) var coll *mongo.Collection if intent.IsTimeseries() { coll = intendedDB.Collection(&quot;system.buckets.&quot; + intent.C) } else { coll = intendedDB.Collection(intent.C) } isView := true collInfo, err := db.GetCollectionInfo(coll) if err != nil { return err } else if collInfo != nil { isView = collInfo.IsView() } // 推断并设置dump.storageEngine if dump.storageEngine == storageEngineUnknown &amp;&amp; !isView { if err != nil { return err } dump.storageEngine = storageEngineModern isMMAPV1, err := db.IsMMAPV1(intendedDB, intent.C) if err != nil { dump.Logger.Logvf(log.Always, &quot;failed to determine storage engine, an mmapv1 storage engine could result in&quot;+ &quot; inconsistent dump results, error was: %v&quot;, err) } else if isMMAPV1 { dump.storageEngine = storageEngineMMAPV1 } } findQuery := &amp;db.DeferredQuery{Coll: coll} switch { case len(dump.query) &gt; 0: if intent.IsTimeseries() { metaKey, ok := intent.Options[&quot;timeseries&quot;].(bson.M)[&quot;metaField&quot;].(string) if !ok { return fmt.Errorf(&quot;could not determine the metaField for %s&quot;, intent.Namespace()) } for i, predicate := range dump.query { splitPredicateKey := strings.SplitN(predicate.Key, &quot;.&quot;, 2) if splitPredicateKey[0] != metaKey { return fmt.Errorf(&quot;cannot process query %v for timeseries collection %s. &quot;+ &quot;mongodump only processes queries on metadata fields for timeseries collections.&quot;, dump.query, intent.Namespace()) } if len(splitPredicateKey) &gt; 1 { dump.query[i].Key = &quot;meta.&quot; + splitPredicateKey[1] } else { dump.query[i].Key = &quot;meta&quot; } } } findQuery.Filter = dump.query case dump.storageEngine == storageEngineMMAPV1 &amp;&amp; !dump.InputOptions.TableScan &amp;&amp; !isView &amp;&amp; !intent.IsSpecialCollection() &amp;&amp; !intent.IsOplog(): autoIndexId, found := intent.Options[&quot;autoIndexId&quot;] if !found || autoIndexId == true { findQuery.Hint = bson.D{{&quot;_id&quot;, 1}} } } var dumpCount int64 if dump.OutputOptions.Out == &quot;-&quot; { // 初始化阶段有 &quot;intent.BSONFile = &amp;stdoutFile{Writer: dump.OutputWriter}&quot;, 可以搜下源码 // 所以这里虽然也是写到intent.BSONFile, 但实际写到dump.OutputWriter了 dump.Logger.Logvf(log.Always, &quot;writing %v to stdout&quot;, intent.DataNamespace()) dumpCount, err = dump.dumpQueryToIntent(findQuery, intent, buffer) if err == nil { // on success, print the document count dump.Logger.Logvf(log.Always, &quot;dumped %v %v&quot;, dumpCount, docPlural(dumpCount)) } return err } // 将findQuery查到的写入intent.BSONFile if dumpCount, err = dump.dumpQueryToIntent(findQuery, intent, buffer); err != nil { return err } return nil}// 将query查到的写入intent.BSONFilefunc (dump *MongoDump) dumpQueryToIntent( query *db.DeferredQuery, intent *intents.Intent, buffer resettableOutputBuffer) (dumpCount int64, err error) { return dump.dumpValidatedQueryToIntent(query, intent, buffer, nil)}func (dump *MongoDump) dumpValidatedQueryToIntent( query *db.DeferredQuery, intent *intents.Intent, buffer resettableOutputBuffer, validator documentValidator) (dumpCount int64, err error) { err = intent.BSONFile.Open() if err != nil { return 0, err } defer func() { closeErr := intent.BSONFile.Close() if err == nil &amp;&amp; closeErr != nil { err = fmt.Errorf(&quot;error writing data for collection `%v` to disk: %v&quot;, intent.Namespace(), closeErr) } }() // don't dump any data for views being dumped as views if intent.IsView() &amp;&amp; !dump.OutputOptions.ViewsAsCollections { return 0, nil } total, err := dump.getCount(query, intent) if err != nil { return 0, err } dumpProgressor := progress.NewCounter(total) if dump.ProgressManager != nil { dump.ProgressManager.Attach(intent.Namespace(), dumpProgressor) defer dump.ProgressManager.Detach(intent.Namespace()) } var f io.Writer f = intent.BSONFile if buffer != nil { buffer.Reset(f) f = buffer defer func() { closeErr := buffer.Close() if err == nil &amp;&amp; closeErr != nil { err = fmt.Errorf(&quot;error writing data for collection `%v` to disk: %v&quot;, intent.Namespace(), closeErr) } }() } cursor, err := query.Iter() if err != nil { return } // 将cursor查到的东西写入f err = dump.dumpValidatedIterToWriter(cursor, f, dumpProgressor, validator) dumpCount, _ = dumpProgressor.Progress() if err != nil { err = fmt.Errorf(&quot;error writing data for collection `%v` to disk: %v&quot;, intent.Namespace(), err) } return} 多路读写模块: archive.Writer/Reader 这是MongoDump唯一比较复杂的模块, 因为只讲备份, 所以只讲archive.Writer, archive.Reader是恢复时用到, 原理一样 多路读写核心Multiplexer, 里面有个核心组件MuxIn, 这东西其实就是上面提到的BSONFile的实现, 每次BSONFile.Open就相当于New一个NuxIn然后塞给Multiplexer管理, MuxIn就是多路读写里面的路 多路读写怎么实现? 其实本质是多路In, 一路Out, 上面提到的MuxIn是实现多路In, 而一路Out的关键逻辑在Multiplexer.formatBody, 这里可以看看下面的源码, 其实就是利用写入header和namespace来做数据隔离, 配合Multiplexer的select channel这样就实现了多路读写. 这个思想是值得学习的 概念那么多是不是看了头晕? 我们将所有概念都关联起来捋一下: 在1次备份中, 只有1个archive.Writer, 也意味着只有1个Multiplexer, 1个Multiplexer管理了n个MuxIn, n又等于Intent的个数, Intent有多少个? Intent的个数为len(collections) + 1 + 1, 这里的两个1分别是metadata和oplog Multiplexer源码的几个核心方法: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150type Writer struct { Out io.WriteCloser Prelude *Prelude Mux *Multiplexer}type Multiplexer struct { Out io.WriteCloser Control chan *MuxIn Completed chan error shutdownInputs notifier // ins and selectCases are correlating slices ins []*MuxIn selectCases []reflect.SelectCase currentNamespace string}type notifier interface { Notify()}func NewMultiplexer(out io.WriteCloser, shutdownInputs notifier) *Multiplexer { mux := &amp;Multiplexer{ Out: out, Control: make(chan *MuxIn), Completed: make(chan error), shutdownInputs: shutdownInputs, ins: []*MuxIn{ nil, // There is no MuxIn for the Control case }, } // 反射实现channel select, 非常少见的玩法! mux.selectCases = []reflect.SelectCase{ { Dir: reflect.SelectRecv, Chan: reflect.ValueOf(mux.Control), Send: reflect.Value{}, }, } return mux}// 核心事件循环: 处理MuxIn的增删事件和来自MuxIn的写数据事件func (mux *Multiplexer) Run() { var err, completionErr error for { // select的反射玩法, 学到了 index, value, notEOF := reflect.Select(mux.selectCases) EOF := !notEOF if index == 0 { // index 0 为 mux.Control, 用于接收新的MuxIn if EOF { log.Logvf(log.DebugLow, &quot;Mux finish&quot;) mux.Out.Close() if completionErr != nil { mux.Completed &lt;- completionErr } else if len(mux.selectCases) != 1 { mux.Completed &lt;- fmt.Errorf(&quot;Mux ending but selectCases still open %v&quot;, len(mux.selectCases)) } else { mux.Completed &lt;- nil } return } muxIn, ok := value.Interface().(*MuxIn) if !ok { mux.Completed &lt;- fmt.Errorf(&quot;non MuxIn received on Control chan&quot;) // one for the MuxIn.Open return } log.Logvf(log.DebugLow, &quot;Mux open namespace %v&quot;, muxIn.Intent.DataNamespace()) mux.selectCases = append(mux.selectCases, reflect.SelectCase{ Dir: reflect.SelectRecv, Chan: reflect.ValueOf(muxIn.writeChan), Send: reflect.Value{}, }) mux.ins = append(mux.ins, muxIn) } else { // index &gt; 0 为 MuxIn.writeChan, 用于接收MuxIn.Write的data if EOF { mux.ins[index].writeCloseFinishedChan &lt;- struct{}{} err = mux.formatEOF(index, mux.ins[index]) if err != nil { mux.shutdownInputs.Notify() mux.Out = &amp;nopCloseNopWriter{} completionErr = err } log.Logvf(log.DebugLow, &quot;Mux close namespace %v&quot;, mux.ins[index].Intent.DataNamespace()) mux.currentNamespace = &quot;&quot; mux.selectCases = append(mux.selectCases[:index], mux.selectCases[index+1:]...) mux.ins = append(mux.ins[:index], mux.ins[index+1:]...) } else { bsonBytes, ok := value.Interface().([]byte) if !ok { mux.Completed &lt;- fmt.Errorf(&quot;multiplexer received a value that wasn't a []byte&quot;) return } // format bsonBytes, 然后 mux.Out.Write(bsonBytes) err = mux.formatBody(mux.ins[index], bsonBytes) if err != nil { mux.shutdownInputs.Notify() mux.Out = &amp;nopCloseNopWriter{} completionErr = err } } } }}// 核心逻辑, 这个里的header用于隔离不同namespace的数据, 已达到多路的效果, 恢复的时候也是根据header来恢复的// mux.Out.Write header和bsonBytes, 这里的Out其实就是dump.archive.Outfunc (mux *Multiplexer) formatBody(in *MuxIn, bsonBytes []byte) error { var err error var length int defer func() { in.writeLenChan &lt;- length }() if in.Intent.DataNamespace() != mux.currentNamespace { // Handle the change of which DB/Collection we're writing docs for // If mux.currentNamespace then we need to terminate the current block if mux.currentNamespace != &quot;&quot; { l, err := mux.Out.Write(terminatorBytes) if err != nil { return err } if l != len(terminatorBytes) { return io.ErrShortWrite } } header, err := bson.Marshal(NamespaceHeader{ Database: in.Intent.DB, Collection: in.Intent.DataCollection(), }) if err != nil { return err } l, err := mux.Out.Write(header) if err != nil { return err } if l != len(header) { return io.ErrShortWrite } } mux.currentNamespace = in.Intent.DataNamespace() length, err = mux.Out.Write(bsonBytes) if err != nil { return err } return nil} MuxIn源码: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273type MuxIn struct { writeChan chan []byte writeLenChan chan int writeCloseFinishedChan chan struct{} buf []byte hash hash.Hash64 Intent *intents.Intent Mux *Multiplexer}func (muxIn *MuxIn) Read([]byte) (int, error) { return 0, nil}func (muxIn *MuxIn) Pos() int64 { return 0}// 关闭muxIn内部的所有chan, 最后multiplexer会收到关闭信号并返回formatEOF, 同时multiplexer也会发信号muxIn.writeCloseFinishedChanfunc (muxIn *MuxIn) Close() error { // the mux side of this gets closed in the mux when it gets an eof on the read log.Logvf(log.DebugHigh, &quot;MuxIn close %v&quot;, muxIn.Intent.DataNamespace()) if bufferWrites { muxIn.writeChan &lt;- muxIn.buf length := &lt;-muxIn.writeLenChan if length != len(muxIn.buf) { return io.ErrShortWrite } muxIn.buf = nil } close(muxIn.writeChan) close(muxIn.writeLenChan) &lt;-muxIn.writeCloseFinishedChan return nil}// 初始化muxIn, 然后把自己发给 muxIn.Muxfunc (muxIn *MuxIn) Open() error { log.Logvf(log.DebugHigh, &quot;MuxIn open %v&quot;, muxIn.Intent.DataNamespace()) muxIn.writeChan = make(chan []byte) muxIn.writeLenChan = make(chan int) muxIn.writeCloseFinishedChan = make(chan struct{}) muxIn.buf = make([]byte, 0, bufferSize) muxIn.hash = crc64.New(crc64.MakeTable(crc64.ECMA)) if bufferWrites { muxIn.buf = make([]byte, 0, db.MaxBSONSize) } muxIn.Mux.Control &lt;- muxIn return nil}// buf写入muxIn.buf, 满了就把muxIn.buf写入muxIn.writeChan, 然后清空muxIn.buffunc (muxIn *MuxIn) Write(buf []byte) (int, error) { if bufferWrites { // 固定true if len(muxIn.buf)+len(buf) &gt; cap(muxIn.buf) { muxIn.writeChan &lt;- muxIn.buf length := &lt;-muxIn.writeLenChan if length != len(muxIn.buf) { return 0, io.ErrShortWrite } muxIn.buf = muxIn.buf[:0] } muxIn.buf = append(muxIn.buf, buf...) } else { muxIn.writeChan &lt;- buf length := &lt;-muxIn.writeLenChan if length != len(buf) { return 0, io.ErrShortWrite } } muxIn.hash.Write(buf) return len(buf), nil}","link":"/2023/04/15/mongoDump%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"Mongodb数据迁移:MongoShake源码阅读","text":"简述 近期用到了MongoShake做数据迁移, 顺便看看源码, 本篇为阅读源码的笔记 本文只讲数据迁移这块相关的 原理及架构 架构 源码信息 源码版本: v2.8.1 源码仓库: https://github.com/alibaba/MongoShake 本文贴的源码片段为了只关注核心逻辑, 无关紧要的代码段会干掉或注释代替 一. 进程入口: collector的func main为进程的入口, 核心源码如下: 简单来讲做了3件事情 初始化和校验配置参数 加进程锁 使用了第三方工具github.com/nightlyone/lockfile实现的 简单讲就是在conf.Options.LogDirectory目录下建一个{conf.Options.Id}.pid文件来实现进程锁; 所以你可以扫描该目录下有多少个pid文件来确认当前有多少MongoShake进程在运行 开始跑数据迁移(startup) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798// cmd/collector/collector.go// 初始化ReplicationCoordinator然后Runfunc main() { var err error defer handleExit() defer LOG.Close() defer utils.Goodbye() // argument options configuration := flag.String(&quot;conf&quot;, &quot;a.conf&quot;, &quot;configure file absolute path&quot;) verbose := flag.Int(&quot;verbose&quot;, 0, &quot;where log goes to: 0 - file，1 - file+stdout，2 - stdout&quot;) version := flag.Bool(&quot;version&quot;, false, &quot;show version&quot;) flag.Parse() var file *os.File if file, err = os.Open(*configuration); err != nil { crash(fmt.Sprintf(&quot;Configure file open failed. %v&quot;, err), -1) } defer file.Close() // read fcv and do comparison if _, err := conf.CheckFcv(*configuration, utils.FcvConfiguration.FeatureCompatibleVersion); err != nil { crash(err.Error(), -5) } configure := nimo.NewConfigLoader(file) configure.SetDateFormat(utils.GolangSecurityTime) if err := configure.Load(&amp;conf.Options); err != nil { crash(fmt.Sprintf(&quot;Configure file %s parse failed. %v&quot;, *configuration, err), -2) } // verify collector options and revise if err = SanitizeOptions(); err != nil { crash(fmt.Sprintf(&quot;Conf.Options check failed: %s&quot;, err.Error()), -4) } conf.Options.Version = utils.BRANCH utils.Mkdirs(conf.Options.LogDirectory) // get exclusive process lock and write pid if utils.WritePidById(conf.Options.LogDirectory, conf.Options.Id) { startup() }}func startup() { // leader election at the beginning selectLeader() // ReplicationCoordinator即迁移任务, 包含全量和增量 coordinator := &amp;coordinator.ReplicationCoordinator{ MongoD: make([]*utils.MongoSource, len(conf.Options.MongoUrls)), } // init for i, src := range conf.Options.MongoUrls { coordinator.MongoD[i] = new(utils.MongoSource) coordinator.MongoD[i].URL = src if len(conf.Options.IncrSyncOplogGIDS) != 0 { coordinator.MongoD[i].Gids = conf.Options.IncrSyncOplogGIDS } } if conf.Options.MongoSUrl != &quot;&quot; { coordinator.MongoS = &amp;utils.MongoSource{ URL: conf.Options.MongoSUrl, ReplicaName: &quot;mongos&quot;, } coordinator.RealSourceFullSync = []*utils.MongoSource{coordinator.MongoS} coordinator.RealSourceIncrSync = []*utils.MongoSource{coordinator.MongoS} if conf.Options.IncrSyncMongoFetchMethod == utils.VarIncrSyncMongoFetchMethodOplog { coordinator.RealSourceIncrSync = coordinator.MongoD } } else { coordinator.RealSourceFullSync = coordinator.MongoD coordinator.RealSourceIncrSync = coordinator.MongoD } if conf.Options.MongoCsUrl != &quot;&quot; { coordinator.MongoCS = &amp;utils.MongoSource{ URL: conf.Options.MongoCsUrl, } } // start mongodb replication if err := coordinator.Run(); err != nil { // initial or connection established failed LOG.Critical(fmt.Sprintf(&quot;run replication failed: %v&quot;, err)) crash(err.Error(), -6) } // if the sync mode is &quot;document&quot;, mongoshake should exit here. if conf.Options.SyncMode == utils.VarSyncModeFull { return } // do not exit select {}} 上面的startup里面的coordinator.Run()会根据syncMode走全量,增量或全量+增量12345678910111213141516171819202122232425switch syncMode {case utils.VarSyncModeAll: // 全量+增量 if conf.Options.FullSyncReaderOplogStoreDisk { LOG.Info(&quot;run parallel document oplog&quot;) if err := coordinator.parallelDocumentOplog(fullBeginTs); err != nil { return err } } else { LOG.Info(&quot;run serialize document oplog&quot;) if err := coordinator.serializeDocumentOplog(fullBeginTs); err != nil { return err } }case utils.VarSyncModeFull: // 全量 if err := coordinator.startDocumentReplication(); err != nil { return err }case utils.VarSyncModeIncr: // 增量 if err := coordinator.startOplogReplication(int64(0), int64(0), startTsMap); err != nil { return err }default: LOG.Critical(&quot;unknown sync mode %v&quot;, conf.Options.SyncMode) return errors.New(&quot;unknown sync mode &quot; + conf.Options.SyncMode)} 二. 全量同步 根据上面可知道, 全量同步的入口在ReplicationCoordinator.startDocumentReplication, 主要分为3步: 获取同步源的所有表, 删除同步目标对应的表 上面说的表实际在源码中是ns(namespace), 格式为f’{database}.{collection}’, 后面会经常提到 同步所有索引数据 (Option为后台索引时是放在这一步, 如果是前台索引则是同步db后才执行同步) 查询源库getIndexes, 然后在目标库createIndex 同步db(collection)数据 多线程同步, 线程数取决源数据地址和架构 mongos只算一个地址即一条线程, 多线程是针对mongod的情况 dbSyncer是同步的核心, 一条线程对应一个dbSyncer, 负责单个db实例的全量同步工作, 所以通常情况下只有1个dbSyncer 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177// collector/coordinator/full.gofunc (coordinator *ReplicationCoordinator) startDocumentReplication() error { fromIsSharding := coordinator.SourceIsSharding() var shardingChunkMap sharding.ShardingChunkMap var err error // init orphan sharding chunk map if source is mongod(get data directly from mongod) if fromIsSharding &amp;&amp; coordinator.MongoS == nil { LOG.Info(&quot;source is mongod, need to fetching chunk map&quot;) shardingChunkMap, err = fetchChunkMap(fromIsSharding) if err != nil { LOG.Critical(&quot;fetch chunk map failed[%v]&quot;, err) return err } } else { LOG.Info(&quot;source is replica or mongos, no need to fetching chunk map&quot;) } filterList := filter.NewDocFilterList() // get all namespace need to sync nsSet, _, err := utils.GetAllNamespace(coordinator.RealSourceFullSync, filterList.IterateFilter, conf.Options.MongoSslRootCaFile) if err != nil { return err } LOG.Info(&quot;all namespace: %v&quot;, nsSet) var ckptMap map[string]utils.TimestampNode if conf.Options.SpecialSourceDBFlag != utils.VarSpecialSourceDBFlagAliyunServerless &amp;&amp; len(coordinator.MongoD) &gt; 0 { // get current newest timestamp ckptMap, err = getTimestampMap(coordinator.MongoD, conf.Options.MongoSslRootCaFile) if err != nil { return err } } // create target client toUrl := conf.Options.TunnelAddress[0] var toConn *utils.MongoCommunityConn if !conf.Options.FullSyncExecutorDebug { if toConn, err = utils.NewMongoCommunityConn(toUrl, utils.VarMongoConnectModePrimary, true, utils.ReadWriteConcernLocal, utils.ReadWriteConcernDefault, conf.Options.TunnelMongoSslRootCaFile); err != nil { return err } defer toConn.Close() } // create namespace transform trans := transform.NewNamespaceTransform(conf.Options.TransformNamespace) // drop target collection if possible if err := docsyncer.StartDropDestCollection(nsSet, toConn, trans); err != nil { return err } // enable shard if sharding -&gt; sharding shardingSync := docsyncer.IsShardingToSharding(fromIsSharding, toConn) if shardingSync { var connString string if len(conf.Options.MongoSUrl) &gt; 0 { connString = conf.Options.MongoSUrl } else { connString = conf.Options.MongoCsUrl } if err := docsyncer.StartNamespaceSpecSyncForSharding(connString, toConn, trans); err != nil { return err } } // 同步所有索引数据 // fetch all indexes var indexMap map[utils.NS][]bson.D // Ns即namespace, 说白了就是 f'{database}.{collection}' if conf.Options.FullSyncCreateIndex != utils.VarFullSyncCreateIndexNone { if indexMap, err = fetchIndexes(coordinator.RealSourceFullSync, filterList.IterateFilter); err != nil { return fmt.Errorf(&quot;fetch index failed[%v]&quot;, err) } // print LOG.Info(&quot;index list below: ----------&quot;) for ns, index := range indexMap { // LOG.Info(&quot;collection[%v] -&gt; %s&quot;, ns, utils.MarshalStruct(index)) LOG.Info(&quot;collection[%v] -&gt; %v&quot;, ns, index) } LOG.Info(&quot;index list above: ----------&quot;) // 后台索引, 就是简单的查询源库getIndexes, 然后在目标库createIndex if conf.Options.FullSyncCreateIndex == utils.VarFullSyncCreateIndexBackground { if err := docsyncer.StartIndexSync(indexMap, toUrl, trans, true); err != nil { return fmt.Errorf(&quot;create background index failed[%v]&quot;, err) } } } // global qps limit, all dbsyncer share only 1 Qos qos := utils.StartQoS(0, int64(conf.Options.FullSyncReaderDocumentBatchSize), &amp;utils.FullSentinelOptions.TPS) // 同步db数据, 配置文件填了几个源地址就开几条线程(mongos只算一个地址即一条线程, 多线程是针对mongod的情况) // start sync each db var wg sync.WaitGroup var replError error for i, src := range coordinator.RealSourceFullSync { var orphanFilter *filter.OrphanFilter if conf.Options.FullSyncExecutorFilterOrphanDocument &amp;&amp; shardingChunkMap != nil { dbChunkMap := make(sharding.DBChunkMap) if chunkMap, ok := shardingChunkMap[src.ReplicaName]; ok { dbChunkMap = chunkMap } else { LOG.Warn(&quot;document syncer %v has no chunk map&quot;, src.ReplicaName) } orphanFilter = filter.NewOrphanFilter(src.ReplicaName, dbChunkMap) } dbSyncer := docsyncer.NewDBSyncer(i, src.URL, src.ReplicaName, toUrl, trans, orphanFilter, qos, fromIsSharding) dbSyncer.Init() LOG.Info(&quot;document syncer-%d do replication for url=%v&quot;, i, src.URL) wg.Add(1) nimo.GoRoutine(func() { defer wg.Done() if err := dbSyncer.Start(); err != nil { LOG.Critical(&quot;document replication for url=%v failed. %v&quot;, utils.BlockMongoUrlPassword(src.URL, &quot;***&quot;), err) replError = err } dbSyncer.Close() }) } wg.Wait() if replError != nil { return replError } // 完成同步后创建前台索引, 后台索引是同步数据前创建 // create index if == foreground if conf.Options.FullSyncCreateIndex == utils.VarFullSyncCreateIndexForeground { if err := docsyncer.StartIndexSync(indexMap, toUrl, trans, false); err != nil { return fmt.Errorf(&quot;create forground index failed[%v]&quot;, err) } } // update checkpoint after full sync // do not update checkpoint when source is &quot;aliyun_serverless&quot; if conf.Options.SyncMode != utils.VarSyncModeFull &amp;&amp; conf.Options.SpecialSourceDBFlag != utils.VarSpecialSourceDBFlagAliyunServerless { // need merge to one when from mongos and fetch_mothod==&quot;change_stream&quot; if coordinator.MongoS != nil &amp;&amp; conf.Options.IncrSyncMongoFetchMethod == utils.VarIncrSyncMongoFetchMethodChangeStream { var smallestNew int64 = math.MaxInt64 for _, val := range ckptMap { if smallestNew &gt; val.Newest { smallestNew = val.Newest } } ckptMap = map[string]utils.TimestampNode{ coordinator.MongoS.ReplicaName: { Newest: smallestNew, }, } } /* eg: map[map[shard1_servers:{Oldest:7329804871119405057 Newest:7431129274255409154} shard2_servers:{Oldest:7398473718780919810 Newest:7431129274255409153} shard3_servers:{Oldest:7417453196441813035 Newest:7431129278550376449}]] 这个长数字其实时间戳, 只不过是 `ts &lt;&lt; 32 + cnt`, oplog就是这样的格式的 */ LOG.Info(&quot;try to set checkpoint with map[%v]&quot;, ckptMap) if err := docsyncer.Checkpoint(ckptMap); err != nil { return err } } LOG.Info(&quot;document syncer sync end&quot;) return nil} 全量同步的核心: dbSyncer dbSyncer负责单个db的全量同步工作, 同步逻辑如下的Start: 将同步任务细分为nsList, ns即namespace, 其实就是collection 开n条线程, n=conf.Options.FullSyncReaderCollectionParallel 将上面细分的任务nsList丢给这些线程去运行, 即1个collection的同步是一个任务单元, 所以多个collection是做到了并行同步的 任务单元的执行逻辑在dbSyncer.collectionSync 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162// 每个collection为1个任务(nsList), 分配给n条线程执行func (syncer *DBSyncer) Start() (syncError error) { syncer.startTime = time.Now() var wg sync.WaitGroup filterList := filter.NewDocFilterList() // get all namespace (就是f'{database}.{collection}') nsList, _, err := utils.GetDbNamespace(syncer.FromMongoUrl, filterList.IterateFilter, conf.Options.MongoSslRootCaFile) if err != nil { return err } collExecutorParallel := conf.Options.FullSyncReaderCollectionParallel namespaces := make(chan utils.NS, collExecutorParallel) wg.Add(len(nsList)) nimo.GoRoutine(func() { for _, ns := range nsList { namespaces &lt;- ns } }) // run collection sync in parallel var nsDoneCount int32 = 0 for i := 0; i &lt; collExecutorParallel; i++ { collExecutorId := GenerateCollExecutorId() nimo.GoRoutine(func() { for { ns, ok := &lt;-namespaces if !ok { break } // 每个ns本质就是一个collection toNS := utils.NewNS(syncer.nsTrans.Transform(ns.Str())) LOG.Info(&quot;%s collExecutor-%d sync ns %v to %v begin&quot;, syncer, collExecutorId, ns, toNS) err := syncer.collectionSync(collExecutorId, ns, toNS) // from collection to collection atomic.AddInt32(&amp;nsDoneCount, 1) if err != nil { LOG.Critical(&quot;%s collExecutor-%d sync ns %v to %v failed. %v&quot;, syncer, collExecutorId, ns, toNS, err) syncError = fmt.Errorf(&quot;document syncer sync ns %v to %v failed. %v&quot;, ns, toNS, err) } else { process := int(atomic.LoadInt32(&amp;nsDoneCount)) * 100 / len(nsList) LOG.Info(&quot;%s collExecutor-%d sync ns %v to %v successful. db syncer-%d progress %v%%&quot;, syncer, collExecutorId, ns, toNS, syncer.id, process) } wg.Done() } LOG.Info(&quot;%s collExecutor-%d finish&quot;, syncer, collExecutorId) }) } wg.Wait() close(namespaces) return syncError} collectionSync的逻辑如下, 在collection这个粒度下还在splitter中做了细分任务, 这个是根据splitKeys去做分割的, 一般很少用到 splitter负责从源读数据, 数据reader入队到splitter.readerChan splitSync那上面出队的reader进行读数据, 这里就是读数据的终点了 读到的真实数据(BSON)会交给colExecutor去同步给目标 colExecutor也是一个生产-消费模型, 上面读到的数据会推给colExecutor.docBatch (chan []*bson.Raw), 在colExecutor.Start()中处理队列数据 colExecutor又又又细分了DocExecutor, DocExecutor拿到docBatch里面的数据后, 才真正的进行同步exec.doSync(docs), 这里就是写数据的终点了 写数据用的BulkWrite去批量写入 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163// 单个collection的全量同步, splitter负责从FromMongoUrl-ns读, colExecutor负责往ToMongoUrl-toNS写// start sync single collectionfunc (syncer *DBSyncer) collectionSync(collExecutorId int, ns utils.NS, toNS utils.NS) error { // writer colExecutor := NewCollectionExecutor(collExecutorId, syncer.ToMongoUrl, toNS, syncer, conf.Options.TunnelMongoSslRootCaFile) if err := colExecutor.Start(); err != nil { return fmt.Errorf(&quot;start collectionSync failed: %v&quot;, err) } // splitter reader: splitter.Run()会生成n个reader(DocumentReader), 往splitter.readerChan灌; // 每个reader相当于一个任务, 在下面走多线程执行, 属于多个reader往一个writer(colExecutor)写的模式; // 全量数据可以放心并发无序写入; splitter := NewDocumentSplitter(syncer.FromMongoUrl, conf.Options.MongoSslRootCaFile, ns) if splitter == nil { return fmt.Errorf(&quot;create splitter failed&quot;) } defer splitter.Close() // run in several pieces var wg sync.WaitGroup wg.Add(conf.Options.FullSyncReaderParallelThread) for i := 0; i &lt; conf.Options.FullSyncReaderParallelThread; i++ { go func() { defer wg.Done() for { reader, ok := &lt;-splitter.readerChan if !ok || reader == nil { break } // 从reader里面读取docs, 然后把bson结果往chan colExecutor.docBatch灌 if err := syncer.splitSync(reader, colExecutor, collectionMetric); err != nil { LOG.Crashf(&quot;%v&quot;, err) } } }() } wg.Wait() LOG.Info(&quot;%s all readers finish, wait all writers finish&quot;, syncer) // close writer if err := colExecutor.Wait(); err != nil { return fmt.Errorf(&quot;close writer failed: %v&quot;, err) } // set collection finish collectionMetric.CollectionStatus = StatusFinish return nil}// 从reader读docs数据, 然后写到colExecutorfunc (syncer *DBSyncer) splitSync(reader *DocumentReader, colExecutor *CollectionExecutor, collectionMetric *CollectionMetric) error { bufferSize := conf.Options.FullSyncReaderDocumentBatchSize buffer := make([]*bson.Raw, 0, bufferSize) bufferByteSize := 0 for { // 里面就是docCursor.Next(), 只是做了层简单的封装 doc, err := reader.NextDoc() if err != nil { return fmt.Errorf(&quot;splitter reader[%v] get next document failed: %v&quot;, reader, err) } else if doc == nil { atomic.AddUint64(&amp;collectionMetric.FinishCount, uint64(len(buffer))) colExecutor.Sync(buffer) // colExecutor.docBatch &lt;- buffer syncer.replMetric.AddSuccess(uint64(len(buffer))) // only used to calculate the tps which is extract from &quot;success&quot; break } syncer.replMetric.AddGet(1) if bufferByteSize+len(doc) &gt; MAX_BUFFER_BYTE_SIZE || len(buffer) &gt;= bufferSize { atomic.AddUint64(&amp;collectionMetric.FinishCount, uint64(len(buffer))) colExecutor.Sync(buffer) syncer.replMetric.AddSuccess(uint64(len(buffer))) // only used to calculate the tps which is extract from &quot;success&quot; buffer = make([]*bson.Raw, 0, bufferSize) bufferByteSize = 0 } // transform dbref for document if len(conf.Options.TransformNamespace) &gt; 0 &amp;&amp; conf.Options.IncrSyncDBRef { var docData bson.D if err := bson.Unmarshal(doc, &amp;docData); err != nil { LOG.Error(&quot;splitter reader[%v] do bson unmarshal %v failed. %v&quot;, reader, doc, err) } else { docData = transform.TransformDBRef(docData, reader.ns.Database, syncer.nsTrans) if v, err := bson.Marshal(docData); err != nil { LOG.Warn(&quot;splitter reader[%v] do bson marshal %v failed. %v&quot;, reader, docData, err) } else { doc = v } } } buffer = append(buffer, &amp;doc) bufferByteSize += len(doc) } LOG.Info(&quot;splitter reader finishes: %v&quot;, reader) reader.Close() // reader.CloseMgo() return nil}// 接上面collectionSync的colExecutor.Start()func (colExecutor *CollectionExecutor) Start() error { var err error if !conf.Options.FullSyncExecutorDebug { writeConcern := utils.ReadWriteConcernDefault if conf.Options.FullSyncExecutorMajorityEnable { writeConcern = utils.ReadWriteConcernMajority } if colExecutor.conn, err = utils.NewMongoCommunityConn(colExecutor.mongoUrl, utils.VarMongoConnectModePrimary, true, utils.ReadWriteConcernDefault, writeConcern, colExecutor.sslRootFile); err != nil { return err } } parallel := conf.Options.FullSyncReaderWriteDocumentParallel colExecutor.docBatch = make(chan []*bson.Raw, parallel) executors := make([]*DocExecutor, parallel) for i := 0; i != len(executors); i++ { executors[i] = NewDocExecutor(GenerateDocExecutorId(), colExecutor, colExecutor.conn, colExecutor.syncer) go executors[i].start() } colExecutor.executors = executors return nil}// 接上面的go executors[i].start()func (exec *DocExecutor) start() { if !conf.Options.FullSyncExecutorDebug { defer exec.conn.Close() } for { // 读取源端的数据 docs, ok := &lt;-exec.colExecutor.docBatch if !ok { break } if exec.error == nil { // 里面就是往目标 if err := exec.doSync(docs); err != nil { exec.error = err // since v2.4.11: panic directly if meets error LOG.Crashf(&quot;%s sync failed: %v&quot;, exec, err) } } exec.colExecutor.wg.Done() // atomic.AddInt64(&amp;exec.colExecutor.batchCount, -1) }}// 终于到头了, 这里便是连接目标库进行BulkWritefunc (exec *DocExecutor) doSync(docs []*bson.Raw) error { // 省略大量逻辑 opts := options.BulkWrite().SetOrdered(false) res, err := exec.conn.Client.Database(ns.Database).Collection(ns.Collection).BulkWrite(nil, models, opts) // 省略大量逻辑} 看完了全量同步流程, 很明显有个缺陷, 全量同步期间源端有数据更新, 两边数据就不一致了, 当然这个限制条件官方也是有指出的 三. 增量同步 增量同步逻辑在OplogSyncer OplogSyncer和DbSyncer类似 多线程同步, 线程数取决源数据地址和架构 mongos只算一个地址即一条线程, 多线程是针对mongod的情况 一条线程对应一个OplogSyncer, 负责单个db实例的增量同步工作, 所以通常情况下只有1个OplogSyncer 依旧是生产-消费模型 worker是消费者, Batcher是生产者 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// collector/coordinator/incr.go// 增量同步func (coordinator *ReplicationCoordinator) startOplogReplication(oplogStartPosition interface{}, fullSyncFinishPosition int64, startTsMap map[string]int64) error { // prepare all syncer. only one syncer while source is ReplicaSet // otherwise one syncer connects to one shard LOG.Info(&quot;start incr replication&quot;) for i, src := range coordinator.RealSourceIncrSync { var syncerTs interface{} if val, ok := oplogStartPosition.(int64); ok &amp;&amp; val == 0 { if v, ok := startTsMap[src.ReplicaName]; !ok { return fmt.Errorf(&quot;replia[%v] not exists on startTsMap[%v]&quot;, src.ReplicaName, startTsMap) } else { syncerTs = v } } else { syncerTs = oplogStartPosition // fullBeginTs } LOG.Info(&quot;RealSourceIncrSync[%d]: %s, startTimestamp[%v]&quot;, i, src, syncerTs) syncer := collector.NewOplogSyncer(src.ReplicaName, syncerTs, fullSyncFinishPosition, src.URL, src.Gids) // syncerGroup http api registry syncer.Init() coordinator.syncerGroup = append(coordinator.syncerGroup, syncer) } // set to group 0 as a leader coordinator.syncerGroup[0].SyncGroup = coordinator.syncerGroup // prepare worker routine and bind it to syncer for i := 0; i &lt; conf.Options.IncrSyncWorker; i++ { syncer := coordinator.syncerGroup[i%len(coordinator.syncerGroup)] w := collector.NewWorker(syncer, uint32(i)) if !w.Init() { return errors.New(&quot;worker initialize error&quot;) } w.SetInitSyncFinishTs(fullSyncFinishPosition) syncer.Bind(w) go w.StartWorker() // worker是消费者, Batcher是生产者(在syncer.Start()里面) } for _, syncer := range coordinator.syncerGroup { go syncer.Start() } return nil} 附oplog实例及字段意义 oplog各字段的解析 1234567891011121314{ &quot;ts&quot; : Timestamp(1582277156, 1), // 操作的时间戳，64位表示，高32位是时间戳，低32位是计数累加 &quot;t&quot; : NumberLong(1), // 对应raft协议里面的term，每次发生节点down掉，新节点加入，主从切换，term都会自增 &quot;h&quot; : NumberLong(0), // 操作的全局唯一id的hash结果 &quot;v&quot; : 2, // oplog的版本字段 &quot;op&quot; : &quot;i&quot;, // &quot;i&quot;表示插入，&quot;d&quot;表示删除，&quot;u&quot;表示更新，&quot;c&quot;表示DDL操作，&quot;n&quot;表示心跳 &quot;ns&quot; : &quot;zz.test&quot;, // 命名空间。操作发生在哪个表上面 &quot;ui&quot; : UUID(&quot;20d9f949-cfc7-496e-a80e-32ba633701a8&quot;), // 表的uuid &quot;wall&quot; : ISODate(&quot;2020-02-21T09:25:56.570Z&quot;), &quot;o&quot; : { // 具体的操作指令字段, 跟&quot;op&quot;一对 &quot;_id&quot; : ObjectId(&quot;5e4fa224a6717632d6ee2e85&quot;), &quot;kick&quot; : 1 }}","link":"/2023/04/09/mongoShake%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"OTP动态口令及底层实现","text":"背景 最近用到了OTP, 遂mark一下 我们常用的那种倒计时验证码就是TOTP, 既不是叫OTP也不是叫MFA, 经常听有人这么说所以提一嘴 OTP 动态口令验证可以看作是服务端和客户端之间通过约定相同的算法来实现验证功能, 也即你在客户端看到的动态口令是客户端通过算法生成的无需请求服务端获取 TOTP 平时用的google动态口令用的就是TOTP(Time-based One-Time Password), TOTP基于HOTP 原理: 假设用的是30秒间隔的六位口令, 精简版伪代码:12345678// secret为密码, timestamp为时间戳, 返回口令GetOTPCode(secret, timestamp) { hs = hmac(secret, timestamp/30) // hsToInt是对hs这个[]byte进行各种&amp;与偏移操作然后转为int intHs = hsToInt(hs) code = intHs % 1000000 return code} HOTP TOTP本质就是一个套皮HOTP, 核心是HOTP 我们从TOTP的视角来理解HOTP做了什么, 见代码和注释:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647type HOTP struct { secret []byte // 密钥, 每个人都有属于自己的一串密钥 digits int // 验证码的位数}/* counter就是`当前时间戳/设定的倒计时长`, return的就是平时看到的那串数字(通常为6位); eg: 假设设定的倒计时长为60: counter为(1600000000 / 60) 返回 519365 counter为((1600000000 + 5) / 60) 返回 519365 counter为((1600000000 + 60) / 60)返回 797425*/func (h HOTP) At(counter uint64) string { counterBytes := make([]byte, 8) binary.BigEndian.PutUint64(counterBytes, counter) hash := hmac.New(sha1.New, h.secret) hash.Write(counterBytes) hs := hash.Sum(nil) offset := hs[19] &amp; 0x0f binCodeBytes := make([]byte, 4) binCodeBytes[0] = hs[offset] &amp; 0x7f binCodeBytes[1] = hs[offset+1] &amp; 0xff binCodeBytes[2] = hs[offset+2] &amp; 0xff binCodeBytes[3] = hs[offset+3] &amp; 0xff binCode := binary.BigEndian.Uint32(binCodeBytes) mod := uint32(1) for i := 0; i &lt; h.digits; i++ { mod *= 10 } code := binCode % mod codeString := strconv.FormatUint(uint64(code), 10) if len(codeString) &lt; h.digits { paddingByteLength := h.digits - len(codeString) paddingBytes := make([]byte, paddingByteLength) for i := 0; i &lt; paddingByteLength; i++ { paddingBytes[i] = '0' } codeString = string(paddingBytes) + codeString } return codeString}// 验证阶段就简单了, 就是拿用户的输入code和上面的At结果对比func (h HOTP) Verify(code string, counter uint64) bool { return h.At(counter) == code} 库 golang-gootp python-pyotp 参考 RFC 4226 (HOTP) RFC 6238 (TOTP) 动态令牌-(OTP,HOTP,TOTP)-基本原理","link":"/2020/06/06/otp/"},{"title":"Py小玩具-绘图转线稿","text":"背景 临摹大佬的作品的时候丰富的颜色会反而产生莫名的干扰, 所以希望能转成干净的线稿! PS的滤镜效果不理想, 也找不到其他合适的工具, 故自己撸一个试试 源码 https://github.com/shuoGG1239/Paint2Sketch 版本一(分支:no-ml) 原理就是直接用opencv各种骚操作, 效果如下图 右下角几个滑条用于调参, 参数主要有canny卷积核和开闭操作的几个阈值参数 效果就是这样…参数不管怎么调都很辣鸡 版本二(分支:master) 版本一的效果太辣鸡, 没啥思路, 弃坑搁置了一年; 无意瞎逛逛到了一个lllyasviel/sketchKeras的项目, 看似效果不错? lllyasviel/sketchKeras是走了神经网络的路线, 开源了test_code和训练好的mod, 总之先抄过来试试 效果如下: 牛逼!机器学习逆天改命! 使用 如果想用的话直接clone下来, 再把release的mod.h5下载完丢根目录, 跑main.py就行了","link":"/2019/06/30/paint2sketch/"},{"title":"Py小玩具-MarkDown图床助手","text":"简介 现在markdown越用越频繁了, md好用是好用, 但就是贴图片的时候有些麻烦: 要截图-&gt;上传图片-&gt;复制图片url, 于是做了个简单的工具: 截图-&gt;传图-&gt;生成图片url三合一, 三…三分之一倍的快乐呀! 效果 截图上传(也可以用快捷键ctrl+shift+alt+F8) 上传后自动将图片url复制到剪贴板, 直接粘贴即可 也可以选择图片上传 也可以直接拖到框中上传 相关地址 exe下载: https://github.com/shuoGG1239/PicPong/releases 源码仓库: https://github.com/shuoGG1239/PicPong 技术相关 纯pyQt5开发 图床是用了sm.ms, 简单好用 后期也许会加一些其他的图床吧(也许…)","link":"/2018/10/25/picpong/"},{"title":"总结Pyinstaller的坑及终极解决方法","text":"一. 首先要有个稳定环境 下面是博主经测试的觉得坑比较少的环境搭配 Python3.4 + PyQt5.4 + Pyinstaller3.2.1 Python3.5 + PyQt5.8 + Pyinstaller3.2.1 二. Pyinstaller遇到坑没必要换打包工具 博主好几次用Pyinstaller遇到坑时都有考虑换工具如py2exe或cx-freeze之类的, 依旧无法解决 (最后还是用pyinstaller解决了) 所以没必要换其他工具, pyinstaller就够了 三. 坑1: 打包不了, 连exe都生成不出来解决方法 直接换Pyinstaller的版本, 即卸掉重装, 推荐用3.2.1 四. 坑2: exe生成了, 但是跑不了 大多数情况都是被坑在这里 解决方法 遇到这种问题不管弹出什么样的错误提示, 在输出exe时参数加个’-d’即debug模式, 然后打开的时候能看到打印的错误信息了, 这招很好用 留意一下程序依赖的一些资源文件, 检查下路径是否正确, 特别是程序里有相对路径的; 还有一些涉及到依赖系统默认资源的如默认字体啥的, 也得留意 换下打包方式, 如onefile模式和onedir模式 (之前出现过onedir打包可以但onefile打包不行的情况) 环境变量PATH中加上PyQt5的plugins的路径 依旧不行则换个Pyinstaller的版本, 即卸掉重装, 推荐用3.2.1 再不行则换操作系统试试, 有win10跑得了但到了win7就跑不了的情况 (弄个虚拟机测下找下问题在哪) 五. 错误码集锦main return -1 这种错误基本都是自己的问题, 只能在输出exe时参数加个’-d’即debug模式, 然后再查下打印的错误信息 Failed to execute script pyi_rth_pkgres 可以先换Pyinstaller的版本, 这个错误会消失, 但会弹出其他的错误信息, 然并卵 这种错误基本都是自己的问题, 只能在输出exe时参数加个’-d’即debug模式, 然后再查下打印的错误信息 Failed to execute script xxxx 这种错误基本都是自己的问题, 只能在输出exe时参数加个’-d’即debug模式, 然后再查下打印的错误信息 This application failed to start … Qt platform plugin … 这种错误先配下PyQt5的plugins的环境变量, 如博主的是C:\\Python34\\Lib\\site-packages\\PyQt5\\plugins 不行再换Pyinstaller的版本 (貌似3.0.0这个版本有问题, 后来换3.2.1就没事了)","link":"/2018/07/06/pyinstaller_keng/"},{"title":"快速美化PyQt应用--QCandyUi","text":"QCandy-UI 快速美化PyQt应用 项目地址: https://github.com/shuoGG1239/QCandyUi 使用方法 pip install QCandyUi 仅需在需要美化的窗口类上加上@colorful装饰器即可 也可以调用CandyWindow.creatWindow()返回经美化的QWidget (推荐用这种) 实例 原味窗口 12345678910# 窗口类为TcpUdpSerialPortTool# TcpUdpSerialPortTool.pyclass TcpUdpSerialPortTool(QWidget): ... ...# main.pyapp = QApplication(sys.argv)mainWindow = TcpUdpSerialportTool.TcpUdpSerialPortTool()mainWindow.show()sys.exit(app.exec_()) 加了蓝绿色主题的窗口(使用@colorful) 12345678910111213# 窗口类为TcpUdpSerialPortTool# TcpUdpSerialPortTool.pyfrom QCandyUi.CandyWindow import colorful@colorful('blueGreen')class TcpUdpSerialPortTool(QWidget): ... ...# main.pyapp = QApplication(sys.argv)mainWindow = TcpUdpSerialportTool.TcpUdpSerialPortTool()mainWindow.show()sys.exit(app.exec_()) 加了蓝色主题的窗口(使用@colorful) 12345678910111213# 窗口类为TcpUdpSerialPortTool# TcpUdpSerialPortTool.pyfrom QCandyUi.CandyWindow import colorful@colorful('blue')class TcpUdpSerialPortTool(QWidget): ... ...# main.pyapp = QApplication(sys.argv)mainWindow = TcpUdpSerialportTool.TcpUdpSerialPortTool()mainWindow.show()sys.exit(app.exec_()) 加了蓝色主题的窗口(使用CandyWindow.createWindow) 12345from QCandyUi import CandyWindowmainWindow = TcpUdpSerialportTool.TcpUdpSerialPortTool()mainWindow = CandyWindow.createWindow(mainWindow, 'blue')mainWindow.show() Ps: 想自己新增颜色主题可以在theme.json里面配, 按照theme.json里的格式配即可 py模块的安装包在/python-version/dist中","link":"/2018/07/11/qcandyui/"},{"title":"go-爬点Pixiv画师图","text":"背景 刚好需要某个画师的插画, 故写了个简单无需登录的爬图工具 根据Pixiv画师ID, 爬完直接保存在当前目录的 使用1234567// Fetch完后自动建一个画师ID的目录然后图片就放里面cli := PixivClient{ Cli: http.Client{}, Proxy: defaultProxy(), // 不需要代理则nil即可}ctx, _ := context.WithTimeout(context.Background(), time.Second*600)cli.Fetch(ctx, &quot;4462&quot;, -1) // 画师ID:4462 完整实现 代码很简单, 就100多行 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166package pixivimport ( &quot;context&quot; &quot;encoding/json&quot; &quot;fmt&quot; &quot;golang.org/x/net/proxy&quot; &quot;io&quot; &quot;io/ioutil&quot; &quot;math/rand&quot; &quot;net/http&quot; &quot;os&quot; &quot;strconv&quot; &quot;strings&quot; &quot;sync&quot; &quot;time&quot;)type PixivClient struct { Cli http.Client Proxy proxy.Dialer // 不为nil则走proxy RandSleep bool // 随机sleep, 防止爬太快}// limit为-1则无限func (pcli PixivClient) Fetch(ctx context.Context, userId string, limit int) { wg := sync.WaitGroup{} tasksDone := make(chan struct{}) illusts, err := pcli.ListIllustByUser(userId) if err != nil { return } for i, illust := range illusts { if i &gt; limit &amp;&amp; limit != -1 { break } wg.Add(1) go func(imgUrl, imgId string) { defer wg.Done() if pcli.RandSleep { randSleep(time.Second * 5) } err := pcli.fetchOne(userId, imgUrl, imgId) if err != nil { fmt.Printf(&quot;fetchOne(%s, %s): %s\\n&quot;, userId, imgId, err.Error()) return } fmt.Printf(&quot;%s finish!\\n&quot;, imgId) }(illust.ImageUrls.Large, strconv.Itoa(illust.Id)) } go func() { wg.Wait() tasksDone &lt;- struct{}{} }() select { case &lt;-tasksDone: case &lt;-ctx.Done(): fmt.Println(ctx.Err()) }}type illustInfo struct { Id int `json:&quot;id&quot;` ImageUrls struct { Large string `json:&quot;large&quot;` } `json:&quot;image_urls&quot;`}func (pcli PixivClient) ListIllustByUser(userId string) ([]illustInfo, error) { type pagination struct { Pages int `json:&quot;pages&quot;` Current int `json:&quot;current&quot;` PerPage int `json:&quot;per_page&quot;` Total int `json:&quot;total&quot;` } type imjad struct { Response []illustInfo `json:&quot;response&quot;` Pagination pagination `json:&quot;pagination&quot;` } pcli.Cli.Transport = nil // 国内的api无需代理 getFn := func(pageNo int) (*imjad, error) { u := fmt.Sprintf(&quot;https://api.imjad.cn/pixiv/v1/?type=member_illust&amp;id=%s&amp;page=%d&quot;, userId, pageNo) req, _ := http.NewRequest(&quot;GET&quot;, u, nil) req.Header.Set(&quot;user-agent&quot;, &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36&quot;) resp, err := pcli.Cli.Do(req) if err != nil { return nil, err } data, err := ioutil.ReadAll(resp.Body) if err != nil { return nil, err } var im imjad err = json.Unmarshal(data, &amp;im) if err != nil { return nil, err } return &amp;im, nil } im, err := getFn(1) if err != nil { return nil, err } illusts := make([]illustInfo, 0) for p := 1; p &lt;= im.Pagination.Pages; p++ { im, err := getFn(p) if err != nil { return nil, err } illusts = append(illusts, im.Response...) } return illusts, nil}func (pcli PixivClient) fetchOne(userId, imgUrl, imgId string) error { u := imgUrl cli := pcli.Cli if pcli.Proxy != nil { cli.Transport = pcli.socks5Transport() } req, _ := http.NewRequest(&quot;GET&quot;, u, nil) req.Header.Set(&quot;user-agent&quot;, &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36&quot;) req.Header.Set(&quot;Referer&quot;, &quot;http://www.pixiv.net/&quot;) resp, err := cli.Do(req) if err != nil { return err } _ = os.Mkdir(userId, os.ModePerm) idx := strings.LastIndexFunc(imgUrl, func(r rune) bool { if r == '/' { return true } return false }) f, err := os.Create(fmt.Sprintf(&quot;%s/%s&quot;, userId, imgUrl[idx+1:])) if err != nil { return err } defer func() { _ = f.Close() }() if _, err = io.Copy(f, resp.Body); err != nil { return err } return nil}func (pcli PixivClient) socks5Transport() *http.Transport { httpTransport := &amp;http.Transport{} httpTransport.Dial = pcli.Proxy.Dial return httpTransport}func randSleep(max time.Duration) { t := rand.Int63n(int64(max)) time.Sleep(time.Duration(t))}func defaultProxy() proxy.Dialer { d, err := proxy.SOCKS5(&quot;tcp&quot;, &quot;127.0.0.1:1080&quot;, nil, proxy.Direct) if err != nil { panic(err) } return d}","link":"/2020/06/21/pixiv_spider/"},{"title":"sd1.5微调实践","text":"微调实践 目前sd1.5我主要试了3种微调方法, dreamBooth, lora, lycoris dreamBooth 说实话我感受不到这个微调方式的任何优势, 属于花好几倍的时间, 呈现出来的效果却不理想, 不管是人物训练还是画风训练, 而且对显存要求也高, 最后的模型还很大! 推荐指数: 极低 lora &amp; lycoris lora和lycoris放一起讲是因为他们2个确实差不多, 训练时间短, 资源消耗少, 效果好, 模型小 用同样样本和参数训练出来的画风模型, 二者确实相差不大 推荐指数: 高 由于二者的训练成本都不高, 其实完全可以两种方式一起用, 看哪个效果相对好些就用哪个","link":"/2023/12/23/sd1.5%E5%BE%AE%E8%B0%83%E5%AE%9E%E8%B7%B5/"},{"title":"Redis数据迁移:RedisShake源码阅读","text":"简述 近期用到了RedisShake做数据迁移, 源码代码量不多于是看了一遍, 本篇为阅读源码的笔记 本篇重点讲解RedisShake的数据迁移功能, 其他几个功能dump,decode,restore,rump只简单提及 原理及架构 原理用一句话概述就是: 假装成源Redis的slave, 利用pSync接收来自源Redis的数据再回放到目标Redis redisShake架构图cluster版 redisShake架构图standalone版 源码信息 源码版本: v1.6 源码仓库: https://github.com/tair-opensource/RedisShake 一. 进程入口:main func main为进程的入口, 核心源码如下: (为了只关注核心逻辑, 无关紧要的代码片段会用// ... + 注释代替) 简单来讲做了3件事情 初始化和校验配置参数 加进程锁 使用了第三方工具github.com/nightlyone/lockfile实现的 简单讲就是在conf.Options.PidPath目录下建一个{conf.Options.Id}.pid文件来实现进程锁; 所以你可以扫描该目录下有多少个pid文件来确认当前有多少RedisShake进程在运行 跑数据迁移 12345678910111213141516171819202122232425262728// main/main.gofunc main() { // ... 各种初始化和校验, 如配置文件, 入参等 // 加进程锁, 进程id为`conf.Options.Id`, 入参时指定 if err = utils.WritePidById(conf.Options.Id, conf.Options.PidPath); err != nil { crash(fmt.Sprintf(&quot;write pid failed. %v&quot;, err), -5) } // 根据需求选择对应的命令, 我们这里只关注数据迁移, 所以走run.CmdSync var runner base.Runner switch *tp { case conf.TypeDecode: runner = new(run.CmdDecode) // 见decode.go case conf.TypeRestore: runner = new(run.CmdRestore) // 见restore.go case conf.TypeDump: runner = new(run.CmdDump) // 见dump.go case conf.TypeSync: runner = new(run.CmdSync) // 见sync.go case conf.TypeRump: runner = new(run.CmdRump) // 见rump.go } // 运行迁移任务 runner.Main()} 二. 数据迁移入口: CmdSync 数据迁移的具体实现在 sync.go/CmdSync.Main, 核心源码如下: 简单来讲做了2件事情 建n个dbSyncer, 分配给m条线程 默认情况下n = m = len(SourceAddressList), 即和源地址相关, 但和源架构无关 对于迁移目标为cluster架构, 所有dbSyncer用同一个dst, 即TargetAddressList 对于迁移目标为standalone架构, 用roundRobin将TargetAddressList分配给各个DbSyncer 用dbSyncer完成数据迁移, 所以dbSyncer才是数据迁移的核心, 下小节讲解 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// sync.go// 这个Main()就是上小节的`runner.Main()`func (cmd *CmdSync) Main() { syncChan := make(chan syncNode, total) // dbSyncer是数据迁移的核心, 相当于worker cmd.dbSyncers = make([]*dbSyncer, total) for i, source := range conf.Options.SourceAddressList { var target []string if conf.Options.TargetType == conf.RedisTypeCluster { target = conf.Options.TargetAddressList } else { // round-robin pick pick := utils.PickTargetRoundRobin(len(conf.Options.TargetAddressList)) target = []string{conf.Options.TargetAddressList[pick]} } nd := syncNode{ id: i, source: source, sourcePassword: conf.Options.SourcePasswordRaw, target: target, targetPassword: conf.Options.TargetPasswordRaw, } syncChan &lt;- nd } var wg sync.WaitGroup wg.Add(len(conf.Options.SourceAddressList)) for i := 0; i &lt; int(conf.Options.SourceRdbParallel); i++ { go func() { for { nd, ok := &lt;-syncChan if !ok { break } ds := NewDbSyncer(nd.id, nd.source, nd.sourcePassword, nd.target, nd.targetPassword, conf.Options.HttpProfile+i) cmd.dbSyncers[nd.id] = ds go ds.sync() &lt;-ds.waitFull // 阻塞直至全量同步完成 wg.Done() } }() } wg.Wait() // 阻塞直至全量同步完成 close(syncChan) // 永远阻塞 select {}} 三. 数据迁移核心: dbSyncer 核心方法为3个: sendPSyncCmd: 读取全量+增量数据(pSync), 返回reader syncRDBFile: 从reader读取全量数据, 并同步(restore key) syncCommand: 从reader读取增量数据, 并同步(回放cmd) 这三个核心方法的具体逻辑如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223// sync.go// 不阻塞// 跑Psync, 跑一条全量+增量同步的goroutine, 用于不断读取全量+增量的数据,// 全量和增量同步获取的实体数据最终都会Pipe到piper, 即return的那个pipe.Readerfunc (ds *dbSyncer) sendPSyncCmd(master, auth_type, passwd string, tlsEnable bool) (pipe.Reader, int64) { // 1. 执行pSync c := utils.OpenNetConn(master, auth_type, passwd, tlsEnable) utils.SendPSyncListeningPort(c, conf.Options.HttpProfile) br := bufio.NewReaderSize(c, utils.ReaderBufferSize) bw := bufio.NewWriterSize(c, utils.WriterBufferSize) // 2. 首次pSync获取runid, offset, nsize, 后面的rdb数据会写入bw, 我们只需关注从br读取即可 runid, offset, wait := utils.SendPSyncFullsync(br, bw) ds.targetOffset.Set(offset) var nsize int64 // nsize为rdb的大小 for nsize == 0 { // 获取nsize为耗时操作, 通过wait管道通知获取(变量名换成waitForRdbSize好些) select { case nsize = &lt;-wait: if nsize == 0 { log.Infof(&quot;dbSyncer[%v] +&quot;, ds.id) } case &lt;-time.After(time.Second): log.Infof(&quot;dbSyncer[%v] -&quot;, ds.id) } } // br -&gt; pipew -&gt; piper(这个返回出去,作为ds.syncRDBFile的reader) piper, pipew := pipe.NewSize(utils.ReaderBufferSize) go func() { defer pipew.Close() p := make([]byte, 8192) // 3. 全量: 读取psync的数据直至读了nsize的数据, 最终写到piper(return出去那个) for rdbsize := int(nsize); rdbsize != 0; { // br -&gt; pipew rdbsize -= utils.Iocopy(br, pipew, p, rdbsize) } // 4. 增量: 不断从psync读数据, 最终写到piper(return出去那个), 是一个死循环(除非异常) for { n, err := ds.pSyncPipeCopy(c, br, bw, offset, pipew) // 正常会在这里永远阻塞 if err != nil { log.PanicErrorf(err, &quot;dbSyncer[%v] psync runid = %s, offset = %d, pipe is broken&quot;, ds.id, runid, offset) } // ... 后面是失败重试相关的操作, 这里不展示 } }() return piper, nsize}// 阻塞至全量同步完成// 从reader(这个就是上面sendPSyncCmd返回的reader)读出BinEntry, 再OpenRedisConn(target), 然后RestoreRdbEntry到target的redis节点func (ds *dbSyncer) syncRDBFile(reader *bufio.Reader, target []string, auth_type, passwd string, nsize int64, tlsEnable bool) { pipe := utils.NewRDBLoader(reader, &amp;ds.rbytes, base.RDBPipeSize) wait := make(chan struct{}) go func() { defer close(wait) var wg sync.WaitGroup wg.Add(conf.Options.Parallel) // restore的时候可以并发, 从pipe里面取, 因为是全量的(按key进行restore), 所以没有顺序之分, 可以并发执行 for i := 0; i &lt; conf.Options.Parallel; i++ { go func() { defer wg.Done() c := utils.OpenRedisConn(target, auth_type, passwd, conf.Options.TargetType == conf.RedisTypeCluster, tlsEnable) defer c.Close() var lastdb uint32 = 0 for e := range pipe { // e是BinEntry, 全量同步的单位数据 // filterDB控制src, targetDB控制dst if filter.FilterDB(int(e.DB)) { } else { // 这里执行selectDB选择同步的目标DB // selectDB, 写这么多只是为了防止重复selectDB浪费性能 if conf.Options.TargetDB != -1 { if conf.Options.TargetDB != int(lastdb) { lastdb = uint32(conf.Options.TargetDB) utils.SelectDB(c, uint32(conf.Options.TargetDB)) } } else { // 如果不指定targetDB, 则源DB是啥, targetDB就是啥 if e.DB != lastdb { lastdb = e.DB utils.SelectDB(c, lastdb) } } // 根据BinEntry的Key进行过滤 if filter.FilterKey(string(e.Key)) == true { // key白名单 ds.ignore.Incr() continue } else { slot := int(utils.KeyToSlot(string(e.Key))) if filter.FilterSlot(slot) == true { // slot白名单 ds.ignore.Incr() continue } } utils.RestoreRdbEntry(c, e) // restore 到 target } } }() } wg.Wait() }() // 这会阻塞至&lt;-wait信号, 即全量同步完成 for done := false; !done; { select { case &lt;-wait: done = true case &lt;-time.After(time.Second): } // ... 后面都是统计和打日志逻辑, 这里不展示 }}// 永远阻塞func (ds *dbSyncer) syncCommand(reader *bufio.Reader, target []string, auth_type, passwd string, tlsEnable bool) { c := utils.OpenRedisConnWithTimeout(target, auth_type, passwd, readeTimeout, writeTimeout, isCluster, tlsEnable) defer c.Close() // ... 一大段FakeSlaveOffset相关逻辑, 给不支持pSync的用的, 这里不展示 // ... 一大段统计相关逻辑, 这里不展示 go func() { var ( lastdb int32 = 0 bypass = false isselect = false scmd string argv, newArgv [][]byte err error reject bool ) decoder := redis.NewDecoder(reader) // 1. 读取reader, 解析出cmdDetail, 然后发送到sendBuf for { ignoresentinel:= false ignorecmd := false isselect = false resp := redis.MustDecodeOpt(decoder) // 这里是我精简后的代码 // 根据scmd做一些过滤逻辑, 以及对当scmd为Select db时, 对target db的一些处理 if scmd, argv, err = redis.ParseArgs(resp); err != nil { } else { if scmd != &quot;ping&quot; { if strings.EqualFold(scmd, &quot;select&quot;) { s := string(argv[0]) n, err := strconv.Atoi(s) bypass = filter.FilterDB(n) isselect = true } else if filter.FilterCommands(scmd) { ignorecmd = true } if strings.EqualFold(scmd, &quot;publish&quot;) &amp;&amp; strings.EqualFold(string(argv[0]), &quot;__sentinel__:hello&quot;){ ignoresentinel = true } if bypass || ignorecmd || ignoresentinel{ ds.nbypass.Incr() continue } } newArgv, reject = filter.HandleFilterKeyWithCommand(scmd, argv) if bypass || ignorecmd || reject { continue } } if isselect &amp;&amp; conf.Options.TargetDB != -1 { if conf.Options.TargetDB != int(lastdb) { lastdb = int32(conf.Options.TargetDB) ds.sendBuf &lt;- cmdDetail{Cmd: &quot;SELECT&quot;, Args: [][]byte{[]byte(strconv.FormatInt(int64(lastdb), 10))}} } continue } ds.sendBuf &lt;- cmdDetail{Cmd: scmd, Args: newArgv} } }() // 2. 从sendBuf读取出cmd, 回放到target (默认5000个cmd flush一次) go func() { var noFlushCount uint var cachedSize uint64 for item := range ds.sendBuf { length := len(item.Cmd) data := make([]interface{}, len(item.Args)) for i := range item.Args { data[i] = item.Args[i] length += len(item.Args[i]) } err := c.Send(item.Cmd, data...) // 回放cmd noFlushCount += 1 if noFlushCount &gt;= conf.Options.SenderCount || cachedSize &gt;= conf.Options.SenderSize || len(ds.sendBuf) == 0 { // 5000 ds in a batch err := c.Flush() noFlushCount = 0 cachedSize = 0 } } }() // 3. 永远阻塞, 每1s做一次统计 for lstat := ds.Stat(); ; { time.Sleep(time.Second) nstat := ds.Stat() var b bytes.Buffer fmt.Fprintf(&amp;b, &quot;dbSyncer[%v] sync: &quot;, ds.id) fmt.Fprintf(&amp;b, &quot; +forwardCommands=%-6d&quot;, nstat.forward-lstat.forward) fmt.Fprintf(&amp;b, &quot; +filterCommands=%-6d&quot;, nstat.nbypass-lstat.nbypass) fmt.Fprintf(&amp;b, &quot; +writeBytes=%d&quot;, nstat.wbytes-lstat.wbytes) log.Info(b.String()) lstat = nstat }} 四. 总结 简单来说, 这个迁移原理就是假装为slave (利用pSync), 接收源redis的rdb然后restore到目标redis实现全量同步,然后继续接收源redis的增量cmd然后回放到目标redis实现增量同步","link":"/2022/07/09/redisShake%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"Redis源码阅读-事件模型ae","text":"源码文件 src/ae.c 入口函数 src/ae.c下的void aeMain(aeEventLoop *eventLoop)函数; 推荐从这个函数开始阅读1234567891011121314/* * 事件处理器的主循环 */void aeMain(aeEventLoop *eventLoop) { eventLoop-&gt;stop = 0; while (!eventLoop-&gt;stop) { // 如果有需要在事件处理前执行的函数，那么运行它 if (eventLoop-&gt;beforesleep != NULL) eventLoop-&gt;beforesleep(eventLoop); // 开始处理事件 aeProcessEvents(eventLoop, AE_ALL_EVENTS); }} 我们着重看下aeMain里面aeProcessEvents(eventLoop, AE_ALL_EVENTS)做了什么; 这里我们留意一下里面的aeApiPoll函数, 该函数用于获取可执行的事件, 获取之后在下面的for循环中处理事件, 执行事件处理器 fe-&gt;rfileProc(eventLoop,fd,fe-&gt;clientData,mask) aeApiPoll函数是ae模块提供的一个接口, 在ae_epoll.c ae_kqueue.c ae_select.c ae_evport.c都做了相应的具体实现, 也是所谓IO多路复用各平台的具体实现, 目的为了兼容不同平台 备注: 也许你会好奇为啥IO多路复用没有iocp的实现难道windows就没人权吗, 其实redis的官方版本是不支持windows的, windows版本在https://github.com/microsoftarchive/redis由微软团队自己维护, 里面就有ae_wsiocp.c即iocp版的实现1234567891011121314151617181920212223242526int aeProcessEvents(aeEventLoop *eventLoop, int flags) { ... ... // 处理文件事件 numevents = aeApiPoll(eventLoop, tvp); for (j = 0; j &lt; numevents; j++) { // 从已就绪数组中获取事件 aeFileEvent *fe = &amp;eventLoop-&gt;events[eventLoop-&gt;fired[j].fd]; int mask = eventLoop-&gt;fired[j].mask; int fd = eventLoop-&gt;fired[j].fd; int rfired = 0; // 读事件 if (fe-&gt;mask &amp; mask &amp; AE_READABLE) { // rfired 确保读/写事件只能执行其中一个 rfired = 1; fe-&gt;rfileProc(eventLoop,fd,fe-&gt;clientData,mask); } // 写事件 if (fe-&gt;mask &amp; mask &amp; AE_WRITABLE) { if (!rfired || fe-&gt;wfileProc != fe-&gt;rfileProc) fe-&gt;wfileProc(eventLoop,fd,fe-&gt;clientData,mask); } processed++; } ... ...} 通常说的redis的reactor模型(反应堆)其实说的就是aeMain的大循环中aeProcessEvents做的那些事情: 监听网络连接的FD的文件事件---&gt; 获取事件---&gt; 执行事件回调 剩下具体细节不多赘述, 顺着思路看源码即可 参考 Redis 和 IO 多路复用 redis的事件模型详解(结合Reactor设计模式)","link":"/2020/05/05/redis_ae/"},{"title":"Py小玩具-Tcp&amp;Udp&amp;串口调试工具","text":"简介 以前捣鼓嵌入式的时候写的, 就是那种网上搜就一大把的UDP+TCP+串口调试工具, 为了方便定制些功能于是自己搞了一个, 平时自己用, 功能没啥问题 效果如下 界面 十分眼熟的那四种模式…Udp+TcpClient+TcpServer+串口通信 代码https://github.com/shuoGG1239/TcpUdpSerialPortTool 补充 纯PyQt开发 界面右下角的AOP功能目的主要用于拦截发送和接收的数据, 然后在脚本中做额外处理, 一般场景用不到可无视…","link":"/2019/03/31/tcpudp_tool/"},{"title":"做个纸片人桌宠live2d Viewer","text":"展示下效果 能在桌面展示Live2d模型并和鼠标互动 (双生最近的圣诞苏小真的Live2d模型做的是真的好!) 关于这个live2d Viewer 之前逛了一圈看很少有对live2d-v3做支持的, 大部分还是停留v2. 而最近双生这些高质量的live2d模型全是v3, 于是想自己做一个live2dViewer, 好把新老婆放桌面欣赏 技术选型上直接用electron了 (再见了老朋友Qt) , 因为未来打算在网站也复用一下, 所以选择electron无需犹豫 如何使用? 可以直接拉源码用electron跑, 后面我会打包执行文件到release直接用也行 源码仓库 源码仓库: https://github.com/shuoGG1239/live2d-Waifu 模型仓库: https://github.com/shuoGG1239/Live2d-model live2d 对接过程中的坑 一些游戏厂的模型, 并不按live2d cubisum的标准live2dParamId来制作, 例如双生的苏小真-圣诞Ver (id对比如下源码);我没搞懂为啥不按官方标准来定义, 这样只会徒增模型师和程序员的工作量 如何获取模型的ParamId列表? 可以在framework的加载好模型后, 用idManager遍历和打印params 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110// live2d官方默认的parameterid/** * @brief パラメータIDのデフォルト値を保持する定数&lt;br&gt; * デフォルト値の仕様は以下のマニュアルに基づく&lt;br&gt; * https://docs.live2d.com/cubism-editor-manual/standard-parametor-list/ */export namespace Live2DCubismFramework{ // パーツID export const HitAreaPrefix: string = &quot;HitArea&quot;; export const HitAreaHead: string = &quot;Head&quot;; export const HitAreaBody: string = &quot;Body&quot;; export const PartsIdCore: string = &quot;Parts01Core&quot;; export const PartsArmPrefix: string = &quot;Parts01Arm_&quot;; export const PartsArmLPrefix: string = &quot;Parts01ArmL_&quot;; export const PartsArmRPrefix: string = &quot;Parts01ArmR_&quot;; // パラメータID export const ParamAngleX: string = &quot;ParamAngleX&quot;; export const ParamAngleY: string = &quot;ParamAngleY&quot;; export const ParamAngleZ: string = &quot;ParamAngleZ&quot;; export const ParamEyeLOpen: string = &quot;ParamEyeLOpen&quot;; export const ParamEyeLSmile: string = &quot;ParamEyeLSmile&quot;; export const ParamEyeROpen: string = &quot;ParamEyeROpen&quot;; export const ParamEyeRSmile: string = &quot;ParamEyeRSmile&quot;; export const ParamEyeBallX: string = &quot;ParamEyeBallX&quot;; export const ParamEyeBallY: string = &quot;ParamEyeBallY&quot;; export const ParamEyeBallForm: string = &quot;ParamEyeBallForm&quot;; export const ParamBrowLY: string = &quot;ParamBrowLY&quot;; export const ParamBrowRY: string = &quot;ParamBrowRY&quot;; export const ParamBrowLX: string = &quot;ParamBrowLX&quot;; export const ParamBrowRX: string = &quot;ParamBrowRX&quot;; export const ParamBrowLAngle: string = &quot;ParamBrowLAngle&quot;; export const ParamBrowRAngle: string = &quot;ParamBrowRAngle&quot;; export const ParamBrowLForm: string = &quot;ParamBrowLForm&quot;; export const ParamBrowRForm: string = &quot;ParamBrowRForm&quot;; export const ParamMouthForm: string = &quot;ParamMouthForm&quot;; export const ParamMouthOpenY: string = &quot;ParamMouthOpenY&quot;; export const ParamCheek: string = &quot;ParamCheek&quot;; export const ParamBodyAngleX: string = &quot;ParamBodyAngleX&quot;; export const ParamBodyAngleY: string = &quot;ParamBodyAngleY&quot;; export const ParamBodyAngleZ: string = &quot;ParamBodyAngleZ&quot;; export const ParamBreath: string = &quot;ParamBreath&quot;; export const ParamArmLA: string = &quot;ParamArmLA&quot;; export const ParamArmRA: string = &quot;ParamArmRA&quot;; export const ParamArmLB: string = &quot;ParamArmLB&quot;; export const ParamArmRB: string = &quot;ParamArmRB&quot;; export const ParamHandL: string = &quot;ParamHandL&quot;; export const ParamHandR: string = &quot;ParamHandR&quot;; export const ParamHairFront: string = &quot;ParamHairFront&quot;; export const ParamHairSide: string = &quot;ParamHairSide&quot;; export const ParamHairBack: string = &quot;ParamHairBack&quot;; export const ParamHairFluffy: string = &quot;ParamHairFluffy&quot;; export const ParamShoulderY: string = &quot;ParamShoulderY&quot;; export const ParamBustX: string = &quot;ParamBustX&quot;; export const ParamBustY: string = &quot;ParamBustY&quot;; export const ParamBaseX: string = &quot;ParamBaseX&quot;; export const ParamBaseY: string = &quot;ParamBaseY&quot;; export const ParamNONE: string = &quot;NONE:&quot;;}// 双生视界的parameterid (这游戏比较奇葩parameterid不按规矩来)export namespace CafeGunGirlParam{ export const PartsArmPrefix: string = &quot;PARTS_01_ARM_&quot;; export const PartsArmLPrefix: string = &quot;PARTS_01_ARM_L_&quot;; export const PartsArmRPrefix: string = &quot;PARTS_01_ARM_R_&quot;; export const ParamAngleX: string = &quot;PARAM_ANGLE_X&quot;; export const ParamAngleY: string = &quot;PARAM_ANGLE_Y&quot;; export const ParamAngleZ: string = &quot;PARAM_ANGLE_Z&quot;; export const ParamEyeLOpen: string = &quot;PARAM_EYE_L_OPEN&quot;; export const ParamEyeLSmile: string = &quot;PARAM_EYE_L_SMILE&quot;; export const ParamEyeROpen: string = &quot;PARAM_EYE_R_OPEN&quot;; export const ParamEyeRSmile: string = &quot;PARAM_EYE_R_SMILE&quot;; export const ParamEyeBallX: string = &quot;PARAM_EYE_BALL_X&quot;; export const ParamEyeBallY: string = &quot;PARAM_EYE_BALL_Y&quot;; export const ParamBrowLY: string = &quot;PARAM_BROW_L_Y&quot;; export const ParamBrowRY: string = &quot;PARAM_BROW_R_Y&quot;; export const ParamBrowLX: string = &quot;PARAM_BROW_L_X&quot;; export const ParamBrowRX: string = &quot;PARAM_BROW_R_X&quot;; export const ParamBrowLAngle: string = &quot;PARAM_BROW_L_ANGLE&quot;; export const ParamBrowRAngle: string = &quot;PARAM_BROW_R_ANGLE&quot;; export const ParamBrowLForm: string = &quot;PARAM_BROW_L_FORM&quot;; export const ParamBrowRForm: string = &quot;PARAM_BROW_R_FORM&quot;; export const ParamMouthForm: string = &quot;PARAM_MOUTH_FORM&quot;; export const ParamMouthOpenY: string = &quot;PARAM_MOUTH_OPEN_Y&quot;; export const ParamCheek: string = &quot;PARAM_CHEEK&quot;; export const ParamBodyAngleX: string = &quot;PARAM_BODY_ANGLE_X&quot;; export const ParamBodyAngleY: string = &quot;PARAM_BODY_ANGLE_Y&quot;; export const ParamBodyAngleZ: string = &quot;PARAM_BODY_ANGLE_Z&quot;; export const ParamBreath: string = &quot;PARAM_BREATH&quot;; export const ParamArmLA: string = &quot;PARAM_ARM_L_A&quot;; export const ParamArmRA: string = &quot;PARAM_ARM_R_A&quot;; export const ParamArmLB: string = &quot;PARAM_ARM_L_B&quot;; export const ParamArmRB: string = &quot;PARAM_ARM_R_B&quot;; export const ParamHandL: string = &quot;PARAM_HAND_L&quot;; export const ParamHandR: string = &quot;PARAM_HAND_R&quot;; export const ParamHairFront: string = &quot;PARAM_HAIR_FRONT&quot;; export const ParamHairSide: string = &quot;PARAM_HAIR_SIDE&quot;; export const ParamHairBack: string = &quot;PARAM_HAIR_BACK&quot;; export const ParamHairFluffy: string = &quot;PARAM_HAIR_FLUFFY&quot;; export const ParamShoulderY: string = &quot;PARAM_SHOULDER_Y&quot;; export const ParamBustX: string = &quot;PARAM_BUST_X&quot;; export const ParamBustY: string = &quot;PARAM_BUST_Y&quot;; export const ParamBaseX: string = &quot;PARAM_BASE_X&quot;; export const ParamBaseY: string = &quot;PARAM_BASE_Y&quot;; export const ParamNONE: string = &quot;NONE:&quot;;} 由于部分游戏厂的模型不按标准来定义id, 就意味着想做通用live2dViewer就需要各种适配, 就挺坑的 还有live2d cubisum的sdk和framework, 文档和源码注释全是日文, 难道就不重视下岛外市场吗?","link":"/2020/01/31/%E5%81%9A%E4%B8%AA%E7%BA%B8%E7%89%87%E4%BA%BAlive2d%20Viewer/"},{"title":"spine学习笔记","text":"参考资料 官方教程简短可以刷一遍: Spine官方Manual 企业级工程值得学习: BlueArchive的Spine工程 本篇实例的原画文件: https://www.live2d.com/zh-CHS/learn/sample/ 新建工程 拆好件的psd, 菜单--&gt;脚本--&gt;PhotoshopToSpine--&gt;OK, 此时会输出1个带部件图的文件夹和1个json文件 打开spine, 主菜单--&gt;导入数据--&gt;选上一步的json文件, 确定 此时spine工程已建好 基础操作 右键拖动: 移动视图, 相当于其他软件的按住空格 中键拖动: 框选 工具 变换工具: 旋转, 移动, 缩放, 倾斜 (C, V, X, Z) 高级工具: 姿势, 权重, 创建 (B, G, N) 7个工具之间是互斥的, 同时只能使用1个工具 锁 当骨骼和部件绑一起时, 你只想调整骨骼的位置, 不想带动下面的部件一起变, 则可用锁图片实现, 如图 骨骼 骨骼创建工具: 如下图 骨骼同样可以旋转, 移动, 缩放, 倾斜, 它会带动骨骼下的子节点进行变换 快速创建骨骼 在骨骼创建模式下, 点父骨骼(没得选就点root骨骼), 按住ctrl点待绑部件, 拖出新骨骼; 此时新骨骼的父子关系, 部件绑定关系, 还有命名都由系统自动安排好了 ik约束 选2个骨骼, 创建ik约束 网格 点编辑网格, 若没有网格会自动创建; 然后点生成会自动布点, 但布点算法很垃圾! 网格的网点编辑就是修改,创建,删除来回切换使用 (难用得要死!) 选中网格, 点绑定, 再点左边的骨骼, 将网格和骨骼做绑定 点高级工具的权重进入权重视图 随便新建个新骨骼arm_r_bone2, 还是选中上面刚做好的网格, 然后绑定这个新骨骼, 进入权重视图, 此时会有个权重笔刷, 改为新增模式, 刷下面几个点, 会发现变成紫色, 也就是说这几个点的控制权已转交给骨骼arm_r_bone2了 动画 动画模式: 点击左上角切换进入 K帧: 例如做一个手臂缩小的动画: 选中骨骼--&gt;0帧处点缩放的钥匙--&gt; 15帧处将缩放值调小(此时自动K帧)","link":"/2024/11/13/spine%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"博客主题icarus样式魔改","text":"简介 这几天把博客主题从next换成了icarus, 官方默认样式不大满意, 我做了些调整, 这里记下调整过程 预览(前者官方, 后者魔改) 小组件调整 自带的小组件太杂了, 这里我只保留了总览, 分类, 标签, 近期文章 修改_config.icarus.yml的widgets, 仅保留type为profile, categories, recent_posts, tags这4个, 其他删掉或注释掉即可 代码样式调整 修改_config.icarus.yml的article/highlight/theme, 默认是用atom-one-light, 我改用vs即vscode的样式 标题样式调整 原大标题字体没加粗处理, 跟文章content看起来不好区分, 所以做了加粗处理 修改include/style/article.styl文件, 在h1到h5项分别加上font-weight: 600, 如下:12345678910111213141516171819202122232425262728293031323334&amp;.article .article-meta, .article-tags color: $text-light .article-meta overflow-x: auto margin-bottom: .5rem .article-more @extend .button.is-light .content word-wrap: break-word font-size: $article-font-size h1 font-weight: 600 font-size: 1.75em h2 font-weight: 600 font-size: 1.5em h3 font-weight: 600 font-size: 1.25em h4 font-weight: 600 font-size: 1.125em h5 font-weight: 600 font-size: 1em 文章宽度和留空区宽度调整 默认的文章宽度太小, 两边的留空区太大, 文章内部就显得拥挤 调整include/style/base.styl的基础变量$gap, 由64px改为32px 12345$gap ?= 32px$tablet ?= 769px$desktop ?= 1088px$widescreen ?= 1280px$fullhd ?= 1472px 调整include/style/responsive.styl里面containter的width, container其实就是文章容器, 这里把默认值2 * $gap改成1 * $gap 12345678910111213+widescreen() .is-1-column .container, .is-2-column .container max-width: $widescreen - 1 * $gap width: $widescreen - 1 * $gap+fullhd() .is-2-column .container max-width: $fullhd - 1 * $gap width: $fullhd - 1 * $gap .is-1-column .container max-width: $desktop - 1 * $gap width: $desktop - 1 * $gap 调整layout/common/widgets.jsx的getColumnSizeClass, 将case 2的is-4-tablet is-4-desktop is-4-widescreen替换为is-2-tablet is-2-desktop is-2-widescreen 123456789function getColumnSizeClass(columnCount) { switch (columnCount) { case 2: return 'is-2-tablet is-2-desktop is-2-widescreen'; case 3: return 'is-3-tablet is-3-desktop is-3-widescreen'; } return '';} 调整layout/layout.jsx, 将'is-8-tablet is-8-desktop is-8-widescreen': columnCount === 2替换为'is-8-tablet is-9-desktop is-9-widescreen': columnCount === 2 12345678&lt;div class={classname({ column: true, 'order-2': true, 'column-main': true, 'is-12': columnCount === 1, 'is-8-tablet is-9-desktop is-9-widescreen': columnCount === 2, 'is-8-tablet is-9-desktop is-6-widescreen': columnCount === 3})} dangerouslySetInnerHTML={{ __html: body }}&gt;&lt;/div&gt; 侧边栏的profile 由于侧边栏被我调窄了, 头像显得太大, 所以这里调下layout/widget/profile.jsx的figure, 将128x128替换为64x641234567891011&lt;div&gt; &lt;figure class=&quot;image is-64x64 mx-auto mb-2&quot;&gt; &lt;img class={'avatar' + (avatarRounded ? ' is-rounded' : '')} src={avatar} alt={author} /&gt; &lt;/figure&gt; {author ? &lt;p class=&quot;title is-size-4 is-block&quot; style={{'line-height': 'inherit'}}&gt;{author}&lt;/p&gt; : null} {authorTitle ? &lt;p class=&quot;is-size-6 is-block&quot;&gt;{authorTitle}&lt;/p&gt; : null} {location ? &lt;p class=&quot;is-size-6 is-flex justify-content-center&quot;&gt; &lt;i class=&quot;fas fa-map-marker-alt mr-1&quot;&gt;&lt;/i&gt; &lt;span&gt;{location}&lt;/span&gt; &lt;/p&gt; : null}&lt;/div&gt;","link":"/2024/11/27/%E5%8D%9A%E5%AE%A2%E4%B8%BB%E9%A2%98icarus%E6%A0%B7%E5%BC%8F%E9%AD%94%E6%94%B9/"},{"title":"梯度下降笔记","text":"梯度下降迭代公式$$\\omega_{t+1} = \\omega_t - \\alpha \\nabla f(\\omega_t)$$ $\\alpha$为学习率 $\\nabla f(\\omega_t)$为梯度 通俗理解梯度下降迭代公式 首先可以确定的是我们的任务是找loss极小值(不是极值而是极小值) 对于f(x)的一阶导可以认为是f(x)随着x的增长而增长的趋势, 所以为了找极小值的x坐标必定和一阶导的反方向来找 在此例子中, $f(x) = x^2-2x+3$, 一阶导$f’(x) = 2x -2$, 在x=2的导数为2, 可以通俗的理解为当x增长1则f(x)会增长2,而我们的任务是找f(x)的极小值, 所以极小值的x坐标必定是跟导数2是反方向;同理在x=0的导数为-2, 即x增长1则f(x)会增长-2, 极小值的x坐标方向确实和导数-2为反向 在这个例子中我们也可以用斜率的投影方向来理解","link":"/2024/01/06/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/"},{"title":"提取公主链接spine","text":"简介 公主链接的Q版小人很适合当Spine的学习项目, 本篇介绍如何提取并转换为spine工程 提取资源 下载资源: 到 https://redive.estertion.win/spine/ 将.altas, .png, .skel都下载了 转json工程文件 (因为spine只认json不认skel): 到 https://naganeko.pages.dev/chibi-gif 点 Add skeleton, 将上步的3个文件选上提交, 然后到最下面的Export skeleton as json for点Spine3.8, 导出json文件 导入资源到Spine 到spine菜单,点 导入数据, 选择上一步导出的json文件 此时图片缺失, 到spine菜单, 点 纹理解包器, 解开atlas, 导出图片后, 将图片文件夹重命名为Texture2D 点右边的图片, 再点右下打开文件夹, 选择上步的Texture2D文件夹, 此时工程已经导入完成 进入动画模式, 然后点各个动画的小点看看效果吧! 最终Spine工程的结构","link":"/2024/11/15/%E6%8F%90%E5%8F%96%E5%85%AC%E4%B8%BB%E9%93%BE%E6%8E%A5spine/"},{"title":"像素画风的画法","text":"制作像素笔刷(CSP为例) 从铅笔笔刷复制一个, 进入笔刷设置 消除锯齿: 无 笔刷尺寸: 1.0; 笔压关闭 出峰入峰: 选项全关(入峰, 出峰, 根据速度调整出入峰) 然后就可以开始画了! 画布: 50x50 若填充颜色时, 记得将油漆桶工具的消除锯齿选项去掉 (但其实直接用像素笔刷上色也不难) 画完最后输出的时候, 改变图像大小, 例如放大为500x500, 插值方法选硬边","link":"/2025/01/13/%E5%83%8F%E7%B4%A0%E7%94%BB%E9%A3%8E/"},{"title":"用csp编辑gif动画","text":"前言 以前编辑gif一直用Ulead GIF Animator, 说实话, 很不顺手, 想寻找新的工具 尝试用了csp的动画功能来做gif编辑, 发现意外的顺手! 前置工作: gif转图片序列 csp不接受gif的图片, 这点挺蠢的, 所以需要我们手动将gif转成图片序列 这里可以用脚本解决:123456789101112131415161718192021222324from PIL import Imageimport osimport sysdef gif_to_frames(gif_path, output_folder): gif = Image.open(gif_path) if not os.path.exists(output_folder): os.makedirs(output_folder) gif_name = os.path.splitext(os.path.basename(gif_path))[0] frame_number = 0 try: while True: frame = gif.copy() frame.save(os.path.join(output_folder, f&quot;{gif_name}_frame_{frame_number:04d}.png&quot;), &quot;PNG&quot;) frame_number += 1 gif.seek(gif.tell() + 1) except EOFError: passgif_path = &quot;your_gif_file_name.gif&quot;output_folder, _ = os.path.splitext(gif_path)gif_to_frames(gif_path, output_folder) gif导入到动画轨道 先创建一个长宽大小和gif一致且边距上下左右均为0的动画 打开上一步的动画序列图片的文件夹, 框选所需序列图片, 然后直接拖到csp的动画文件夹里, 如图: 原先自带的胶片记得删掉, 如上图的文件夹最下面那个图层, 直接删掉就行 展开动画文件 -&gt; 右键轨道标签 -&gt; 批量指定胶片 - &gt; 从现在的动画胶片名称进行指定 -&gt; 确定 此时已经导入完成, 可以试试播放下动画 编辑动画 觉得图片太大了, 则可以缩小图片大小, 编辑-&gt; 图片大小 觉得图片帧之间的间隔太小, 那只能手动一张一张往后面拖来实现 至于图片的修改, 直接点所要修改的图层(胶片)进行修改就行, 怎么涂都行 导出动画 文件 -&gt; 导出动画 -&gt; Gif动画","link":"/2025/03/01/%E7%94%A8csp%E7%BC%96%E8%BE%91gif%E5%8A%A8%E7%94%BB/"},{"title":"神经网络基础","text":"Cnn","link":"/2024/01/19/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/"},{"title":"读书笔记:任天堂的体验设计","text":"三大主题: 直觉设计, 惊喜设计, 故事设计 书中的内容基本可以一图概括 心理学: 初始效应 读后感 赶紧去看看游戏心理学","link":"/2025/01/03/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E4%BB%BB%E5%A4%A9%E5%A0%82%E7%9A%84%E4%BD%93%E9%AA%8C%E8%AE%BE%E8%AE%A1/"},{"title":"纪念第1个sd丹炉","text":"模型 当然, 这仅仅是训练一个sd的微调模型 想训练个画风, 但素材不多, 可预见的效果不会好到哪去 主要的几个训练参数如下: 1234567network_module: loraoptimizer: AdamW8bitrepeat: 8epoch: 20network_dim: 32unet_lr: 0.0001text_encoder_lr: 1e-05 效果 毫无意外的过拟合了","link":"/2023/07/19/%E7%BA%AA%E5%BF%B5%E7%AC%AC1%E4%B8%AAsd%E4%B8%B9%E7%82%89/"}],"tags":[{"name":"python","slug":"python","link":"/tags/python/"},{"name":"blender","slug":"blender","link":"/tags/blender/"},{"name":"Qt","slug":"Qt","link":"/tags/Qt/"},{"name":"go","slug":"go","link":"/tags/go/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"godot","slug":"godot","link":"/tags/godot/"},{"name":"grpc","slug":"grpc","link":"/tags/grpc/"},{"name":"net","slug":"net","link":"/tags/net/"},{"name":"live2d","slug":"live2d","link":"/tags/live2d/"},{"name":"markdown","slug":"markdown","link":"/tags/markdown/"},{"name":"mongodb","slug":"mongodb","link":"/tags/mongodb/"},{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"electron","slug":"electron","link":"/tags/electron/"},{"name":"spine","slug":"spine","link":"/tags/spine/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"sd","slug":"sd","link":"/tags/sd/"}],"categories":[{"name":"美术","slug":"美术","link":"/categories/%E7%BE%8E%E6%9C%AF/"},{"name":"杂杂","slug":"杂杂","link":"/categories/%E6%9D%82%E6%9D%82/"},{"name":"ai","slug":"ai","link":"/categories/ai/"},{"name":"前端","slug":"前端","link":"/categories/%E5%89%8D%E7%AB%AF/"},{"name":"后端","slug":"后端","link":"/categories/%E5%90%8E%E7%AB%AF/"},{"name":"游戏开发","slug":"游戏开发","link":"/categories/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"}],"pages":[{"title":"文章分类","text":"","link":"/categories/index.html"},{"title":"文章分类","text":"","link":"/tags/index.html"}]}